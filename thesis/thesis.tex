\documentclass[draft,final]{thesisclass} % Remove option 'final' to obtain debug information.

% Load packages to allow input and output of non-ASCII characters.
\usepackage{lmodern}        % Use an extension of the original Computer Modern font to minimize the use of bitmapped letters.
\usepackage[T1]{fontenc}    % Determines font encoding of the output. Font packages have to be included before this line.
\usepackage[utf8]{inputenc} % Determines encoding of the input. All input files have to use UTF8 encoding.

% added package for bibliography
\usepackage{csquotes}
\usepackage[backend=biber,style=authoryear,date=year,maxbibnames=10,dashed=false]{biblatex}
\addbibresource{thesis.bib}
\DeclareDelimFormat[bib,biblist]{nametitledelim}{\addcolon\space}
\DeclareDelimFormat{postnotedelim}{\addcolon\space}

% for definitions
\usepackage{amsthm}
\newtheorem{definition}{Definition}

% Extended LaTeX functionality is enabled by including packages with \usepackage{...}.
\usepackage[usenames,dvipsnames,table]{xcolor} % Allows the definition and use of colors. This package has to be included before tikz.
\usepackage{amsmath}    % Extended typesetting of mathematical expression.
\usepackage{amssymb}    % Provides a multitude of mathematical symbols.
\usepackage{mathtools}  % Further extensions of mathematical typesetting.
\usepackage{microtype}  % Small-scale typographic enhancements.
\usepackage[inline]{enumitem} % User control over the layout of lists (itemize, enumerate, description).
\usepackage{multirow}   % Allows table elements to span several rows.
\usepackage{booktabs}   % Improves the typesetting of tables.
\usepackage{subcaption} % Allows the use of subfigures and enables their referencing.
\usepackage[ruled,linesnumbered,algochapter]{algorithm2e} % Enables the writing of pseudo code.
\usepackage{nag}       % Issues warnings when best practices in writing LaTeX documents are violated.
\usepackage{todonotes} % Provides tooltip-like todo notes.
\usepackage{lipsum}  % Provides blind text.
\usepackage{acronym} % Provides a list of acronyms.
\usepackage{float} % Provides the H float modifier option.
\usepackage{tabularx} % Provides a tabular package.
\usepackage{listings} % for code listings.
\usepackage{csvsimple} % for CSV displayment.
\usepackage{rotating} % for sideways tables.

% Import these packages in a separate group.
\usepackage{hyperref}  % Enables hyperlinking in the electronic document version. This package has to be included second to last.
\usepackage[acronym,toc]{glossaries} % Enables the generation of glossaries and lists of acronyms. This package has to be included last.

% Define convenience functions for using the author name and the thesis title in the PDF document properties.
\newcommand{\authorname}{Hannes Brantner} % The author name without titles.
\newcommand{\thesistitle}{Enhancing recruitment efficiency by exploring the impact of large language models on the screening process} % The thesis title. The English version should be used if it exists.

% Set PDF document properties
\hypersetup{
    pdfpagelayout   = TwoPageRight,           % How the document is shown in PDF viewers (optional).
    linkbordercolor = {Melon},                % The color of the borders of boxes around hyperlinks (optional).
    pdfauthor       = {\authorname},          % The author's name in the document properties (optional).
    pdftitle        = {\thesistitle},         % The document's title in the document properties (optional).
    pdfsubject      = {LLMs in \acs{HR}},              % The document's subject in the document properties (optional).
    pdfkeywords     = {Machine Learning, \acs{HR}, Human Resources, \acs{AI}, LLM} % The document's keywords in the document properties (optional).
}

\setpnumwidth{2.5em}        % Avoid overfull hboxes in the table of contents (see memoir manual).
\setsecnumdepth{subsection} % Enumerate subsections.

\nonzeroparskip             % Create space between paragraphs (optional).
\setlength{\parindent}{0pt} % Remove paragraph indentation (optional).

\makeindex      % Use an optional index.
\makeglossaries % Use an optional glossary.
%\glstocfalse   % Remove the glossaries from the table of contents.

% Set persons with four arguments:
%  {title before name}{name}{title after name}{gender}
%  where both titles are optional (i.e., can be given as empty brackets {}).
\setauthor{Ing. Dipl.-Ing.}{\authorname}{}{male}
\setadvisor{Mag. Dr.}{Alexander Pfeiffer}{MBA MA}{male}

% For bachelor and master theses:
\setfirstassistant{}{Michaela Wawra}{MSc}{female}
% \setsecondassistant{Pretitle}{Forename Surname}{Posttitle}{male}
% \setthirdassistant{Pretitle}{Forename Surname}{Posttitle}{male}

% For dissertations:
% \setfirstreviewer{Pretitle}{Forename Surname}{Posttitle}{male}
% \setsecondreviewer{Pretitle}{Forename Surname}{Posttitle}{male}

% For dissertations at the Ph.D. School and optionally for dissertations:
% \setsecondadvisor{Pretitle}{Forename Surname}{Posttitle}{male} % Comment to remove.

\definecolor{delim}{RGB}{20,105,176}
\definecolor{numb}{RGB}{106, 109, 32}
\definecolor{string}{rgb}{0.64,0.08,0.08}

\lstdefinelanguage{json}{
    inputencoding=utf8,
    extendedchars=true,
    numbers=left,
    numberstyle=\small,
    frame=single,
    rulecolor=\color{black},
    showspaces=false,
    showtabs=false,
    breaklines=true,
    postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{gray}\hookrightarrow\space}},
    breakatwhitespace=true,
    basicstyle=\ttfamily\small,
    upquote=true,
    morestring=[b]",
    stringstyle=\color{string},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

\newcommand{\json}[2]{
    \lstinputlisting[language=json,label=lst:#1,caption=#2]{../generated_jsons/#1.json}
}

\newcolumntype{?}{>{\global\let\currentrowstyle\relax}}
\newcolumntype{^}{>{\currentrowstyle}}
\newcommand{\rowstyle}[1]{\gdef\currentrowstyle{#1}#1\ignorespaces}

\makeatletter
\csvset{
    options/.style={
        after head=\csv@pretable\begin{tabular}{|?l|*{\csv@columncount}{^c|}}
                                    \csv@tablehead,
                                    table head=\hline \rowstyle{\bfseries}\csvlinetotablerow \\\hline\hline \rowstyle{},
                                    late after line=                                         \\\hline,
                                    table foot=                                              \\\hline,
                                    late after last line=\csv@tablefoot
        \end{tabular}\csv@posttable,
        command=\csvlinetotablerow,
        respect all=true},
}
\makeatother

\newcommand{\csv}[3]{
    \begin{table}[H]
        \centering{}
        \resizebox{#3\linewidth}{!}{\csvautotabular[options]{../generated_tables/#1.csv}}
        \caption{#2}
        \label{tab:#1}
    \end{table}
}

% Required data.
\setregnumber{01614466}
\setauthorbirthdate{19.03.1998}
\setauthorbirthplace{Mistelbach}
\setdate{01}{04}{2024} % Set date with 3 arguments: {day}{month}{year}.
\settitle{\thesistitle}{\thesistitle} % Sets English and German versions of the title (both can be English or German). If your title contains commas, enclose it with additional curvy brackets (i.e., {{your title}}) or define it as a macro as done with \thesistitle.
\setsubtitle{}{} % Sets English and German versions of the subtitle (both can be English or German).

% Select the thesis type: bachelor / master / doctor.
% Bachelor:
% \setthesis{bachelor}
%
% Master:
\setthesis{master}
\setmasterdegree{master} % dipl. / rer.nat. / rer.soc.oec. / master
%
% Doctor:
%\setthesis{doctor}
%\setdoctordegree{rer.soc.oec.}% rer.nat. / techn. / rer.soc.oec.

% For bachelor and master:
\setcurriculum{Master in Business Administration}{Master in Business Administration} % Sets the English and German name of the curriculum.

% Optional reviewer data:
\setfirstreviewerdata{Affiliation, Country}
\setsecondreviewerdata{Affiliation, Country}

% Add glossary entries.
\newglossaryentry{LLM}
{
    name=Large Language Model,
    description={A Large Language Model is reading and emitting text, enabling it to perform tasks such as translation, summarization, and question answering}
}
\newglossaryentry{TTH}
{
    name=time-to-hire,
    description={The time from the receiving of the candidate's application to the accepted job offer}
}
\newglossaryentry{TAPJFNN}{
    name=Topic-Based Ability-Aware Person-Job Fit Neural Network,
    description={This framework based on the Recurrent Neural Network architecture for predicting person-job fit was introduced in \textcite{pj_fit_ml}}
}

% define style for Javascript scripts
\lstdefinelanguage{TypeScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}
\lstset{
  inputencoding=utf8,
  extendedchars=true,
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
  captionpos=b,
}

\begin{document}

\frontmatter % Switches to Roman numbering.
% The structure of the thesis has to conform to the guidelines at
%  https://informatics.tuwien.ac.at/study-services

% \addtitlepage{naustrian} % German title page.
\addstatementpage
\addtitlepage{english} % English title page.

% citation tutorial
% cite only page 1
% \parencite[1]{discrimination_algorithms} \newline
% cite pages 2 to 5
% \parencite[2-5]{discrimination_algorithms} \newline
% cite page 3 and the following page
% \parencite[3f]{discrimination_algorithms} \newline
% cite page 3 and the following pages
% \parencite[3ff]{discrimination_algorithms} \newline

\begin{acknowledgements}
I must thank Dr. Alexander Pfeiffer and his assistant, Michaela Wawra, MSc, for their guidance and support in writing this thesis.
Mr. Pfeiffer made the technical and social hybrid master thesis topic possible, always had an open ear, and provided valuable advice when problems arose.
Ms. Wawra was always available for questions, caught formal errors, and gave valuable and quick feedback to improve the thesis's structure and content.
Furthermore, the thesis was only possible with the five participating excellent human recruiters from five companies who provided valuable feedback and insights into their daily business. I want to thank Mr. Pfeiffer and the five recruiters for taking their time for the two interviews and the ranking and categorization task.
\end{acknowledgements}

% Use an optional list of figures.
\listoffigures % Starred version, i.e., \listoffigures*, removes the toc entry.
\cleardoublepage

% Use an optional list of tables.
\listoftables % Starred version, i.e., \listoftables*, removes the toc entry.
\cleardoublepage

\chapter{List of Abbreviations}
% Add acronym entries.
\begin{acronym}
    \acro{AI}{Artificial Intelligence}
    \acro{ATS}{Applicant Tracking System}
    \acro{CV}{Curriculum Vitae}
    \acro{EU AI Act}{European Union Artificial Intelligence Act}
    \acro{GDPR}{General Data Protection Regulation}
    \acro{LIWC}{Linguistic Inquiry and Word Count}
    \acro{HR}{Human Resources}
    \acro{NLP}{Natural Language Processing}
    \acro{SaaS}{Software as a Service}
\end{acronym}
\cleardoublepage

% Select the language of the thesis, e.g., english or naustrian.
\selectlanguage{english}

% Add a table of contents (toc).
\tableofcontents % Starred version, i.e., \tableofcontents*, removes the self-entry.

\chapter{Executive Summary}
The recruitment process has evolved significantly with the advent of digital technologies, leading to an increase in the volume of applications and the complexity of screening processes. More and more \acs{AI} technologies are deployed in \acs{HR} to counteract this phenomenon and to further increase \acs{HR} process throughput, especially in the screening task. Most available \acs{AI} tools either are costly, need large amounts of historical training data, or work as black boxes with no obvious transparently made decision. This thesis tries to tackle these problems by using \gls{LLM}s, which are trained on extensive text corpora, and therefore offer a promising solution to enhance the screening task efficiency by automating the categorization (promising and non-promising category) and ranking of candidate applications. This thesis investigates the potential of \gls{LLM}s to improve recruitment efficiency by automating the screening task of job applications consisting only of a \acs{CV}. The developed, proposed model leveraged an \gls{LLM} to extract job requirements from job descriptions and match them against candidate \acs{CV}s, generating a total suitability score from $0$ to $100$ as well as a categorization as promising or non-promising for each candidate. The individual job requirements are matched in isolation and are assigned a score from $0$ to $100$ and a textual explanation for that score. That makes the matching procedure transparent and understandable from a human perspective.
Furthermore, the individual requirement scores are accumulated using an understandable and configurable weighting for each of the $12$ defined job requirement types. The big picture with the matched requirements is used to categorize the applicant as promising or non-promising, and this includes a textual explanation for this decision. The whole model is designed to be very configurable and \gls{LLM} independent, which means any major \gls{LLM} provider can be used. A qualitative study involved five human expert recruiters to analyze the past, present, and expected future state of \acs{AI} in \acs{HR} and to get requirements and possible future improvements for the proposed model. Moreover, a quantitative study was also conducted to compare the model's screening task outcomes with traditional human screening, focusing on similarity and time and cost savings. The model demonstrated strong indications of similarity to human experts in matching candidates to job descriptions, with distance and correlation scores suggesting that the model's results are indistinguishable from the human recruiter results. The similarity of the categorization task was determined via the Hamming distance, and the similarity of the ranking task was determined using Kendall's Tau correlation coefficient. The downside of this result is that the overall Kendall's Tau correlation coefficient between the human recruiter and the other results was low at about $0.2$, and the respective Hamming distance with a distance of about $3$ was relatively high for the same case. That means that to better statistically support the claims made, the sample size needs to be vastly increased. As stated above, the model also provided transparent decision-making processes and detailed explanations for its categorizations and requirement matching scores, enhancing trust in this automated screening technique. Time savings due to model usage were around $95\%$, and the cost to match a single applicant was around $0.27\$$, with the time savings percentage expected to go up and the cost significantly down.
The proposed model currently uses the \textit{GPT-4 Turbo} model from \textit{OpenAI} to match the applicants. By switching this model with the \textit{GPT-3.5 Turbo} model from \textit{OpenAI}, the cost per applicant can be brought down to $0.013\$$ by simultaneously increasing the time-saving percentage. This presumable leads to less accurate matchings, but the degree of which may be explored in follow-up work. The human expert recruiters suggested only using the categorization aspect of the model as assistive tooling. This decision was made as the \acs{CV} does not offer enough information to rank applicants with enough validity to be helpful in their opinion. Future work should explore the proposed model improvements and maybe include original ideas on further improving this model. The model implementation is provided as open-source code on \textit{GitHub} at the URL \url{https://github.com/Oidlichtnwoada/hrGPT}.

\cleardoublepage

\begin{abstract}
The recruitment process has evolved significantly with the advent of digital technologies, leading to an increase in the volume of applications and the complexity of screening processes. \gls{LLM}s, trained on extensive text corpora, offer a promising solution to enhance screening task efficiency by automating the categorization (promising and non-promising category) and ranking of candidate applications. This thesis investigates the potential of \gls{LLM}s to improve recruitment efficiency by automating the screening task of job applications consisting only of a \acs{CV}. The developed, proposed model leveraged an \gls{LLM} to extract job requirements from job descriptions and match them against candidate \acs{CV}s, generating a total suitability score from $0$ to $100$ as well as a categorization as promising or non-promising for each candidate. A qualitative and quantitative study was conducted involving five human expert recruiters to analyze the past, present, and expected future state of \acs{AI} in \acs{HR} and to compare the model's screening task outcomes with traditional human screening, focusing on similarity and time and cost savings. The model demonstrated strong indications of similarity to human experts in matching candidates to job descriptions, with distance and correlation scores suggesting that the model's results are indistinguishable from the human recruiter results. The model also provided transparent decision-making processes and detailed explanations for its categorizations and requirement matching scores, enhancing trust in this automated screening technique. Time savings due to model usage were around $95\%$, and the cost to match a single applicant was around $0.27\$$, with the time savings percentage expected to go up and the cost significantly down. The human expert recruiters suggested only using the categorization aspect of the model as assistive tooling. Future work should explore the proposed model improvements and the model's accuracy with more statistical support by vastly improving the sample size. The model implementation is provided as open-source code on \textit{GitHub} at the URL \url{https://github.com/Oidlichtnwoada/hrGPT}.
\end{abstract}

% Switch to Arabic numbering and start the enumeration of chapters in the table of contents.
\mainmatter

\chapter{Introduction} \label{introduction}

\section{Problem Statement} \label{problem_statement}
This section gives an overview of how the evolution of digital recruiting has led to many more candidates applying to each job offer \parencite[4]{ai_recruiting}.
It also discusses that the usage of \acs{AI}-enabled tools in human resources is increasing and that mostly larger companies can afford to use these tools or have the required amount of historic recruiting data to calibrate them.
This leads to productivity gains and cost reductions in the human resources department of larger companies, which may be necessary to cope with an increasing number of applicants.
To bring a part of this efficiency gain to smaller companies, this thesis aims to implement an open-source \acs{AI}-enabled tool that can screen applicants for a job offer by using \gls{LLM}s.
This has the advantage of manageable costs and eliminates the need for historic recruiting data to calibrate the tool as \gls{LLM}s are trained on and have knowledge of a vast corpus of text.
The full version of the problem statement is given below.

The problem statement elaboration relies heavily on the article \textcite{ai_recruiting}, which is based on over $50$ research papers in that field and concisely describes the evolution of recruiting.
As described in \textcite[1]{ai_recruiting}, the average firm's value by 2000 comprised roughly 65\% of value from intangible assets.
This has evolved a lot, as by the end of 1980, around 70 to 90\% of tangible assets were accountable for the average firm's value \parencite[1]{ai_recruiting}.
This means that a firm's value is increasingly dependent on the quality of its employees and the knowledge they possess, and this ongoing process does not seem to halt soon.
The technological context of how companies recruit people has also evolved a lot over the last decades, as machine learning tools are more and more used to automate processes or assist humans in attracting suitable candidates, screening, assessing, and selecting them \parencite[2]{ai_recruiting}.
The article \textcite[2-4]{ai_recruiting} described four evolution stages of recruiting, which are the following:
\begin{enumerate}
    \item \textbf{Analog Recruiting} \label{analog_recruiting}\\
    The first stage is analog recruiting, where people are the primary mechanism of recruiting new employees.
    Prospective applicants must go to the company to manually submit a paper job application.
    Companies want to maximize the richness and reach of the information they supply about the current job vacancy to attract as many promising applicants as possible.
    But as described in \textcite[2]{ai_recruiting}, in analog recruiting, these two goals faced the analog reach and richness frontier as shown in \ref{fig:analog_reach_richness_frontier} because the more information is supplied, the more costly it is when you supply to media with great reach at that time:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5,page=2,width=0.6\linewidth,trim={300 100 55 515},clip]{literature/ai_recruiting.pdf}
        \caption{Analog reach and richness frontier \parencite[2]{ai_recruiting}}
        \label{fig:analog_reach_richness_frontier}
    \end{figure}
    \item \textbf{Digital Recruiting 1.0} \label{digital_recruiting_1}\\
    This first evolution stage of digital recruiting in the late 1990s was characterized by breaking the analog reach and richness frontier by using digital media, which allowed the supply of rich information to many prospective candidates at a meager cost because there were no printing and low distribution costs.
    There was also a change on the applicant's side as no more manually filled-out documents were required to be handed in physically at the company site.
    It also allowed them to filter out job offers based on various selectors, and it also allowed companies to offer more dynamic content to job seekers by adding video and audio data to the job search websites.
    A considerable exponential and self-enforcing network effect was also ongoing for job search websites \parencite[3]{ai_recruiting}.
    As they listed more job offers, more job seekers were attracted to the platform, which made it easier to persuade companies to list their job offers on job search websites.
    \item \textbf{Digital Recruiting 2.0} \label{digital_recruiting_2}\\
    This evolution emerged around ten years after the first evolution of digital recruiting and was mainly driven by two developments.
    The first development was the rise of job board aggregation services that presented all job offers from various job search websites on one platform.
    Job seekers can now access all available job offers without visiting each platform individually. Job firms do not need to publish their offers on each website.
    The second development was the introduction and rise of professional social network platforms such as \textit{LinkedIn}.
    These network platforms allowed people to form professional communities and groups of interest and also allowed companies to present themselves to the public and potential applicants.
    Moreover, with endorsements, people on such platforms could endorse the skills of others, which allowed them to build a reputation and trust in the community.
    It enabled companies to target their job ads more effectively to promising candidates, contact candidates directly through the network, and also helped a cheap and efficient way to post job offers on large social websites, whether they are professional or not, like \textit{Facebook} \parencite[3]{ai_recruiting}.
    \item \textbf{Digital Recruiting 3.0} \label{digital_recruiting_3}\\
    After Digital Recruiting matured from 2010 to 2015, Digital Recruiting 3.0 emerged and was primarily driven by the rise of machine learning and artificial intelligence in human resources processes.
    As digital recruiting digitized the processes and made them more frictionless for employers and employees, more and more applications came in for each job offer. On average, the number is around 250 applications per job offer \parencite[4]{ai_recruiting}.
    This can be explained by the fact that the application cost is meager for the applicant, but this led to about 80\% of the applications being unqualified \parencite[4]{ai_recruiting}.
    To deal with this massive number of applicants, you can deploy more human resources to screen the applications, use machine learning to automate processes or assist humans in working more productively.
    Human resources are mission-critical for companies as human capital is increasingly critical for success.
    Moreover, research showed that top performers are four to eight times more productive than the average performers, increasingly so in complex environments, according to \textcite[4]{ai_recruiting}.
    Furthermore, this new evolution stage of recruiting also has its downsides, as discussed in \textcite[4-5]{challenges_opportunities_hr} due to the emerging use of technology:
    \begin{itemize}
        \item It was stated that using technology in human resources typically leads to more efficiency and decreasing costs associated with human resources transactions. However, some researchers argue that there is no considerable effect on the primary goal of human resources to attract, motivate, and maintain talented employees.
        \item Furthermore, it is argued that the technologies are often static and one-way communication systems that do not allow either side of the recruiting process to ask questions. This may entail creating an artificial distance between the applicant and the people doing the recruitment tasks. The technologies of the future, which are already here, can partially mitigate those drawbacks.
        \item The article also discussed that if the tasks of complete human resource departments are transferred to other employees and managers, this may hurt the overall productivity of organizations. This also means that if the administrative burden for the human resource department is reduced, it can also contribute to the strategic direction of organizations.
    \end{itemize}
    More consideration on the use of \acs{AI}-assisted technologies regarding recruiting are presented here \parencite[2-4]{ai_in_hr_management}:
    \begin{itemize}
        \item Algorithms that helped filter applicants and were trained with imitation learning are often trained with biased data. As these algorithms try to map input attributes or features to desirable outputs like job performance present in the training data sets, they keep the bias from past recruiting activities, such as hiring fewer women in top management positions in favor of men. Also, \textit{Amazon} had this bias problem in their hiring algorithm, which is an alarming sign for using \acs{AI} in human resources due to legal considerations and violations of social norms.
        \item Furthermore, as applicants discover the biases of the used algorithms or traits they will like, they may increasingly artificially craft application documents to meet the algorithm's expectations.
        \item The article also discussed that it is hard to define what a \textit{good employee} is. Most sources describe an excellent employee based on performance appraisal scores. Still, those are very hard to measure as any reasonably complex job is interdependent with other jobs, making it very hard to disentangle individual performance from group performance. The performance metrics are often criticized for a lack of validity and reliability while having a considerable bias. Therefore, it is challenging and nearly impossible to achieve precisely this behavior of selecting high-performant applicants with imitation learning and unsuitable training data.
        \item Algorithms based on imitation learning require large amounts of past data, and important events like dismissals may be sparse in the training data.
        \item Moreover, algorithms are not liable for their decisions, even though hiring activities greatly affect the organization's dynamics. Most algorithms in use today cannot explain what attributes have driven the final decision.
    \end{itemize}
\end{enumerate}
This should have made the need for an effective human resources pipeline clear. To improve this pipeline, machine learning tools are deployed to the following four fields \parencite[4-8]{ai_recruiting}:
\begin{enumerate}
    \item \textbf{Outreach}\\
    Firms try to identify candidates and get job opportunities in front of them in a way that invites them to apply. Machine learning can help refine the job description in ways that attract more applicants or bring more balance to the gender of the applicants. As there are more passive candidates not actively searching for a job than actively searching candidates, machine learning can identify suitable talents from a massive pool of candidates, e.g., hundreds of millions of \textit{LinkedIn} users.
    \item \textbf{Screening}\\
    This stage should pre-filter the applicants to keep only the most promising ones for the following assessment stage.
    As stated in \textcite[6]{ai_recruiting}, machine learning tools were at least 25\% superior to humans even when they had a reasonable amount of time to screen the application. Furthermore, the \acs{AI}-enabled screening tool provider \textit{Ideal} says that with its technology, the average \gls{TTH} fell from 24 days to 9 days.
    Moreover, \textit{L'Oréal} reported a drop of screening time per resume from 40 minutes to 4 minutes, and \textit{Hilton Hotels \& Resorts} reported a decline of \gls{TTH} from 42 days to 5 days by incorporating \acs{AI} tools in the recruitment process.
    \item \textbf{Assessment}\\
    The assessments typically involve one to many rounds of evaluation to determine the most suitable candidates who will receive a job offer. Recent research showed that gamification with short games is increasingly used to measure candidates' personality traits, like risk aversion. Companies like \textit{Unilever} and \textit{L'Oréal} used \acs{AI}-chatbots that asked various questions, and applicants were able to record video responses in the \textit{Unilever} case and chat response in the case of \textit{L'Oréal}. The \acs{AI} systems analyzed the content, the word choice, and the used structure and matched the responses against successful employees in that field. In the case of video content, the system can also analyze the tone of the voice and the micro-facial movements. These two chatbots could be filled with information at any time within the given timeframe, reducing scheduling times with candidates and offering candidates more freedom to answer the questions at a time that suits them best. These chatbots can also be used to fill in missing information from job seekers, like potential start dates, and answer questions regarding the salary range.
    \item \textbf{Coordination}\\
    This task involves coordinating with the applicants, which requires appointment scheduling and cancellation. In the age of digital recruitment, more and more candidates are rejected. Therefore, you need to convey this information to all of your applicants, as little to no information regarding the process is the main driver for bad experiences with the application process. Machine learning tools can help to achieve that.
\end{enumerate}
By 2018, only around 40\% had used machine learning tools in these four core human resource sourcing processes \parencite[4]{ai_recruiting}.
The cost to implement, integrate, and maintain \acs{AI} tools in human resources is high, may need large amounts of historic recruitment data, and most companies should use services from external providers if they do not have massive amounts of hires to amortize these costs \parencite[8]{ai_recruiting}.
This circumstance makes \acs{AI} tools less affordable for smaller companies.
Furthermore, suppose the \acs{AI} tools are not used as assistive technology but as a technology to replace humans in the human resource sector. In that case, the acceptance of these technologies within this sector is relatively low \parencite[9]{ai_recruiting}.
Moreover, around 70\% of large organization change initiatives, including digital transformations, fail.

This thesis tries to implement a new open-source tool in screening to bring part of the productivity gains of \acs{AI}-enabled tools to human resources workers in companies of any size.
As \gls{LLM}s are capable of summarization and question-answering when they are presented with natural text as input within their context length, the problem statement to solve now is to match a provided \acs{CV} from an applicant to the applied job description and assign this match a score with the help of prompting the \gls{LLM}s.
Furthermore, the model should also categorize the applicants as promising or not by prompting the \gls{LLM}.
The score should represent the candidate's suitability for the job description and enable ordering, while the promising flag is needed to quickly filter out unsuitable candidates.
This approach should result in manageable costs for the company and does not require historic recruitment data to calibrate the model as the \gls{LLM}s have inherent knowledge.

\section{Significance of the Work} \label{significance_of_the_work}
The advantages of Digital Recruiting 3.0 should be available to all companies and not just to big corporations or as paid services from external providers.
Machine learning tools should also not have the precondition of having massive datasets to train and use the models.
Using the model should bring efficiency benefits without using it often to amortize costs, making it perfectly viable for small companies.
The effects and the significance of using \acs{AI}-enabled technologies in human resource management have been discussed in detail in \textcite{ai_hrm_review} by reviewing $45$ articles in that field and covering the following main points:
\begin{itemize}
    \item The article describes a disruptive (future) transformation from electronic human resource management systems to systems defined by intelligent automation. The ongoing digitization of information was an enabler for this transformation \cite[4]{ai_hrm_review}.
    \item It is also discussed that automatic matching of candidates to jobs reduces costs and the need for \acs{HR} professionals to have domain knowledge for a particular professional field \cite[10]{ai_hrm_review}.
    \item Furthermore, as automated tools eliminate distance constraints, there is an increasing risk of lacking direct contact between people, which may hide lurking problems. Therefore, they propose to use the \acs{AI} tools as assistive technologies \cite[12]{ai_hrm_review}.
    \item There is also a theory presented that \acs{AI} will not replace human workplaces on the job level from the start but rather on the task level, so more straightforward tasks will be automated first, and more complex tasks will be automated later \cite[12]{ai_hrm_review}. For example, simple question-answering or administrative work can already be executed by voice assistants like \textit{Siri} without having human employees as representatives at physical locations.
    \item \acs{AI}-based application could significantly improve employee training or applicant assessing because they can be used to simulate real-world scenarios with supported interactivity within a safe environment \cite[13]{ai_hrm_review}. In the future, the automated screening procedure in the proposed thesis model can also be amended with feedback from the applicant to further clarify skills that are a missing education requirement, for example.
    \item The article \parencite[14]{ai_hrm_review} also highlights the importance of explanations from \acs{AI} systems on decisions they have made for a human to understand the automated decision. This feature was also integrated into the model proposed by this thesis.
    \item The proposed model of this thesis is based on \gls{LLM} models with fixed training sets that only contain information up to a certain point in time. Still, the article \textcite[13]{ai_hrm_review} emphasizes the importance of an up-to-date model that was trained or had access to real-time data, even if this means continuous readjustments to the model.
\end{itemize}


\section{Research Objective and Research Question} \label{research_objective_and_research_question}
The research aims to supply the proposed reasonably accurate screening tool based on \gls{LLM}s outlined in \ref{problem_statement} as open-source software to the public.
That means companies of any size can integrate this tool into their human capital sourcing pipelines to increase efficiency and decrease costs eventually.
As outlined in the previous chapters, people working in human resources have to screen more and more resumes or \acs{CV}s as the reach of online job advertisements attracts many applicants.
It was also discussed that many of these applicants were not qualified for the advertised job and should not be assessed further.
This pre-filtering saves costly human resources and makes it easier to invest the most time and effort into the most promising candidates, given that you have an easy and cheap way to screen the application documents.
With the rise of \gls{LLM}s capable of summarization and question answering, the idea was born to use these capabilities and apply them to the screening task in human resources.
\\\\
The research question is:\\
\textit{How might an \gls{LLM}-based screening model affect the screening process?}\\\\
This formulation entails subordinate research questions, which are shown in the following enumeration:
\begin{itemize}
    \item \textit{What is the accuracy of the proposed model?}\\
    This question will be answered by testing the model's outputs' accuracy against human expert recruiters' annotations.
    This procedure is described in detail in \ref{quantitative_research_design}.
    \item \textit{What time savings are associated with the model usage?}\\
    This question will be answered by measuring the time the human experts took to execute the data mentioned above annotation.
    This time will be compared to the model's time to automate the same tasks.
\end{itemize}

\section{Research Methodology} \label{research_methodology}
This thesis uses a hybrid approach (qualitative research design \ref{qualitative_research_design} and quantitative research design \ref{quantitative_research_design}) to answer the research question.
In the quantitative context, the accuracy of the proposed model will be measured, and the time savings associated with the model usage will be calculated by comparing the model's statistics against the results from human expert recruiters.

Literature research is carried out first as a methodology for preparing this Master's thesis and substantiating the statements.
Only qualitative literature, publications, papers, and scientific articles in journals and books from various online libraries were used as information sources.
Also, some internet sources have been used to link the reader directly to the respective source without relying on a search engine.
This literature review should provide a theoretical basis on whether the use of \gls{LLM}s may be a good fit for the screening task and how other researchers have approached the person-environment fit quantization problem from a technical perspective.
Furthermore, it should also provide theory on person-environment fit and list considerations on and chances of using \acs{AI}-assisted tools in the human resources domain.
Moreover, a guideline interview in a group discussion setting collects qualitative information from the five participating human expert recruiters on their considerations, expectations, and past experiences with \acs{AI}-assisted tools.
In this empirical part, these experts will also be interviewed about the results of the implemented proposed model, and all participating experts will have at least five years of professional experience in this domain.
The transcribed interview will be analyzed and coded by a qualitative content analysis with inductive category formation according to \textit{Mayring} \parencite{mayring}.
This analysis should generate hypotheses and derive strengths and weaknesses of the proposed model, which will be presented using a \textit{SWOT} analysis.
This should answer a part of the research question that covers how and in what way an \gls{LLM}-based model would affect the screening process.
This entails the expected baseline performance for the model and considerations of the model usage.

All quantitative information regarding the proposed and implemented \gls{LLM}-based model is obtained from an experiment conducted especially for this thesis for trustworthiness, validity, and quality.
This experiment compares the proposed model's applicant ranking and filtering capabilities against those of human expert recruiters, tracking the experts' time usage.
The numeric results will be submitted using an online form to double-check the data, and then this data will be statistically analyzed.
This statistical analysis should answer the research question, especially the two quantitative subordinate research questions.

\section{Structure of the Work} \label{structure_of_the_work}
This thesis starts with the introduction chapter \ref{introduction} which gives an overview of the problem statement \ref{problem_statement}, the significance of the work \ref{significance_of_the_work}, the research objective and research question \ref{research_objective_and_research_question}, the research methodology \ref{research_methodology} and the structure of the work \ref{structure_of_the_work}.
The second chapter \ref{theoretical_background} gives an overview of the theoretical background of the work, including revisiting \gls{LLM}s and their broad application field and then discussing literature on person-environment fit and technical methods to quantize this fit.
This chapter also discusses the considerations and chances that come with the use of \acs{AI}-assisted tools in the human resources domain.
Afterward, the methodology chapter \ref{methodology} describes what research methods have been used, including how the results have been obtained, how the sample screening documents were created, and how the model has been designed and implemented.
The data chapter \ref{data} describes the data that has been sourced with qualitative and quantitative methods, which is then analyzed in the analysis chapter \ref{analysis}.
The retrieved insights are then discussed and interpreted in the discussion and conclusion chapter \ref{discussion_and_conclusion}.
\chapter{Theoretical Background} \label{theoretical_background}

\section{Large Language Models}
The machine learning model type \gls{LLM} is commonly abbreviated as \gls{LLM} and makes natural language texts processable for computers.
The model works by compressing the read text into an internal state, and based on this state, an output text is generated.
As the model compresses the data according to the learned patterns in the training data, it does not understand the text the same way humans do.
These models perform tasks such as translation, summarization, and question answering \parencite[1]{llm_literature_review}.
As this enabled a wide field of automation for applications that humans primarily carried out, many technology companies have developed their own \gls{LLM} and made their services available to the public while keeping their source code private.
Some notable examples are the \textit{Gemini} model family by \textit{Google} \parencite{gemini}, the \textit{GPT-4} model by \textit{OpenAI} \parencite{gpt4} and the \textit{LLAMA 2} model family by \textit{Meta} \parencite{llama2}.
The models of the \textit{LLAMA 2} model family are the only models from the picked three candidate groups that have been released with public source code.
That means that researchers and engineers worldwide can use the model as a building block, improve the underlying mechanisms, or try to incorporate it into their applications.
The real breakthrough of \gls{LLM}s came with the release of the \textit{GPT-3} model by \textit{OpenAI} \parencite{gpt3} that powered the initial version of \textit{ChatGPT}.
They offered the model's capabilities as a website accessible to the public and allowed users to insert text and receive a response from the model.
As described in \textcite[1]{gpt3}, the model provided excellent performance on various \acs{NLP} datasets that include tasks like translation and question answering.
To briefly visualize the complexity behind an \gls{LLM}, consider the function $f_{a,b,c}(x) = ax^2+bx+c$ that has the three parameters $a$, $b$ and $c$.
Here, the function $f$ maps the input data denoted as $x$ to the output data denoted as $f(x)$.
The input data in the \acs{NLP} case is the input text, and the output data is the output text.
\gls{LLM}s also use parameterized and differentiable functions in their internal structure to map the input text to the output text. Still, they have orders of magnitudes more parameters than this sample function.
For example, the model \textit{GPT-3} uses 175 billion parameters \parencite[1]{gpt3} in total. The parameter count of \textit{GPT-4} was not disclosed in their technical report \parencite{gpt4}.
The training data needed to train these models was present in the required amounts because the researchers have not used reinforcement learning \parencite{rl_bible} or supervised learning \parencite[3]{sl_bible}.
Reinforcement learning gives the model a reward when an action is good and a punishment when an action is wrong. This can be done by letting the model train in the real world, which has terrible scalability, or in simulators that must be coded to mimic the real world, which is also challenging and time-consuming.
For example, animals learn that behaviors that lead to food are good and behaviors that lead to hunger are bad.
The supervised learning approach labels input data with the desired output label. Based on these mappings and a vast number of training samples, the model adjusts its parameters to map the input data correctly.
An example would be input images labeled with the object that can be seen in the pictures. So, each input image must be labeled by hand before the model can be trained to predict itself correctly.
To compress the patterns in the training data and fill them into the model parameters, vast amounts of training data are needed as the parameter count of \gls{LLM}s is enormous.
Both techniques were insufficient to train models of that sheer size, so the researchers used a method called self-supervised learning \parencite[7]{llm_literature_review} where the model tries to fill in artificially generated gaps in the text.
Because the gaps are artificially introduced, the expected output is known in advance, so the model can be trained without the need for labeled training data, which makes this technique very scalable.
Before the text is fed to the model, it is tokenized \parencite[4]{llm_literature_review}, which means the text is converted into a sequence of tokens, which can either be symbols, characters, subwords, and words.
The model gets the tokenized text input and predicts the follow-up output tokens that will likely follow these input tokens. The output tokens are converted back into text, and then the text from the artificial gap is compared to the model output.
Based on this comparison, the model parameters are adjusted. As no human data labeling or costly real-world or simulator training is needed, the model can be trained on vast amounts of data.
Most text data for training large language models is scraped from the internet \parencite[1]{llm_literature_review}.
The context size of a \gls{LLM} is the number of tokens the model can store in its internal state while generating the output tokens, so it is the history of tokens it can access while generating the response.
For example, the context size of the \textit{LLAMA 2} model is 4096 tokens \parencite[47]{llama2}.
The tokenizer that \textit{OpenAI} is using can be accessed via this website \textcite{openai_tokenizer}.
The output tokens of a \gls{LLM} are generated token by token, so when the first token is generated, it is appended to the input, and the model generates the next token based on the input that now contains the first generated token. Afterward, it is run iteratively in the same way.
That means that the total output token size is also constrained by the context size, even though the entire history of tokens should be within the context size while generating the output.
The model stops the output loop when the model emits the stop token. That means that it has finished the output token generation.
Most \gls{LLM}s are based on the machine learning model type called Transformers \parencite[1]{transformer}, which is a neural network architecture that is based on the attention mechanism.

\subsection{MMLU (Massive Multitask Language Understanding) Test}
As \gls{LLM}s are trained on vast amounts of text data, they have knowledge of various represented domains within that data, which can be assessed by the recently introduced \textit{MMLU} test \parencite{mmlu}.
This massive multitask language understanding (\textit{MMLU}) test consists of $14079$ multiple-choice test questions from various branches of knowledge that cover $57$ tasks including mathematics, history, and law, each represented with at least $100$ test questions \parencite[1-3]{mmlu}.
The final result is given in percentage of correct questions, and the authors estimated that human expert-level performance is approximately $89.8\%$.
If an \gls{LLM} scores higher than the human expert-level performance, it can perform similarly to human domain experts.
The first \gls{LLM} that broke this human expert-level performance boundary was \textit{Gemini Ultra} with a score of above $90\%$ \parencite[1]{gemini}.
Also, the \textit{GPT-4} model scored quite high with $86.4\%$ on the \textit{MMLU} test \parencite[32]{gpt4}.
The \textit{LLAMA 2} model with $70$ billion parameters scored $68.9\%$ on the \textit{MMLU} test \parencite[49]{llama2}, which is a considerably worse result than the other two models have achieved.
That means all three mentioned models, but especially \textit{Gemini Ultra} and \textit{GPT-4}, have a broad understanding of various knowledge domains.
This may help the proposed model with the help of \gls{LLM}s to accurately match the applicant's \acs{CV} to the job description without supplying the model with historic recruitment data.

\section{Person-Environment Fit}
The person-environment fit can be broken up into the person-organization and the person-job fit.
For this section, many citations are made from the article \textcite{po_and_pj_fit_literature_review} as it is an excellent summary of more than $90$ research papers in this field.
Person-organization fit describes the compatibility between the applicant's and the organization's values and characteristics and how well they meet each other's needs \parencite[179]{po_and_pj_fit_literature_review}.
The person-job fit describes the compatibility between the applicant's abilities and the job's demands or the person's desires and the job's attributes \parencite[179]{po_and_pj_fit_literature_review}.
These two fit measures should both be considered when computing the score.

\subsection{Person-Environment Fit Types} \label{pef_types}
In essence, person-environment fit is a complex and multi-dimensional concept.
It can be conceptualized as both complementary and supplementary.
Supplementary fit happens when a person supplements, embellishes or possesses characteristics similar to others in the environment \parencite[180]{po_and_pj_fit_literature_review}.
Complementary fit happens when a person possesses missing characteristics in the environment, making it more complete \parencite[180]{po_and_pj_fit_literature_review}.
Complementary person-environment fit encompasses the needs-supplies and demands-abilities perspectives.
An environment supplies financial, physical, and psychological resources and task-related, interpersonal, and growth opportunities that the person demands or needs \parencite[180]{po_and_pj_fit_literature_review}.
A needs-supplies fit is achieved when the supply meets the individual's needs.
A demands-abilities fit is achieved when the individual's professional contributions in terms of time, effort, commitment, skills, and knowledge meet the demands of the environment \parencite[180]{po_and_pj_fit_literature_review}.
Person-environment fit can be understood as perceived fit and actual fit.
The interconnections between these types of person-environment fit are visualized in figure \ref{fig:person_environment_fit_types}:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5,page=3,width=0.8\linewidth,trim={55 130 55 470},clip]{literature/po_and_pj_fit_literature_review.pdf}
    \caption{Person-environment fit types \parencite[3]{po_and_pj_fit_literature_review}}
    \label{fig:person_environment_fit_types}
\end{figure}

\subsection{Person-Organization Fit}
Person organization-fit is defined as the compatibility between people and organizations or between an individual and broader organizational attributes and is the key to maintaining a flexible and committed workforce in competitive business environments with probably tight labor markets \parencite[182]{po_and_pj_fit_literature_review}.
The roots of person-organization fit research can be traced to Schneider's Attraction-Selection-Attrition framework, which says that organizations are one particular situation where people are attracted to specific job opportunities, selected to be a part of and remain within the organization as long as they are a good fit \parencite[182]{po_and_pj_fit_literature_review}.
According to \textcite[182]{po_and_pj_fit_literature_review}, person-organization fit can be operationalized in four ways. The following list is ordered from most used to least used operationalization:
\begin{enumerate}
    \item \textbf{Congruence between individual and organizational values}\\
    This operationalization primarily encompasses the supplementary fit perspective that was introduced in section \ref{pef_types}.
    \item \textbf{Goal congruence with organizational leaders and peers}\\
    This operationalization primarily encompasses the supplementary fit perspective that was introduced in section \ref{pef_types}.
    \item \textbf{Match between individual preferences or needs and organizational systems and structures}\\
    This operationalization reflects the needs-supply fit perspective that was introduced in section \ref{pef_types}.
    \item \textbf{Match between the characteristics of individual personality and organizational climate}\\
    Organizational climate is also sometimes labeled as organizational personality.
    As the organizational climate is often operationalized in terms of corporate supplies (like communication patterns and reward systems), this operationalization also reflects the needs-supply and the supplementary fit perspectives introduced in section \ref{pef_types}.
\end{enumerate}
Empirical evidence has shown that a high level of person-organization fit is associated with higher job satisfaction, organizational commitment, self-reported teamwork, and objective measures for work performance \parencite[183]{po_and_pj_fit_literature_review}.
A high person-organization fit is associated with lower turnover intentions and actual turnover. However, some researchers have also pointed out that a high level of person-organization fit may have negative organizational outcomes \parencite[183]{po_and_pj_fit_literature_review}.

\subsection{Person-Job Fit}
The concept of person-job fit is the traditional foundation for employee selection, and the primary concern has been finding the applicants with skills and abilities necessary to do the job \parencite[183]{po_and_pj_fit_literature_review}.
This encompasses the demands-abilities fit perspective that was introduced in section \ref{pef_types}.
Person-job fit can be assessed by determining the job demand through a job analysis, which identifies an employer's essential tasks and uses this knowledge to specify the skills, knowledge, and abilities to complete the job tasks.
Determining person-job fit increasingly gained sophistication by identifying statistically reliable and valid methods to assess the fit between the person and the job \parencite[183]{po_and_pj_fit_literature_review}.
This assessment also received legal support and was merged into the employee selection procedure, and this fit measure can be operationalized in the following way \parencite[183-184]{po_and_pj_fit_literature_review}:
\begin{itemize}
    \item \textbf{Needs-supplies and demands-abilities perspective}\\
    These two perspectives cover the complementary fit concept that was introduced in section \ref{pef_types}.
    The supplementary fit concept does not suit the person-job fit context as this model compares the applicant to other people rather than against the job.
    The needs-supplies perspective includes the individual's desires, such as goals, psychological needs, interests, and values. A job's characteristics and attributes may or may not satisfy those desires.
    The demands-abilities perspective consists of job demands like knowledge, skills, abilities, education, experience, and aptitudes required to carry out the tasks of this job.
\end{itemize}
The strategies to assess the person-job fit include resumes, \acs{CV}s, tests, interviews, and reference checks \parencite[184]{po_and_pj_fit_literature_review}.
The more structured and validated the procedures were, the more effective the employee selection process compared to using unstructured strategies like oral interviews with no guidelines \parencite[184]{po_and_pj_fit_literature_review}.
Moreover, most candidate selection processes of companies have focused on achieving a high person-job fit because this has positive outcomes like job satisfaction, lower stress levels, and higher adjustment, organizational commitment, motivation, performance, attendance, and employee retention \parencite[184]{po_and_pj_fit_literature_review}.

\subsection{Relationship between Person-Organization Fit and Person-Job Fit}
Research showed that the discriminant validity of these two types is given, as empirical studies have shown that the correlation between person-organization and person-job fit, whether perceived or actual, is very low \parencite[185]{po_and_pj_fit_literature_review}.
Using confirmatory factor analysis, it was shown that job recruiters and applicants could distinguish between the two types of fit, but it was also demonstrated that the recruiters' perceived fit, no matter what kind, is influenced by their past experiences in a predictable way \parencite[185]{po_and_pj_fit_literature_review}.
It was also shown that person-organization fit has a more significant favorable influence on employee retention and contextual performance than person-job fit \parencite[185]{po_and_pj_fit_literature_review}.
There can even be a third type called person-group fit, which is like person-organization fit but limited to a specific group within the organization the employee is working with.
Furthermore, these three types of fit uniquely impact various metrics, supporting the previously made claim that they are distinct concepts \parencite[185]{po_and_pj_fit_literature_review}.

\subsection{Person-Environment Fit in Employee Selection}
Research on employee selection can be divided into the following two fields \parencite[185-186]{po_and_pj_fit_literature_review}:
\begin{itemize}
    \item \textbf{Prescriptive approach}\\
    The prescriptive approach focuses on guidelines that describe selecting the right candidate for the job.
    Traditionally, the selection process has been based mainly on the concept of the person-job fit.
    However, the paradigm shifted, and in addition to the task performance of the candidate, the contextual performance of the candidate is also considered, which is mainly influenced by the person-organization fit of the candidate.
    Researchers have argued that selecting employees with a high person-organization fit may be beneficial, as this means unity in values and visions.
    In many industries, static job analysis must be revised as jobs are dynamic and ever-evolving. Therefore, it is better to recruit a flexible workforce capable of teamwork.
    The person-job fit should also focus more on the applicant's cognitive ability. This is justified because most employers hold multiple jobs within a company. Therefore, a more significant focus on general mental ability will lead to more flexible employees.
    To test employees for their person-organization fit, the organization has to define its values and visions beforehand.
    The evaluation can be done using the Q-sort technique.
    In general, the influence of both person-environment fit types is essential in employee selection.
    \item \textbf{Descriptive approach}\\
    The descriptive approach focuses on how these guidelines play out in selection processes.
    Even though traditional selection research focused on the person-job fit, the person-organization fit was already considered in the selection process.
    In most cases, this happened through applicant interviews, which showed surprisingly high validity when assessing person-organization fit.
    Also, the person-job fit was assessed in interviews,
\end{itemize}
If those two concepts diverge, it may be because the research outcomes need to be appropriately communicated or required to be followed in practice.
Furthermore, there can also be some unexplored factors in research that influence the selection process.

\section{Quantizing the Person-Environment Fit}
This section discusses the literature on how the person-environment fit can be quantized from a technical perspective.
This is necessary to understand how the proposed model can be designed and implemented to compute the person-environment fit, as some ideas may be transferrable.
All the presented approaches used either a machine learning model, a text mining or semantical matching approach, or a combination of these approaches to quantify the person-environment fit.
The presented methods all have the common deficiency of manually creating a keyword dictionary or accessing a large dataset of applicant \acs{CV}s and associated job descriptions with past recruitment decisions to train the model.
The usage of \gls{LLM}s in the proposed model may enable to match the job description and the applicant \acs{CV}s on a semantical level with greater context awareness and without the need for manual intervention or past recruitment decision data due to the superior question answering and summarization capabilities of \gls{LLM}s.
Furthermore, as \gls{LLM}s are trained on vast amounts of text data, they also have a broad understanding of quite a few professional fields, which may enable them to understand and match the job description and the applicant \acs{CV}s better than the presented methods.

\subsection{Text Mining Approach} \label{text_mining_approach}
The article \textcite{text_mining_for_automatic_profiling} describes the necessity of automatically filtering candidates due to the probably very high number of applicants when job vacancies are opened using the internet.
Moreover, in this article, the authors have tested their approach using an anonymized dataset of a company's actual applicants consisting of over $40$ resumes in the \textit{PDF} format for each of the three job positions \textit{Data Developer}, \textit{Human Resource and Development} and \textit{Marketing}.
Text mining is getting increasingly popular due to the big data trend that is expanding into many fields and the fact that most companies probably have many unstructured text documents to analyze \parencite[49]{text_mining_for_automatic_profiling}.
Some use cases for text mining are sentiment analysis or classification, article classification, spam or fake news detection, argument extraction, exploring social issues, logs mining, search personalization, article summarization and automatic recommendation systems \parencite[49]{text_mining_for_automatic_profiling}.
The text-processing algorithm can extract skills, education, and experiences from unstructured resumes to summarize each application.
These extracted keywords are matched against a keyword dictionary of each job vacancy that was created based on the terms used in each profession by the human resource department of the company that provided the dataset \parencite[47]{text_mining_for_automatic_profiling}.
This is also called the profile matching process, which compares the applicant's present competencies with the required competencies of the job vacancy and tests the person-job fit regarding the demands-abilities perspective.
It is assumed that the higher the person-job fit, the higher the congruence between the demands and abilities.
This simple matching will not work as expected in all cases since it suffers from the extracted words losing their contextual information and structure, and the model also does not understand the inherent meaning of the words as matching is done solely by equality checks \parencite[517]{applicant_semantic_matching}.
The final ranking was then compared to the company's human resources department ranking, which provided the anonymized resume dataset.
There were two methods used to compare the extracted keywords against the keyword dictionary of each job vacancy \parencite[53-58]{text_mining_for_automatic_profiling}:
\begin{enumerate}
    \item \textbf{Document Vector Analysis}\\
    This analysis used the \textit{KNIME Analytics Platform} for document preprocessing and vectorization.
    The preprocessing steps on the \textit{PDF} documents include punctuation erasure, number filtering, small word removal with an $n$-char filter (removal of words of length smaller or equal to $n$), conversion to lowercase letters, stop word removal (removal of words not containing any information like \textit{the} and \textit{or}, these words are language-specific) and as a final step the bag of words creation (method to build a list of all used words in all input documents).
    Then, document vectorization is applied, which converts the preprocessed data of each resume to a vector of length $N$, where $N$ is the number of unique words in the bag of words.
    The vector represents a one-hot-encoding, meaning that if one of the unique words is present in the processed resume, this one value out of $N$ will be $1$. Otherwise, it will be $0$.
    This sample vector representation is also computed for the keyword dictionary that was previously defined, whose words are also added to the bag of words.
    The closer the vector representations of the resumes are to the vector representation of the keyword dictionary concerning Euclidian distance, the higher the predicted person-job fit is.
    A downside of this approach is that the presence of words in resumes outside the predefined keyword dictionary will increase the Euclidian distance even if they may not hurt the person-job fit.
    This could be tackled by restricting the bag of words to the words in the keyword dictionary.
    \item \textbf{N-Gram Analysis}\\
    In addition to the preprocessing steps described in the document vector analysis, the N-gram analysis also includes sentence tokenization (separation of sentences), word tokenization (separation of words), dictionary tagger (tag words in a specific language, for example, English), and term identification using verb phrase chunking (splits remaining phrases into their constituents).
    As the bag of words method has the downside of losing the word order and the meanings of word combinations, the data here is analyzed with the N-gram method.
    That means the predicted person-job fit is higher when a word combination of the manually crafted keyword dictionary is found in the processed resume as a $1$-, $2$- or $3$-gram, depending on the keyword word count.
    The more keywords found to be present as $N$-grams in the processed resume, the higher the predicted person-job fit.
\end{enumerate}
This method suffers from the manual creation of a keyword dictionary, which could be automated.
Furthermore, the results heavily depend on the quality and selection of the keywords in the keyword dictionary.
The accuracy of the $N$-gram model was slightly higher than the accuracy of the document vector model on average and topped at $87.5\%$ for the \textit{Data Developer} role.
Moreover, when analyzing text based on chunks of words, the context of the words may be lost.
This thesis tries to mitigate this shortcoming by using the capabilities of \gls{LLM}s to summarize the context of the input documents and answer questions regarding the provided context.

\subsection{Machine Learning Approach} \label{machine_learning_approach}

The article \textcite{pj_fit_ml} describes a machine learning approach to predict the person-job fit.
As also outlined by \textcite[1]{pj_fit_ml}, manual inspection of applicant documents from human resource workers is no longer feasible due to human judgment's subjective, incomplete, and inefficient nature.
The authors of this article have developed a novel end-to-end \gls{TAPJFNN} framework that should reduce human labor and make the employee selection process more interpretable.
The key idea is to exploit the information in historical job application data using a word-level semantic representation for job requirements and job seekers' experiences based on the Recurrent Neural Network architecture \parencite[1]{pj_fit_ml}.
There are also two hierarchical topic-based ability-aware attention strategies designed in this article to measure the different importance of job requirements for semantic representation, as well as measure the varying contribution of each job experience to a specific ability requirement \parencite[1]{pj_fit_ml}.
The \gls{TAPJFNN} framework supports predicting person-job fit, talent sourcing tasks, and job recommendation tasks \parencite[1]{pj_fit_ml}.
There has also never been a formal, mathematical definition of the person-job fit quantization task, but the article \textcite{pj_fit_ml} provides this definition \parencite[2]{pj_fit_ml}.
It is proposed in \textcite[2]{pj_fit_ml} that the job description is represented as a set of ability requirements.
The applicants' abilities are extracted from their documents. They are matched against the ability requirement set using a weighted, accumulative score, as several abilities can cover each requirement, and most applicants will have different abilities.
This approach should counteract the deficiencies of the text mining approach as described in section \ref{text_mining_approach}, where exact keywords or $N$-grams are matched, which can lead to ignoring some abilities if some abilities are not described using the expected keyword list or to misleading of the recruiters due to incomplete or subjective weightings used in the score construction.
Also, the constructed keyword features require manual labor, which is a significant downside \parencite[5]{pj_fit_ml}.
Therefore, \textcite[2]{pj_fit_ml} propose to use machine learning to weight abilities based on historic recruitment results instead of just using a semantic understanding of rich textual information.

\subsubsection{Person-Job Fit Quantization Problem Definition}
The person-job fit quantization problem is mathematically defined as follows in \textcite[7-8]{pj_fit_ml}:
\begin{itemize}
    \item $j_l$: $l^{th}$ job requirement in job posting $J$
    \item $r_l$: $l^{th}$ work/project experience in candidate's resume $R$
    \item $w^J_{l,t}$ work embedding of the $t^{th}$ word in job requirement $j_l$
    \item $w^R_{l,t}$ work embedding of the $t^{th}$ word in candidate's experience $r_l$
    \item $h^J_{l,t}$ word-level representation of $t^{th}$ word in job requirement $j_l$
    \item $h^R_{l,t}$ word-level representation of $t^{th}$ word in candidate's experience $r_l$
    \item $s^J_l$ single topic-based ability-aware representation of job requirement $j_l$
    \item $s^R_l$ single topic-based ability-aware representation of candidate's experience $r_l$
    \item $g^J$ multiple topic-based ability-aware representation of job posting $j$
    \item $g^R$ multiple topic-based ability-aware representation of candidate's resume $r$
    \item $g^{J,R}_{+,1:k}$ multiple topic-based ability-aware representations of $k$ candidates' resumes who successfully applied for the job $J$.
    \item $g^{J,R}_{-,1:k}$ multiple topic-based ability-aware representations of $k$ candidates' resumes who unsuccessfully apply for the job $J$.
    \item $p$ number of job requirements in the job posting $j$.
    \item $q$ number of work/project experiences in candidate's resume $r$.
    \item $m_l$ number of words in job requirement $j_l$.
    \item $n_l$ number of words in candidate's experience $r_l$.
\end{itemize}
The identifier $J$ denotes a job posting containing $p$ pieces of job requirements and duties called \textit{ability requirements}.
The job posting $J$ is the sum of all ability requirements, which means $J = \{j_1,j_2,...,j_p\}$.
\textcite[7]{pj_fit_ml} divide the ability requirements into two categories:
\begin{itemize}
    \item \textbf{Professional skill requirements}\\
    These requirements are related to the professional skills that are required to perform the job, like \textit{Data Mining}, \textit{Truck Driving}, or \textit{Hair Cutting}, for example.
    \item \textbf{Comprehensive quality skills}\\
    These requirements are related to the comprehensive quality skills that are required to perform the job, like \textit{Communication}, \textit{Team Work}, or \textit{Sincerity}, for example.
\end{itemize}
These two types are comprehensively analyzed without any distinction between them.
Moreover, each job ability requirement $j_l$ is assumed to contain $m_l$ words, that means $j_l = \{j_{l,1},j_{l,2},...,j_{l,m_l}\}$.
The identifier $R$ denotes a candidate's resume, which contains $q$ pieces of experience.
The resume $R$ is the sum of all experiences, which means $R = \{r_1,r_2,...,r_q\}$.
Furthermore, each candidate's experience $r_l$ is assumed to contain $n_l$ words, that means $r_l = \{r_{l,1},r_{l,2},...,r_{l,n_l}\}$.
The job application is denoted as $S$ and is represented by a pair of $J$ and $R$, that has an associated recruitment result label $y \in \{0,1\}$ where $y = 1$ means a successful application and $y = 0$ means a failed one.
Each job $J$ may have many different applicants $R$, and each applicant $R$ may apply for many different jobs $J$.
The mathematical problem definition can now be given as provided in \textcite[8]{pj_fit_ml}:
\begin{definition}
    Given a set of job applications $A$, where each application $S \in A$ contains a job posting $J$ and a resume $R$ as well as the corresponding recruitment result label $y$, the target of person-job fit is to learn a predictive model $M$ for measuring the matching degree between $J$ and $R$. Then, the corresponding result label $y$ can be predicted.
\end{definition}

\subsubsection{\gls{TAPJFNN} Architecture}
The \gls{TAPJFNN} architecture is visualized in the following figure:
\begin{figure}[H]
    \centering
    \includegraphics[scale=1,page=8,width=0.8\linewidth,trim={50 435 50 80},clip]{literature/pj_fit_ml.pdf}
    \caption{\gls{TAPJFNN} architecture \parencite[8]{pj_fit_ml}}
    \label{fig:tapjfnn_architecture}
\end{figure}
Each job requirement $j_l$ is a paragraph in the job posting $J$.
Each experience $r_l$ is a paragraph in the candidate's resume $R$.
As can be seen in figure \ref{fig:tapjfnn_architecture}, the architecture mainly consists of the following three components \parencite[8-14]{pj_fit_ml}:
\begin{itemize}
    \item \textbf{Word-Level Representation}\\
        Both the job requirements and the applicant's experiences are encoded on a word basis to an internal embedding using a \textit{BiLSTM} model, which is constructed out of two \textit{LSTM} models, one that gets the input step-by-step in the forward direction (from first to last) and one that receives the input step by step in the backward direction (from last to first).
        The outputs of both \textit{LSTM} models are concatenated to form the final output of each step.
        Each word in a job requirement $j_l$ or an applicant's experience $r_l$ is encoded to a word embedding $w^J_{l,t}$ or $w^R_{l,t}$ respectively by using the same pre-trained word vector matrix $W_e$ that is retrained during training and the following equation $w^J_{l,t} = W_e \cdot j_{l,t}$ or $w^R_{l,t} = W_e \cdot r_{l,t}$ respectively.
        The equation to compute the word-level representation $h^J_{l,t}$ or $h^R_{l,t}$ respectively is $h^J_{l,t} = BiLSTM(w^J_{l,1:m_l},t) \; \forall t \in [1,...,m_l]$ or $h^R_{l,t} = BiLSTM(w^R_{l,1:n_l},t) \; \forall t \in [1,...,n_l]$ respectively.
        These equations have the disadvantage that the words at the beginning have less context than the words at the end, as the first word has just access to the first and last word to compute its word-level representation.
    \item \textbf{Hierarchical Topic-Based Ability-Aware Representation}\\
    This component is divided into the following four parts:
    \begin{itemize}
        \item \textbf{Single Ability-Aware Part for Job Requirement}\\
        This layer is responsible for summing up the attention-weighted intermediate word-level representations $h^J_{l,t}$ to a single ability-aware requirement representation $s^J_l$ for each job requirement $j_l$.
        Some words might be more important than others in a job requirement. Therefore, the attention mechanism is used to weigh the importance of each word and shift the weighting towards keywords.
        This summing can be donated as $s^J_l = \sum_{t=1}^{m_l} \alpha_{l,t} \cdot h^J_{l,t}$ where $\alpha_{l,t} = \frac{\exp(e^J_{l,t})}{\sum_{i=1}^{m_l} \exp(e^J_{l,i})}$ is the attention weight of the $t^{th}$ word in job requirement $j_l$.
        The term $e^J_{l,t}$ is defined to be $v_{\alpha}^{\intercal} \tanh(W_{\alpha} \cdot h^J_{l,t} + b_{\alpha})$.
        All parameters that are not described are initialized and learned in the training process.
        \item \textbf{Multiple Topic-Based Ability-Aware Part for Job Requirement}\\
        The single ability-aware part for job requirement is extended to the multiple topic-based ability-aware part for job requirement by summing the weighted results from the previous layer according to $g^J = \sum_{t=1}^p \beta_t c_t^J$.
        The expression $c_t^J$ can be computed as $c_t^J = BiLSTM(s^J_{1:p},t) \; \forall t \in [1,...,p]$.
        The term $\beta_t$ is defined to be $\frac{\exp(f^J_t)}{\sum_{i=1}^p \exp(f^J_i)}$ where $f^J_t = v_{\beta}^{\intercal} \tanh(W_{\beta} \cdot c_t^J + U_\beta \cdot z^J + b_{\beta})$.
        The term $g^J$ is the final representation of the job requirements of job posting $J$, which contains the summed-up requirements weighted with their importance.
        All parameters that are not described are initialized and learned in the training process.
        \item \textbf{Single Ability-Aware Part for Experience}\\
        The word-level representations $h^R_{l,t}$ for each job experience $r_l$ are summed up for each job requirement $j_k$ to a single ability-aware experience representation $s^R_{l,k}$ which equals $\sum_{t=1}^{n_l} \gamma_{l,k,t} \cdot h^R_{l,t}$.
        The term $\gamma_{l,k,t}$ is defined to be $\frac{\exp(e^R_{l,k,t})}{\sum_{i=1}^{n_l} \sum^p_{j=1} \exp(e^R_{j,k,i})}$ where $e^R_{j,k,i} = v_{\gamma}^{\intercal} \tanh(W_{\gamma} \cdot s^J_{k} + U_\gamma \cdot h^R_{l,r} + b_{\gamma})$.
        This is defined as a novel approach as the attention is not only applied to one dimension, which would be all experiences comparably to the job requirements case, but the second dimension of the job requirements is also considered.
        Moreover, the attention mechanism uses $s^J_k$ as input to correctly weigh the words in the experiences regarding the requirement $j_k$.
        All parameters that are not described are initialized and learned in the training process.
        \item \textbf{Multiple Topic-Based Ability-Aware Part for Experience}\\
        In this layer, the first step is to sum up the attention-weighted intermediate representations $s^R_{l,k}$ to a single ability-aware experience representation $s^R_l$ for each job experience $r_l$.
        This is done by using the following equation $s^R_l = \sum_{t=1}^p s^R_{l,t}$.
        These semantic representations are again accumulated with a \textit{BiLSTM} to extract temporal relationships between them.
        These accumulated representations are computed as $c_t^R = BiLSTM(s^R_{1:q},t) \; \forall t \in [1,...,q]$.
        The final representation of the job experiences of resume $R$ is computed as $g^R = \sum_{t=1}^q \delta_t c_t^R$ where $\delta_t = \frac{\exp(f^R_t)}{\sum_{i=1}^q \exp(f^R_i)}$ and $f^R_t = v_{\delta}^{\intercal} \tanh(W_{\delta} \cdot g^J + U_\delta \cdot c^R_t + M_\delta \cdot z^J + V_\delta \cdot z^R + b_{\delta})$ which represents the attention mechanism in this architecture part.
        All parameters that are not described are initialized and learned in the training process.
    \end{itemize}
    \item \textbf{Person-Job Fit Prediction}\\
    The final prediction result can now be computed as $\hat{y} = sigmoid(W_y \cdot D + b_y)$ where $D$ is defined as $tanh(W_d[g^J;g^R;g^J-g^R;g^J \odot g^R;z^J;z^R;(W_Jz^J + b_J) \odot (W_Rz^R + b_R)] + b_d)$.
    All parameters that are not described are initialized and learned in the training process.
    The application is predicted to succeed if the $\hat{y}$ is bigger than $0.5$. Otherwise, it is predicted to be unsuccessful.
    The researchers have also implemented a refined prediction strategy that improves the model's accuracy by supplying the model additionally with $k$ successful and $k$ unsuccessful applications for the same job posting $J$.
    This is not presented here and can be found in \textcite[13-14]{pj_fit_ml}.
\end{itemize}
The accuracy of the \gls{TAPJFNN} architecture was tested on a large dataset of around $10000$ applicants, and the resulting accuracy was around $85\%$.
Of course, the disadvantage of this approach is that the model is only as good as the data it is trained on. Many successful and unsuccessful applications are needed for the training, making this method infeasible for small companies.
The researchers discuss in their article that the attention mechanisms make the whole architecture more interpretable as the requirements, experiences, or words where the model's attention scores are high identify the focus of the underlying model.
The discussion was more detailed here because the authors successfully applied the divide and conquer strategy to the person-job fit quantization problem and tried to remodel the human steps as differentiable functions in their \gls{TAPJFNN} architecture.

\subsection{Mixed Approach}
The model introduced in \textcite[517]{applicant_semantic_matching} uses a mixed approach to match applicants to job postings by incorporating a combination of supervised learning algorithms and a semantic matching system.
The evaluation of the applicants in this system is based on objective criteria which are directly extracted from an applicant's \textit{LinkedIn} profile, and the personality characteristics are deduced from the applicant's social presence on \textit{LinkedIn} \parencite[517]{applicant_semantic_matching}.
The $5$ objective criteria that were chosen were \parencite[518]{applicant_semantic_matching}:
\begin{enumerate}
    \item Education (years of formal academic training)
    \item Work Experience (months of related experience)
    \item Loyalty (average number of years spent per job)
    \item Extraversion (deduced from the applicant's social presence)
    \item Skills (used to be semantically matched to the job requirements)
\end{enumerate}
It was also introduced as a semantic matching system to match the applicant's past experiences to the job requirements. It also incorporated an algorithm that determined whether the past work experience was within the domain of expertise of the job position.

The system consisted of the following $4$ components \parencite[518-519]{applicant_semantic_matching}:
\begin{itemize}
    \item \textbf{Semantic Matching}\\
    This semantic matching system calculates the semantic distance between candidate skills or prior experiences and the job requirements \parencite[518]{applicant_semantic_matching}.
    Semantic matching means that annotations using controlled domain-specific vocabularies are matched with background knowledge about a particular application domain, which is modeled as a taxonomy of skills in this domain that was created by an expert \parencite[519]{applicant_semantic_matching}.
    A taxonomy is a set of categories or terms organized into a hierarchy with parent-child relationships and implied inheritance. More general concepts are on the top, and more specific concepts are on the bottom, as shown in the following picture \ref{fig:it_skill_taxonomy}:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=1,page=5,width=0.8\linewidth,trim={45 510 45 55},clip]{literature/applicant_semantic_matching.pdf}
        \caption{A part of an IT skill taxonomy \parencite[519]{applicant_semantic_matching}}
        \label{fig:it_skill_taxonomy}
    \end{figure}
    Today, this taxonomy is labeled as a knowledge graph, a way to store information in graphs structurally.
    The taxonomy is used to match the skills mentioned in the applicant's profile (skill keywords are used), the applicant's current work experience (skills from unstructured text are used) and eventually (if the candidate has the required skills) the applicant' past work experiences (skills from unstructured text are used) to the job position requirements (skill keywords are used), whenever a required skill is absent the applicant is rejected and not included into the final ranking \parencite[519-520]{applicant_semantic_matching}.
    The months of work experience are only calculated for experiences that concern relative competencies \parencite[519]{applicant_semantic_matching}.
    As the job's required skills and the user's skills were provided as skill keywords, the problem of extracting skills from unstructured text was reduced to work experiences.
    The search was not keyword-based but concept-based, that means because of the provided ontology, the system would know that a requirement of \textit{structured} can be fulfilled by the skill \textit{C} as can be seen in figure \ref{fig:it_skill_taxonomy}.
    The semantic distance of the required and present skills is based on the node distance metric \parencite[520]{applicant_semantic_matching}.
    \item \textbf{Personality Mining Module}\\
    This module uses the \textit{LinkedIn} user's posts to apply linguistic analysis and derive features that may reflect the user's personality, which is often overlooked in existing recruitment pipelines \parencite[518-520]{applicant_semantic_matching}.
    It was scientifically verified that by using the \acs{LIWC} system, the frequency of certain words in written texts correlated with the \textit{Big-Five} personality dimensions, but the dimension extraversion received the most research attention in this regard and was the dimension exclusively used in this article \parencite[521]{applicant_semantic_matching}.
    \item \textbf{Job Application Module}\\
    This module implemented forms necessary to fill out if a candidate wanted to apply to a job \parencite[518]{applicant_semantic_matching}.
    \item \textbf{Applicant Ranking Module}\\
    This module combines the candidate's selection criteria to derive the candidate's relevance score for the applied position using a parameterized function derived through supervised learning algorithms \parencite[518]{applicant_semantic_matching}.
    As is the case with all machine learning techniques, this one, too, requires sufficient training data of past candidate selection decisions, which will only be present in the necessary scale in some companies \parencite[523]{applicant_semantic_matching}.
    This also raises the problem that the model will learn the past human bias from past candidate selections, as was the case in \textcite[9]{bias_ai_hiring}.
    Of course, all past candidates must again be used to compute the $5$ objective criteria. Also, a human expert recruiter must annotate all the past recruitment decisions with relevant scores that the model should learn. This involves a lot of manual labor \parencite[523-524]{applicant_semantic_matching}.
\end{itemize}

\section{Bias in \acs{AI}-enabled Recruiting Tools}
The article \textcite[9]{bias_ai_hiring} mentions that even \textit{Amazon} had an \acs{AI}-enabled hiring tool that had an internal bias towards male candidates while penalizing female applicants.
Bias in this context means that identical applications apart from the name and sex would be ranked differently by this algorithm, even if they should be ranked equally.
As mentioned in \textcite[9]{bias_ai_hiring}, the problem was that since the machine learning model was trained with historic recruitment data, it also inherently learned the bias already present in this historical data.
This was the bias from the past decisions of human recruiters that seemed to prefer male applicants over female ones, and past choices also penalized African Americans \parencite[9-10]{bias_ai_hiring}.
However, several startups want to show that with a carefully designed system, the human bias can also be removed from the recruitment process \parencite[9]{bias_ai_hiring}.
Some techniques these startups are using are extracting identifying information from applications, holding anonymous interviews and skill-set tests, and tuning the job posting wording to attract a more diverse set of applicants \parencite[9]{bias_ai_hiring}.
The first approach is the one that this thesis takes, the second approach eliminates gender bias by focusing on the skills and impartiality of all candidates (personally identifiable information is stripped away), and the third approach is not applicable in this thesis as the job postings have already been created and are input to the model.
This shows that a bias-free recruiting process cannot be achieved by replacing just one tool in the pipeline. All tools must be carefully designed to be bias-free, starting with the job description wording and ending with a valid way to assess the candidate's skills to make an informed decision.
The second approach can be used to assess the candidates further, which the proposed model from the thesis finds promising. The third approach is also necessary to attract a diverse group of applicants in the first place.
A filtering model like the one from the thesis can never reintroduce diversity that is not present among the applicants, so the wording of the job description is crucial.
Another essential aspect that the article \textcite[9-10]{bias_ai_hiring} mentions is that (continually) trained models must also be monitored for bias continuously, and the recruiters must know that the results from \acs{AI}-enabled tools cannot be trusted blindly but must be overridden by the human judgment if necessary.
Furthermore, constantly staying on alert and cross-checking the model results with human judgment might defeat some of the efficiency gains the model may bring.
The bias issue is increasingly important if the \acs{AI}-enabled tools are increasingly used as autonomous and not as assistive tools, which means the tools make active hiring decisions instead of just providing suggestions or recommendations within the process.
Moreover, there was also a software presented in \textcite[10-11]{bias_ai_hiring} that computes a match score between a candidate's documents and a job's requirements similar to the model proposed in this thesis, and it was reported that with this matching system, recruiters were more likely to consider underprivileged and underrepresented minorities to move forward in the hiring process, significantly improving the overall hiring diversity.
There is also the issue with verifying the claims of \acs{AI}-assisted tools as there currently is no publicly available dataset actually to benchmark these systems \parencite[11]{bias_ai_hiring}. That issue also made the creation of original sample applicant data necessary for this thesis \parencite[11]{bias_ai_hiring}.
Companies do not want to share their training data as this can lead to data privacy or liability issues if some bias is found in the data or the model, so the current system, lacking robust mechanisms for verification and inherently susceptible to confirmation biases, must undergo a radical and scientifically-driven transformation in the future \parencite[11]{bias_ai_hiring}.

\section{\acs{AI}-enabled Recruiting as Marketing Tool and Current Developments}
The article \textcite[215]{marketing_ai_recruitment} mentions that companies do not need to spend money to hide their use of \acs{AI} in the application process. Instead, they can use it to promote their use, which significantly positively affects job application likelihood due to its novelty factor if the candidate already has a positive view of the organization.
\acs{AI} can utilize physiological characteristics (face recognition, DNA, hand geometry, iris recognition, micro-expressions, scent, and retina scanning) and behavioral traits (gait, typing rhythm, and voice patterns) as part of the candidate selection process apart from the aforementioned text-based features of a candidate \parencite[215]{marketing_ai_recruitment}.
The research testing the validity of these machine learning-based methods that try to infer and extrapolate characteristics in terms of job fit and performance is lagging and gives rise to data privacy and bias discussions as it is also possible to deduce a person's sexual orientation from a face recognition with remarkable accuracy \parencite[215]{marketing_ai_recruitment}.
It is essential to transparently communicate what can be done with the current state-of-the-art technologies, but the question of what should be done must be asked from an ethical perspective.
The more data is collected, the more seemingly unrelated features of this data can be used to infer more characteristics about the candidate with reasonable accuracy, but since those characteristics are extracted using machine learning methods, they are not valid in any particular applicant's case which gives rise to ethical and privacy concerns \parencite[215]{marketing_ai_recruitment}.
Furthermore, \acs{AI}-enabled recruiting tools also have the potential to be more efficient and effective than human recruiters, and their use within e-recruitment tools is positively catalyzed with an increased technology use motivation of job seekers due to its perceived usefulness \parencite[216]{marketing_ai_recruitment}.
The candidate's attitude towards the brand or image of the organization is one of the critical factors that prevent applicants from applying for a job. Still, with the help of \acs{AI} and its novelty factor, the technology use motivation can be increased, leading to a higher job application likelihood \parencite[217]{marketing_ai_recruitment}.
The article also mentions that an applicant's anxiety towards the use of \acs{AI} in recruitment is secondary to the applicant's attitude towards the hiring organization \parencite[217]{marketing_ai_recruitment}.
Candidates are more satisfied with technology-based recruitment when it is technologically advanced and user-friendly and if the recruitment has a high perceived efficiency \parencite[219]{marketing_ai_recruitment}.
The novelty of \acs{AI} fosters a positive, sustainable pre-employment relationship behavior where ease of use and playfulness enable candidates with low cow cognitive innovation to form sustainable relationships with potential employers. At the same time, aesthetics, service excellence, and usefulness are the enablers for candidates with high cognitive innovation \parencite[220]{marketing_ai_recruitment}.

\chapter{Methodology} \label{methodology}

\section{Discussion on the Methods}
Qualitative methods describe, interpret, and understand contexts, establish classifications or typologies, and generate hypotheses.
In the thesis's case, the qualitative consideration of the object of investigation is backed by an extensive literature review in chapter \ref{theoretical_background}.
The literature review focuses on the broad application area and superior generality of \gls{LLM}s and how other researchers have approached the person-environment fit quantization problem.
As qualitative methods should be used when new findings or new theories need to be developed, these methods are a good fit for the thesis's case as the \gls{LLM} approach to the person-environment fit quantization problem is a relatively novel approach with few available literature documents.
Those findings and theories cannot be generalized in most cases, as they mostly explore particular cases in depth, like the \gls{LLM} approach in our case.
As described in \textcite[127]{qualitative_methods}, theories are constructed from the results, and conclusions are drawn for practice.
The qualitative methods should conclude whether an \gls{LLM}-based model is a good fit for the person-environment fit quantization problem and what human expert recruiters expect from such assistive technologies, including their considerations.
Furthermore, recruiters' past experiences with such assistive technologies should also be part of the results.
The qualitative methods should enforce openness, breadth, detail, proximity, and interdisciplinarity in favor of representativeness and structuring \parencite[127]{qualitative_methods}.
On the other hand, quantitative methods are concerned with the most accurate description and predictability of behavior in models, correlations, and numerical characteristics, i.e., the measurement of quantities, proportions, or numbers of one or more specific characteristics of the object under investigation.
These are also needed in the thesis's case, as the subordinate research questions can only be answered by measuring the proposed model's accuracy against human expert recruiters while tracking the associated time usage.
Quantitative methods will, therefore, be used to confirm or refute the theory that \gls{LLM}-based models might be a good fit for the person-environment fit quantization problem.
The results from quantitative methods may generalize well if statistical significance is given.
This brief discussion of qualitative and quantitative methods led to the conclusion that a hybrid approach (qualitative and quantitative methods) to answering the research question is beneficial in the context of the thesis.
As less is known about the object of investigation, a qualitative literature review is necessary before going forward with quantitative methods.
Processing and interpreting verbal data from qualitative methods can yield the necessary features for implementing the proposed model.

\subsection{Discussion on the Qualitative Methods}
These are the available survey instruments for qualitative research:
\begin{itemize}
    \item \textbf{Narrative Interview}\\
    The advantage of this kind of survey instrument might be that the interviewed entity can be more relaxed in their answers and can tell their story in length, expansiveness, and level of detail, as the questions are very open-ended.
    A disadvantage might be that certain areas will not be covered in the expected level of detail, and some areas will not be covered if the interview is not guided.
    \item \textbf{Guideline Interview}\\
    The disadvantage of this kind of survey instrument might be that the interviewed entity is somewhat constrained by the interviewer's more specific questions, which means the answers will be less diverse and more specific to the question than in a narrative interview.
    If the interview is guided well, an advantage might be that all expected areas will be covered in the expected level of detail.
    \item \textbf{Group Discussion}\\
    Group discussions have the advantage that participants can interact and build on each other's ideas.
    That means outputs might be more diverse and prosperous than subsequent one-on-one interviews.
    A disadvantage might be that more extroverted people may overshadow introverted people and that a few participants might dominate the discussion.
    Furthermore, some participants may not want to or are not allowed to share internal business-critical company information in a group setting.
    \item \textbf{Text Analysis}\\
    This survey instrument can be used to conduct a literature review, which can help gain a qualitative understanding of the object of investigation and generate new research and model implementation ideas from ongoing research.
    The advantage is that much information is easily accessible, which allows an excellent theoretical foundation to be built quickly.
    A disadvantage may be that literature regarding certain areas may not be available in the expected level of detail, and some areas may have no available literature.
    \item \textbf{Observation Analysis}\\
    This survey instrument is unsuitable as it is mainly used for social studies, where observation refers to all forms of sensory perception.
    As the object of investigation is a computer program, observing it in the traditional sense makes no sense, as it will consistently execute the way it is programmed to when invoked.
\end{itemize}
Analyzing all the discussed survey instruments, it was decided that the most suitable qualitative survey instrument for the thesis's case is the guideline interview in a group discussion setting combined with an extensive literature review (text analysis).
Qualitative content analysis with inductive category formation according to \textit{Mayring} \parencite{mayring} of the transcribed group discussion will be carried out to work with a proven and repeatable methodology and gain valuable insights.
A literature review is needed to get a good theoretical base and answer the research question.
The decision was taken because the group discussion will help to get a diverse set of interactively constructed opinions or may reveal points that have been forgotten in the interview guidelines, and the guideline interview will help to guide the discussion to the expected areas that should be covered in the expected level of detail.
These areas include the impressions of the implemented proposed model, expectations, and considerations on assistive technologies in the \acs{HR} pipeline and the experiences with \acs{AI}-assisted technologies in the context of \acs{HR}.
Narrative interviews are not used in this thesis's methods as particular areas must be addressed in the discussion. In a group setting, the time of all participants needs to be respected.
As mentioned, the observation analysis makes no sense in this thesis's case.

\subsection{Discussion on the Quantitative Methods}
These are the available survey instruments for quantitative research:
\begin{itemize}
    \item \textbf{Research Survey}\\
    A survey might be beneficial for quickly obtaining large amounts of easily processable data from diverse participants, especially when automatically checked online forms are used.
    Another advantage is that each participant can fill out the survey asynchronously, which means that the participants' time is respected.
    A downside of this approach might be that participants are very constrained in their answers as they need to conform to the allowed quantitative boundaries of the expected survey answers.
    \item \textbf{Standardized Observation}\\
    This survey instrument is not suitable as it is mainly used for studies where observation refers to all forms of quantitatively measurable information.
    As the object of investigation is a computer program, observing it in the traditional sense makes no sense, as it will consistently execute the way it is programmed to when invoked.
    \item \textbf{Research Experiment}\\
    If secondary data is unavailable, a research experiment can be conducted to measure values in a repeatable setting.
    The advantage of this method is that the sourced data has the expected and designed quality and conforms to the research question and problem definition.
    The disadvantage is that the data collection process through experiments is time-consuming and costly and may not yield the required amount of data to get statistical significance.
    \item \textbf{Research Panel}\\
    This survey instrument is unsuitable as it mainly monitors a fixed set of participants over time to extract trends or other valuable information. As our object of investigation is a computer program, observing it in the traditional sense makes no sense, as it will only execute how it is programmed to when invoked.
    As the object of investigation is a computer program, observing it over time in the traditional sense makes no sense, as it will consistently execute how it is programmed to when invoked.
    \item \textbf{Secondary Data}\\
    An advantage of secondary data is that it is already available and can be used to answer the research question without collecting it from scratch.
    The disadvantage is that suitable data conforming to the research question and problem definition might not be publicly available.
    As this thesis's problem domain deals with personal data, publicly available data on jobs and applicants is scarce and almost always of inadequate quality, as discussed in section \ref{construction_process_of_the_sample_screening_documents}.
\end{itemize}
By analyzing all the discussed survey instruments, it was decided that the most suitable quantitative survey instrument for the thesis's case is the research experiment, where results are communicated using an online form to double-check the passed input data.
High-quality secondary data for the person-environment quantization task (job descriptions with corresponding applicant \acs{CV}s) was unavailable. Therefore, the data had to be constructed from scratch as mentioned in section \ref{construction_process_of_the_sample_screening_documents}.
This constructed data is then used as input to human expert recruiters and the proposed \gls{LLM}-based model to quantitatively analyze the accuracy of the model and the time savings associated with the model usage.
The resulting data will be statistically analyzed.
As mentioned, the standardized observation and research panel make no sense in this thesis's case.

\section{Qualitative Research Design} \label{qualitative_research_design}
The literature review used as a qualitative method was primarily carried out in chapter \ref{theoretical_background}.
As it was decided to use a guideline interview in a group discussion setting, a focus group of five human expert recruiters was assembled to analyze the model's output and impact from a qualitative perspective.
This amount of experts was chosen to have diverse opinions, but only a few participants, to reduce the coordination work.
Initially, $15$ Austrian recruitment-only companies were contacted to find $5$ participating organizations.
Those human experts will be involved in three major interactions:
\begin{enumerate}
    \item \textbf{Kick-Off Meeting} \label{kick_off_meeting}\\
    In this meeting, the human expert recruiters will be introduced to the proposed model, and the topic of machine learning-assisted technologies in human resources will be discussed.
    The interview guideline contains the following major topics to collect the requirements of the problem domain:
    \begin{enumerate}
        \item \textbf{Bias and Fairness}\\
        This topic entails discussing bias and fairness in the context of machine learning-assisted technologies in human resources.
        Furthermore, the technologies should probably behave in a way that avoids discrimination based on gender, ethnicity, age, or other non-job-related factors.
        Moreover, more general ethical considerations should also be discussed.
        \item \textbf{Accuracy and Reliability}\\
        This topic entails a discussion of how well the technologies should be able to replicate human judgment.
        The operation should probably be reliable, and different \acs{CV} formats and layouts should be supported while keeping the ability to match job requirements with various qualifications and experiences in other industry fields.
        \item \textbf{Legal Considerations}\\
        This topic entails discussing the legal considerations of the technologies that must be matched to use \acs{AI}-assisted technologies in real-world human resource processes.
        This includes the discussion of data security and privacy, as well as the debate on the transparency of the technologies.
        \item \textbf{Machine Learning as Assistive Technology}\\
        This topic entails a discussion on the role of machine learning in the human resource process and how it can complement the human decision-making process.
        There can maybe also be a discussion on scenarios where it would be better not to use \acs{AI}-assisted technologies or a debate on the balance of automated and human decision-making in the screening process and whether the proposed architecture matches the expected balance or if changes should be implemented.
        Moreover, the expected efficiency gains of the technologies should be discussed.
        \item \textbf{Customization and Adaptability}\\
        This topic entails discussing the customization and adaptability of the technologies and whether they can adapt to specific industry needs, company cultures, and varying contexts.
        Moreover, there must be things that the users might want to tweak to customize the technologies to their needs.
        For example, this can be the weighting or definition of certain job requirement types or general hints on matching the job requirement to the applicant's screening documents.
        It is essential to understand how important it is for users to feed their improvement suggestions into the system.
        This could be done so every user can tweak the system's configuration.
        \item \textbf{User Experience}\\
        This topic entails a discussion on the user experience of the technologies, whether they are easy to use, understand, and integrate into existing systems.
        Moreover, the file types and programs used in current human resource processes should be discussed here.
        Furthermore, knowing if these programs support third-party export and import functionalities is essential before using an external program for the screening task.
        \item \textbf{Candidate experience}\\
        This topic entails a discussion on the candidate's experience of the technologies and whether they have any advantages on their side.
        Moreover, these advantages may include a faster response time and automated feedback generation for positive and negative feedback.
        \item \textbf{Previous experiences with \acs{AI}-assisted technologies in human resources}\\
        This topic entails discussing the human experts' previous experiences with \acs{AI}-assisted technologies in the context of human resources.
        Moreover, the discussion should include these technologies' general reception, advantages, disadvantages, potential improvements and drawbacks, and their field of use within the human resource pipeline.
        \item \textbf{Costs}
        This topic entails a discussion on the costs of the technologies, whether they are affordable, and whether they are worth the investment, including the expected costs for a model as outlined in this thesis.
        \item \textbf{Open Discussion}
        This point is reserved to discuss open topics that came up in the meeting that were not covered by the topics above.
    \end{enumerate}
    \item \textbf{Ranking Announcement} \label{ranking_announcement}\\
    After the kick-off meeting, each human expert recruiter will get a set of applicant documents and job descriptions that should be ranked and categorized in \ref{quantitative_research_design}.
    The final outputs of the experts and the time it took to produce the outputs per job description will be collected via an online form that will be provided for that purpose.
    \item \textbf{Closure Meeting} \label{closure_meeting}\\
    In this meeting, the human expert recruiters will get the model's output to the same applicant documents and job descriptions that the recruiters have gotten.
    The model's output will be provided to the recruiters beforehand so they can prepare for the meeting.
    The model's output will be compared to the human expert recruiters' outputs, and the differences or similarities will be discussed.
    There will also be user tests of the model where the time taken to interface with the model will be measured.
    The interview guideline for the expert discussion contains the following topics:
    \begin{enumerate}
        \item \textbf{Consistency and Agreement}\\
        This topic entails discussing the consistency and agreement of the model's output with the human expert recruiters' output.
        There, the satisfaction of the achieved accuracy on the categorization and the ordering task should be discussed, and potential model bias or potential outliers and their reasons can be analyzed.
        \item \textbf{Explainability and Transparency}\\
        To achieve a high degree of user confidence and trust, the users must understand how the model makes its decisions, and the model must have a way to communicate its decisions in a transparent and human-understandable way.
        There should be a discussion on the explainability and transparency of the model's output to the human expert users.
        If deficiencies in the model are found by inspecting its explanations, a discussion on tweaking the model's configuration and whether it is understandable and easy to use should be held.
        \item \textbf{Open Discussion}
        This point is reserved to discuss open topics that came up in the meeting that were not covered by the topics above.
    \end{enumerate}
\end{enumerate}
All the information gathered will be qualitatively analyzed, and the discussions will be summarized while presenting the considerations of the recruiters' common sense.
The participating five human expert recruiters were affiliated with the following five anonymized recruiting companies:
\begin{enumerate}
    \item \textbf{Recruiting Company}\\
    around $6000$ employees
    \item \textbf{Recruiting Company}\\
    around $200$ employees
    \item \textbf{Recruiting Company}\\
    around $100$ employees
    \item \textbf{Recruiting Company}\\
    around $20$ employees
    \item \textbf{Recruiting Company}\\
    around $10$ employees
\end{enumerate}

\section{Quantitative Research Design} \label{quantitative_research_design}
It was decided to conduct a research experiment in which results are communicated online to answer the subordinate research questions.
The five human experts of the focus group introduced in \ref{qualitative_research_design} will get the same sample screening documents consisting of applicant documents and job descriptions.
This marks the start of the experiment.
Each human expert should rank the applicant documents from best to worst and categorize them as promising and unpromising candidates per the job description.
That means that for each job description, there is an applicant ranking from best (1\textsuperscript{st} place) to worst (8\textsuperscript{th} place) applicant, and there are also two applicant groups per job description, the promising applicant group and the unpromising applicant group.
This marks the end of the experiment.
These ranking and categorization results are then typed into an online form to double-check the passed input data before the human experts are allowed to submit it.
The screening documents comprise six job descriptions of various industries with eight applicant document sets each.
This split was chosen to have diverse job descriptions with different applicants competing.
Furthermore, recruiters must rank and categorize $48$ applicants while tracking their time usage per job description.
More importantly, the sample screening documents must also be provided in adequate quality to mimic the real-world screening process as closely as possible.
All job descriptions will only have \acs{CV}s as applicant documents.
The length of each \acs{CV} is bound to six pages.
No applicant document will contain a photo of the applicant.
The following is a table summarizing the structure of the sample screening documents:
\begin{table}[H]
    \begin{tabular}{|l|l|l|l|}
    \hline
    \textbf{index} & \textbf{job description present} & \textbf{\acs{CV} present} & \textbf{cover letter present} \\ \hline
    1 & yes & yes & no \\ \hline
    2 & yes & yes & no \\ \hline
    3 & yes & yes & no \\ \hline
    4 & yes & yes & no \\ \hline
    5 & yes & yes & no \\ \hline
    6 & yes & yes & no \\ \hline
    \end{tabular}
    \caption{Structure of the sample screening documents}
\end{table}

The accuracy of the designed screening model will be determined by comparing the human expert annotations submitted in the online form to the model's output for the same sample screening documents and the following labels:
\begin{enumerate}
    \item \textbf{Ranking}\\
    The ranking of the model's output and each human expert's output will be compared to the mean human expert ranking per job description.
    Metrics summarizing the ranking accuracy for all job descriptions will also be provided.
    The rankings will be compared using Kendall's Tau \ref{kendalls_tau}.
    The mean rankings and the summarized metrics will be computed with an arithmetic mean.
    Additional criteria will be introduced to break eventually occurring ties.
    \item \textbf{Categorization}\\
    The set of promising candidates of the model's output and each human expert's output will be compared to the mean human expert categorization per job description.
    Metrics that summarize the categorization accuracy for all job descriptions will also be provided.
    The comparison of the categorizations will be done using the Hamming distance.
    Therefore, this would equal the number of applicant category changes necessary to transform one categorization into another.
    The mean categorizations will be computed using the mode, and the summarized metrics will be calculated with an arithmetic mean.
    Additional criteria will be introduced to break eventually occurring ties.
\end{enumerate}

The time savings associated with the model usage will be determined by analyzing the time usage of the human expert recruiters submitted in the online form while carrying out the applicant ranking and categorization task.
Since the proposed model can run asynchronously in the background whenever new applicant documents come in, the time usage of the model itself during its execution is rarely a limiting factor for the productivity of employees in the \acs{HR} sector.
The model will add latency to incoming applicant documents, which will then be preprocessed and more accessible for human expert recruiters to work with.
This latency is below one minute per applicant document, but the exact runtimes of the model will be sampled and reported.

\subsection{Rank-Biased Overlap}
Rank-biased overlap (RBO) was used in \textcite{rank_biased_overlap} to compare the search results of various search engines.
It computes the similarity of two rankings from $0$ (no similarity) to $1$ (most similarity). It can be evaluated up to a certain depth $k$ and needs a weighting parameter $p$ out of the interval $(0,1)$.
The lower $p$ is chosen, the more weight is put on the top ranks of the rankings.
Here are some examples to illustrate the behavior of rank-biased overlap denoted as $rbo$, $k=\infty$, which means that the evaluation depth is as deep as the length of the ranking:
\begin{itemize}
    \item $rbo_{k=\infty,p=0.1}(['dog','cat','mom'],['dog','cat','mom']) \approx 1$
    \item $rbo_{k=\infty,p=0.1}(['apple','peach','mom'],['dog','cat','dad']) = 0$
    \item $rbo_{k=\infty,p=0.1}(['dog','cat','mom'],['dog','cat','dad']) \approx 0.99$
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom'],['dog','cat','dad']) \approx 0.74$
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom','tennis'],['dog','cat','dad','tennis']) \approx 0.80$
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom','tennis'],['dog','cat','dad','golf']) \approx 0.78$
\end{itemize}
As described in \textcite[1]{rank_biased_overlap}, it was the first metric at that time that had the following three properties when comparing incomplete rankings (incomplete means that not every element from the population must be necessarily ranked):
\begin{enumerate}
\item Non-Conjointness (incomplete rankings must not necessarily contain the same elements from the population)
\begin{itemize}
    \item $rbo_{k=\infty,p=0.1}(['apple','peach','mom'],['dog','cat','dad']) = 0$
\end{itemize}
\item Weighting (the metric should weight high ranks more than low ranks, e.g., it is worse to have a difference in the 1\textsuperscript{st} place than in the 7\textsuperscript{th} place)
\begin{itemize}
    \item $rbo_{k=\infty,p=0.1}(['dog','cat','mom'],['dog','cat','dad']) \approx 0.99$
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom'],['dog','cat','dad']) \approx 0.74$
\end{itemize}
\item Monotonicity (the ranking should be monotonic with increasing depth of evaluation as also indefinite rankings are supported, which means that the rank-biased overlap measure is non-decreasing with increasing depth of evaluation)
\begin{itemize}
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom'],['dog','cat','dad']) \approx 0.74$
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom','tennis'],['dog','cat','dad','tennis']) \approx 0.80$
    \item $rbo_{k=\infty,p=0.6}(['dog','cat','mom','tennis'],['dog','cat','dad','golf']) \approx 0.78$
\end{itemize}
\end{enumerate}
These properties were helpful when comparing search results from search engines, as they most likely supply incomplete rankings, which are non-conjoint and massive in size (monotonicity and evaluation at a certain depth are desirable). Results at the front are much more important than search results further back in the ranking.

\subsection{Kendall's Tau} \label{kendalls_tau}
Kendall's Tau, defined in \textcite{kendall_tau}, is a correlation coefficient that measures the ordinal association between two conjoint rankings. A rank correlation coefficient evaluates the similarity between two rankings, providing a value between $-1$ (perfect disagreement, ranking order is reversed) and $1$ (perfect agreement, ranking order is the same). A value of $0$ indicates no association or correlation. The metric is computed by: $\tau = \frac{(number\:of\:concordant\:pairs)-(number\:of\:discordant\:pairs)}{number\:of\:pairs}$. A pair of objects is considered concordant if the order between two elements is the same in both rankings. Otherwise, the pair is discordant. There is also a weighted version of the metric, where more importance can be given to the head of the ranking, the tail of the ranking, or even another custom weigher function. This feature was not used as the ranking's head for prioritization, and the ranking's tail for filtering is important. This metric only supports conjoint rankings, meaning the ordered elements must be identical in both rankings. This metric is always computed for full depth, so no partial evaluations are possible with this metric. Here are some examples to illustrate the behavior of Kendall's Tau, denoted as $\tau$, when comparing different rankings:
\begin{itemize}
    \item $\tau(['dog', 'cat', 'mom', 'tennis'], ['dog', 'cat', 'mom', 'tennis']) = 1$
    \item $\tau(['dog', 'cat', 'mom', 'tennis'], ['tennis', 'mom', 'cat', 'dog']) = -1$
    \item $\tau(['dog', 'cat', 'mom', 'tennis'], ['cat', 'mom', 'tennis', 'dog']) = 0$
    \item $\tau(['dog', 'cat', 'mom', 'tennis'], ['cat', 'dog', 'mom', 'tennis']) = \frac{2}{3}$
\end{itemize}
As described in the \textcite[713-715]{kendall_tau}, Kendall's Tau has several properties that make it suitable for comparing rankings, especially in scenarios where the exact order of items is significant:
\begin{enumerate}
\item Sensitivity to swaps\\
Kendall's Tau is sensitive to the number of swaps needed to convert one ranking into another.
\item Interpretability\\
The coefficient is easily interpreted as a measure of concordance or discordance between two rankings, providing clear insights into the degree of association.
\end{enumerate}

\subsection{Decision of Ranking Correlation Metric}
As the candidate rankings are limited in size and conjoint, and no special weighting is needed, Kendall's Tau metric was decided to compare the candidate rankings instead of the rank-biased overlap metric due to its superior interpretability. This interpretability is given as the metric simply compares the concordant and discordant object pairs in both rankings.

\section{Sample Screening Documents} \label{sample_screening_documents}
The sample screening documents (job descriptions and applicant \acs{CV}s) for the previously mentioned research experiment needed to be constructed from scratch as no quality secondary data was available.
This was necessary to mimic the real-world screening process as closely as possible.
Only in a realistic scenario can the model's output be compared to the human expert recruiters' output.
Details on how the screening documents were constructed can be found in the following sections.

\subsection{Overview of the Construction and Usage of the Sample Screening Documents}
The job descriptions and the applicant documents will be either taken from publicly available datasets, taken from publicly available sources, manually crafted, or generated using tools like \textit{GPT-4} \parencite{gpt4} while giving the model some hints on the context and the expected applicant characteristics.
Due to their internal tokenization, the job description and the applicants' \acs{CV}s must be supplied as pure text to the proposed model.
That means the more tools belonging to Digital Recruiting 3.0 \ref{digital_recruiting_3} are deployed in the screening process, the more critical it will be to supply machine-readable applicant documents that please the machine learning models used in the screening process.
When this \acs{AI} barrier is successfully surpassed, it must be ensured that the documents also please the decision-making human after reading them.
This will lead to new challenges for the applicants as they must please both the machine-learning models and the human decision-makers.
As the industry-standard formats for applicant documents are the \textit{PDF} and the \textit{Microsoft Word} format, files in such formats must be converted to pure text before they can be supplied to the model.
As this conversion is not the focus of this thesis, it will be briefly discussed in chapter \ref{implementation}.
This also means that a more sophisticated \acs{CV} layout or design and an included portrait photo will not influence the model's output, as the model will only see the text contents.
Future work can incorporate this information by converting this visual information to text using image-to-text models.
Another way to incorporate this information is to use a multimodal model to process text and images.
Other types of multimodal input could be audio, video, code as a particular text form, and files with the example of \textit{PDF} files.
The proposed model will compute a score from $0$ to $100$ for each \acs{CV}-job-matchup that will be supplied to it.
The model should also output whether the applicant is promising and should categorize the applicants into two groups.
Based on this score, the \acs{CV}s for a particular job can be ranked from best to worst.
If there is a tie with the output scores, additional criteria will be globally introduced to break the tie.
Furthermore, the model will explain each score output to clarify why it thinks this score is justified.
The exact implementation details of the score and explanation generation are described in section \ref{implementation}.
The human experts' rankings will not be available during the model implementation phase. They will only be used to benchmark the model's accuracy after implementation.

\subsection{Construction Process of the Sample Screening Documents} \label{construction_process_of_the_sample_screening_documents}
At first, there was extensive research on the availability of datasets that contain job descriptions and the corresponding applicant \acs{CV}s in document format.
With document format, it means that the documents are either supplied in the \textit{PDF} or the \textit{Microsoft Word} format.
Most of the datasets that were found on \textit{Kaggle} \parencite{kaggle}, via the \textit{Google} search or in \textit{GitHub} projects had at least one of the following deficiencies:
\begin{itemize}
    \item The dataset was not publicly available or not anymore publicly available due to legal reasons
    \item The dataset either contained only jobs or only candidates, which is not ideal since random matching is also no option as there will not be completely random applicants for a specific job in the real world
    \item The dataset contained the applicant or job data in a columnar format, which makes it impossible to use it for the human screening process that is used to benchmark the model's accuracy
    \item The dataset only contained a very narrow set of jobs from a particular industry, making it impossible to test the model's ability to generalize to different industries
    \item The dataset contained seemingly random candidates for the contained jobs, which, as noted before, is no good representation of real-world screening data
\end{itemize}
This is why it was decided to explicitly construct the sample screening documents for this thesis.
To have a diverse set of jobs, the following key sectors of the Austrian economy were looked up on the website \parencite{austria_key_sectors}, which an organization of the Austrian Federal Economic Chamber created:
\begin{itemize}
    \item Food and Drink industry
    \item Mechanical and Steel Engineering
    \item Chemical and Automotive industry
    \item Electrics and Electronics industry
    \item Wood, Pulp, and Paper industry
\end{itemize}
By doing some research on the platform \textit{LinkedIn} \parencite{linkedin} on the various job opportunities these industries offer, the following six job types were selected to be contained in the sample screening documents' job descriptions to cover most of Austria's key sectors:
\begin{itemize}
    \item Export Specialist (Food and Drink industry)
    \item Embedded Software Engineer (Electrics and Electronics industry)
    \item Green Hydrogen Piping Engineer (Mechanical and Steel Engineering)
    \item Validation and Qualification Engineer (Chemical and Automotive industry)
    \item Store Manager (picked representatively for the Commerce industry even if it is not a key sector)
    \item Digital Design Engineer (Chemical and Automotive industry)
\end{itemize}
The six job descriptions in the sample screening documents were manually crafted but heavily inspired by job listings from companies on the \textit{LinkedIn} platform to be as close to reality as possible.
All the job descriptions were kept in a reduced form of the platform's initial job description header structure, which contained the job title, the job location, the work model, the employment type, and the specific level of the position.
The other content was mainly paraphrased from the real job listings, but the company name was removed from the text, and the job location was always set to \textit{Vienna} to redact the job listings further.
The basic formatting and sectioning of the job listings were kept, but the font and the font sizes of the header and the content were homogenized to make the job listings more standardized.
This is no advantage for the proposed machine learning model as this model only sees the text contents of the job descriptions.

Furthermore, the eight applicants per job description were manually crafted but heavily inspired by real \acs{CV}s from the \textit{LinkedIn} platform.
Possible applicants per job description were searched for on the \textit{LinkedIn} platform by searching for the job title of the job description using a people search.
Then, eight applicants were randomly selected per job description with a proper English \textit{LinkedIn} profile. Another selection criterion was that most of the entries in the education and experience section are commented on and elaborated using English text.
Some candidates listed on later pages of the search results were also selected, which means they were less relevant to the job description.
This was done to achieve a reasonable balance of candidate variety and candidate suitability for the job description and to have enough information in the profile to deduce if applicants meet or do not meet specific job requirements.
The \textit{LinkedIn} platform allows the download of profiles as \acs{CV}s in the form of \textit{PDF} files.
The structure, layout, and design of this \acs{CV} download were used to craft the \acs{CV}s for the sample screening documents.
Information that is included in this \acs{CV} structure: \label{cv_structure}
\begin{itemize}
    \item Name
    \item Candidate Location
    \item Summary
    \item Job Experiences
    \item Educational Degrees
    \item Contact Details (not anymore present in the sample screening documents)
    \item Top Skills
    \item Spoken Languages (if present)
    \item Certifications (if present)
    \item Publications (if present)
    \item Honors/Awards (if present)
    \item Patents (if present)
\end{itemize}
To redact the information taken from the \textit{LinkedIn} profiles, all contact-related information was removed from the \acs{CV} documents as well as all hyperlinks present in the \textit{PDF} files were removed.
Moreover, most \acs{CV}s' candidate locations were changed to \textit{Austria}. Sometimes, this made no sense as some current positions demanded a physical presence elsewhere in the world for the \acs{CV} to appear realistic.
Furthermore, the candidates' names were redacted to random unisex English names to eliminate the influence of the candidate's sex on the human decision-making process and the model's decision-making process.

\section{Model Design and Model Implementation} \label{implementation}
This section describes what ideas were used to design the model and how the model was implemented.
It describes how the input screening documents are processed step by step to the final model output.
Furthermore, it explains what \gls{LLM}s are supported to be used within the proposed model, and there are also some remarks made on the context windows and determinism of \gls{LLM}s.
Moreover, the proposed model's fully changeable configuration, scope and limitations, and capability to handle various input and output languages and different input document formats are presented.

\subsection{Input Data Preprocessing}
As described in \ref{sample_screening_documents}, all input files are supplied in the \textit{PDF} format, as this format can be used for humans and \acs{AI}-enabled screening and is widely adopted.
The input files can even be printed if a human expert recruiter wants to analyze the person-environment fit while looking at physical paper instead of a digital screen.
This might be more familiar for recruiters if quick notes need to be made.
These \textit{PDF} files must be converted to pure text contents to be tokenizable and supplied to the proposed model.
The text extraction of the \textit{PDF} files was carried out with the \textit{Python} package \textit{PyMuPDF} \parencite{pymupdf}, but faces these issues which are mentioned in \textcite{pymupdf}:
\begin{itemize}
    \item \textbf{Complex File Structure}\\
    The \textit{PDF Reference} defining the \textit{PDF} standard is vast and extensive.
    The text in a \textit{PDF} document can either be stored in plain text or as a graphic.
    Whereas plain text is easy to extract, the text in a graphic must be extracted using optical character recognition, which may introduce wrongly extracted characters.
    The \textit{PDF} package supports optical character recognition, but this feature was not used for this thesis.
    Furthermore, for plain text extraction, the font and the used encoding must be adequately detected to extract the text correctly, which is appropriately done by the used package.
    Moreover, plain text segments can be specified as a collection of words and placed on the \textit{PDF} page, which is commonly used.
    It is also possible to position each character individually on the page.
    Not only that but also the order of the specified plain text segments in the \textit{PDF} file must not occur in the natural reading order of the \textit{PDF} file due to a possible absolute positioning of these segments. The resulting \textit{PDF} file may always be the same even if a random order of these segments is used.
    Due to the text's final position, a natural reading order may be re-established, but this is a complex problem due to the standard's complexity.
    The package offers several extraction modes to cope with this problem.
    \item \textbf{Complex Layouts}\\
    Another facet of the problem described above is the text extraction of \textit{PDF} files with complex layouts.
    If the layout has multiple columns or even a more complex structure, the order of the extracted text segments should be clarified.
    It usually takes work to determine the natural reading order of this kind of document.
    The used package also offers some extraction modes to cope with this problem.
\end{itemize}
As the \textit{PDF} files containing the job descriptions have a simple layout and no images, no optical character recognition was needed for this case.
These job description \textit{PDF} files were created using \textit{Microsoft Word}, which does not store individual characters as plain text segments but instead stores as long text contents as possible in the natural reading order (from top to bottom) into the resulting \textit{PDF} file.
Most of the time, the plain text segments of a \textit{PDF} file are stored in a natural reading order if the file was programmatically created.
This is also the industry standard way of doing it, so for the extraction, it was enough to extract the plain text segment contents in the order they were defined in the \textit{PDF} file.

The \textit{PDF} files containing the applicant \acs{CV}s were created using \textit{Apache FOP}. They also have no images, so no optical character recognition was needed for this case.
They have a slightly more complex layout than the job description \textit{PDF} files as they feature a two-column layout.
However, the creation tool \textit{Apache FOP} stores the plain text segments of the left column first in the \text{PDF} file, and then the plain text segments of the right column follow in the file.
This means the plain text segments are stored in a natural reading order (from left column to right column, from top to bottom), as is the case for most programmatically generated \textit{PDF} files.
The left \acs{CV} column contains all the information mentioned in \ref{cv_structure} except the name, candidate location, summary, job experiences, and educational degrees.
The extraction was done in the same way as for the job description \textit{PDF} files by extracting the plain text segments in the order they were defined in the \textit{PDF} file.

Optical character recognition would have been needed if there would have been images with text in the \textit{PDF} files or scanned \textit{PDF} documents.
Furthermore, the extraction would have been more complicated if the \textit{PDF} files had had a more complex layout or stored the plain text segments in non-natural reading order.
Text extraction could still have been achieved by using the \textit{PyMuPDF} package and extracting text underneath user-defined extraction rectangles (reading order must be explicitly set), and extracted characters or words can be brought into a natural reading order by ordering them according to the position of their bounding rectangles.

As stated in \textcite{pymupdf}, no effort is made by the package in any way to prettify the extracted text.
That means there can be too few or too many whitespaces (spaces, line breaks, \dots) in expected or unexpected positions in the extracted text.
The non-prettified extracted text was already properly usable for the proposed model, but it was decided that the extracted text should be prettified to group relevant information.
The main issue with the sample screening documents was that the extracted text lacked most of the line breaks that seemed to be there in a \textit{PDF} viewer.
This was the case as line breaks may also be implicitly coded into the \textit{PDF} file by the absolute starting position of the plain text segment.
The prettification was done at first by sending the extracted text to an \gls{LLM}, which was asked to group relevant text parts in a paragraph and to improve the overall formatting of the text without changing the text contents.
This approach worked reasonably well for the thesis's use case. Still, it was later disabled as output tokens are much more expensive than input tokens to \gls{LLM}s, and the explanations and scores have not seemed significantly better. It can be reactivated in the model's configuration \ref{model_configuration}.
Enabling this setting roughly doubles the costs of operating the proposed model.

\subsection{Model Design}
Following the divide-and-conquer principle of \textcite{pj_fit_ml}, the hard task of programmatically quantizing the person-environment fit for a specific job description and a specific applicant was broken into the following two tasks:
\begin{enumerate}
    \item \textbf{Job Requirement Extraction}\\
    The first part of the proposed model extracted the job requirements into a machine-readable format from a job description that was supplied as pure text.
    All \acs{CV}s from applicants for the same job were matched against the same set of extracted job requirements.
    This adds determinism to the model's output as the same set of job requirements is used for all applicants for the same job.
    \item \textbf{Job Requirement Matching}\\
    The second part of the proposed model matched the extracted job requirements against the applicant's \acs{CV} that was also supplied as pure text.
    This part of the model quantized the person-environment fit between the applicant and the job description for every extracted job requirement.
    Furthermore, the used \gls{LLM} was also asked to state whether the candidate was promising by supplying it with all the results computed in the previous steps.
    Afterward, the quantizations were aggregated into a single score that quantified the person-environment fit between the applicant and the job description, with a total score ranging from $0$ to $100$.
\end{enumerate}

\subsection{Job Requirement Extraction} \label{job_requirement_extraction}
This part of the model receives the prettified, extracted text from the job description \textit{PDF} file.
Before extracting the requirements, there were $12$ job requirement types or categories defined, which are heavily inspired by the enumeration of \textcite{job_requirement_types}:
\begin{itemize} \label{job_requirement_types}
    \item \textbf{Work Experience}\\
    This point includes requirements on previous job titles, key responsibilities, achievements, or duration of tenure at a specific position or in a particular field.
    \item \textbf{Education}\\
    For example, this requirement type includes the education level or the requested field of study.
    \item \textbf{Other Qualifications}\\
    This requirement type covers other necessary qualifications like certifications, licenses, or accreditations.
    \item \textbf{Hard Skills}\\
    This requirement type covers the technical skills required to perform the job.
    \item \textbf{Soft Skills}\\
    This requirement type covers the necessary abilities of a candidate to relate well to others.
    \item \textbf{Specific Knowledge}\\
    This requirement type includes knowledge of specific fields necessary to perform the job, which must be listed in the job requirements.
    \item \textbf{Personal Traits}\\
    This requirement type includes personality traits that the employer is looking for to achieve a high person-environment fit and a high person-job fit, which may consist of attention to detail, reliability, creativity, or general intelligence.
    \item \textbf{Languages}\\
    This requirement type includes the languages required to perform well in the job with a necessary level of fluency or proficiency.
    \item \textbf{Travel}\\
    This requirement type includes traveling, apart from commuting, which the job entails.
    \item \textbf{Location}\\
    This requirement type includes the willingness to commute to the working location of the job, but it also consists of the work model like the hybrid or the remote work model.
    \item \textbf{Working Hours}\\
    This requirement type includes the total amount of work hours and the flexibility regarding working hours, including shifts or necessary weekend work.
    \item \textbf{Physical Ability}\\
    This requirement type includes any physical capabilities or limitations relevant to job requirements, such as the ability to lift certain weights or stand for extended periods.
\end{itemize}
The requirements were extracted using one prompt that is sent to the \gls{LLM} that contains the extracted text from the job description as well as a mapping of the job requirement types to a textual definition of the type that should be extracted including some hints how to match the requirements of that type with an applicant \acs{CV}.
This mapping is mostly based on the definitions in \textcite{job_requirement_types} and has the same types as in \ref{job_requirement_types}, but some fine tunings were applied to the definitions to produce a more human-like output.
Moreover, the number of requirement types or their definitions can be easily changed in the current architecture if a human expert wants to modify the model's behavior.
It was decided to extract all the requirements in one pass as extracting them isolated by job requirement type led to many duplicated job requirements.
Also, it seemed like the \gls{LLM} models better categorize all the requirements in one pass.
The prompt requests the \gls{LLM} to output the job requirements extraction result using the \textit{JSON} format with specific fields specified in the prompt.
This \text{JSON} object is then extracted from the output text of the \gls{LLM} and contains $0$ or more requirements as a list per requirement type.
Each requirement has a textual specification and information on whether the requirement is mandatory or optional.
These extracted job requirements by job requirement types are then passed onto the job requirement matching task.

\subsection{Job Requirement Matching} \label{job_requirement_matching}
The job requirements extracted in the previous step are then matched against each applicant's \acs{CV} that is also already supplied as pure text because it already had gone through the preprocessing.
The $0$ or more requirements per requirement type are matched individually against each applicant's \acs{CV}, so the matching processes do not interfere with each other and can be parallelized.
The matching is done by querying the \gls{LLM} to output a \textit{JSON} object that contains a score between $0$ and $100$ and an explanation for the score by supplying the \gls{LLM} with the job requirement specification, the job requirement type, the job requirement type definition from \ref{job_requirement_extraction} and the applicant's \acs{CV}.
The score was chosen between the interval of $0$ and $100$ as the model could better output intermediate scores in this interval more than in the interval of $0$ and $1$, for example.
This is likely because most sample text also contained percentage values instead of values between $0$ and $1$.
These objects are then extracted from the text output of the \gls{LLM} and are used to amend the data structure created in the previous step with the concrete score and a textual explanation.
Afterward, this amended data structure with scores and explanations was used as input to ask the \gls{LLM} if the applicant was promising or not.
The model was prompted to output the result again as \textit{JSON} object, which contained whether the applicant is promising and a textual explanation for the decision.
Furthermore, the applicant's total score was computed by first taking the arithmetic mean of each requirement's score within each requirement type. Job requirement types with $0$ requirements were left out.
Secondly, a weighted arithmetic mean was taken from the arithmetic means of each requirement type to build the applicant's final total score, which is between $0$ and $100$.
A correction factor was used to compensate for requirement types with $0$ requirements and a non-zero weighting. The factor was necessary to still cover the total score range from $0$ to $100$ even if one requirement type had no requirements.
This final total score can be used to sort the applicants by relevance, which means predicted person-environment fit.
The weighting used for the total score computation was initially set to a fixed value. However, if a human expert wants to change the model's behavior, the weighting of the individual requirement types can be easily changed.
This concludes the inner workings of the requirement-matching task. The final output of the model per applicant is the previous amended data structure, a total score, a promising or not promising decision, and a textual explanation.

\subsection{Output Data Postprocessing} \label{output_data_postprocessing}
In this step, the model's output data structure is presented to the user in a human-readable way.
This was done by providing the user with a table per job description, including all candidates, their total scores, and whether a candidate is promising.
Furthermore, this table is sorted in descending order by the promising flag first and then by the applicants' total scores.
This table is provided in the console output of the invoked model, and the table is also offered as a \textit{CSV} file to be used as input for other software in the human resource pipeline.
It must be noted that a promising candidate can have a lower total score than a non-promising candidate. Whether a candidate is promising is not solely based on the total score but also the individual scores of the requirements and whether they are mandatory or not.
That means focusing the work effort on the most promising candidates. Due to the sorting above, looking at the candidates from top to bottom in the table is advisable.
Moreover, suppose the recruiter wants to examine how the decision was made. In that case, the model stores each applicant's whole internal data structure in the human-readable and machine-readable \textit{JSON} format.
Compared to the table, this \textit{JSON} file also contains information on the matched individual requirements, including their score and textual explanations.
Moreover, an explanation is given there as to why the candidate seems promising.
That should help to fine-tune the job requirement type definitions and the weightings of the job requirements to match the desires of the human expert recruiter.

\subsection{Supported \gls{LLM}s}
Whenever the section \ref{implementation} mentions the use of an \gls{LLM}, it means that a concrete \gls{LLM} implementation is used.
For this thesis, only \gls{LLM}s that were fine-tuned for chat completions were used, as the prompts are formulated in conversational requests.
An Interface-based implementation supports different models from different vendors, regardless of whether they are open-source or proprietary.
Requests to third-party hosting providers are used to query all models. The interface-based implementation's configuration options are automatically translated to options understandable by the underlying and currently used model.
The following models were implemented and can be used as \gls{LLM} for the proposed model:
\begin{enumerate}
    \item \textbf{GPT-4 Turbo}\\
    This proprietary model is an evolution of \textit{GPT-4} proposed in \textcite{gpt4}, which has not gotten its technical report. It has a context window of $128000$ tokens and an undisclosed amount of parameters.
    The model was developed by \textit{OpenAI} and is hosted by \textit{OpenAI}.
    \item \textbf{GPT-3.5 Turbo}\\
    This proprietary model is an evolution of \textit{GPT-3} proposed in \textcite{gpt3}, which has not gotten its technical report. It has a context window of $16385$ tokens and an undisclosed amount of parameters.
    The model was developed by \textit{OpenAI} and is hosted by \textit{OpenAI}.
    \item \textbf{LLAMA 2-Chat}\\
    This open-source model collection is described in \textcite{llama2}. Each model has a context window of $4096$ tokens, and the three models of this collection used in this thesis differ in their number of parameters, which are either $7$, $13$, or $70$ billion parameters.
    These models were developed by \textit{Meta} and are hosted by \textit{Replicate} in the implementation's case, one of many hosting providers for this model collection.
    Due to its open-source nature, this model collection can be self-hosted without sending data to third parties.
    \item \textbf{Gemini}\\
    This proprietary model collection is described in \textcite{gemini}. Currently, only \textit{Gemini Pro} is available publicly. \textit{Gemini Pro} has a context window of $32000$ tokens and an undisclosed amount of parameters.
    These models were developed by \textit{Google} and are hosted by \textit{Google}.
\end{enumerate}

\subsection{Context Windows of \gls{LLM}s}
The context window must be large enough to contain the prompt itself, including all input texts and the expected output text of the model so that all input parts can be fully referenced in the answer.
As a rule of thumb, around four characters of standard English text will be translated to one token, a text fragment that is encoded using a unique integer, in the case of the \textit{OpenAI} tokenizer, which is based on the byte pair encoding algorithm \parencite{openai_tokenizer}.
This token translation is bidirectional and can, therefore, go both ways, which means the unique integer sequence can be translated back into the source text.
As mentioned in \textcite[6]{llama2}, the \textit{LLAMA 2-Chat} models also use a tokenizer that employs the byte pair encoding algorithm. Therefore, the rule of thumb for the \textit{OpenAI} tokenizer is used as a general measure in the following calculation examples.
The largest \acs{CV} that this thesis uses as input text has around $6500$ characters, translating to about $1625$ tokens.
The most extensive job description this thesis uses as input text consists of around $3700$ characters, translating to about $925$ tokens.
The largest prompt without the contained input text is the one that extracts the requirements from the job description as it contains all the job requirement definitions and consists of around $7000$ characters in the current default configuration, which equals about $1750$ tokens.
That means with a context size of $4096$ tokens, only $4096-925-1750=1421$ tokens are left for the output text of the model for the job requirement extraction task, which equals about $5684$ characters.
The longest answer that the used \gls{LLM} may give depends on when the model is stopping to generate output text, which itself depends on how many requirements are present in the input job description.
A typical requirement extraction \gls{LLM} output contains around $3000$ characters, so it is within the remaining and available minimum context size of all supported models, and there is still some margin there.
Regarding the context window size, the job requirement extraction task is the limiting factor or critical path, as the other prompts without input texts and expected output texts are much smaller.
If the configuration is changed such that the job requirement definitions are more extensive or if the used job descriptions are much larger, the context window size may quickly reach its limit. Models with a larger context size must be used in this case.

\subsection{Determinism of \gls{LLM}s}
The settings used for configuring the \gls{LLM}s were picked to make the underlying \gls{LLM} deterministic, which means that the same input to the model should lead to the same output every single time.
These settings remove all configurable penalties (presence penalty, repetition penalty, repetition penalty) and biases (only logit bias) that would alter the model output, use a constant system prompt, limit the maximum output token amount to $4096$, and define no stop sequences.
The settings above are not altering if the \gls{LLM} is behaving deterministically or not, but they are instead listed for completeness.
The output tokens of an \gls{LLM} are sampled from the probability distribution of the model's output logits, representing the token vocabulary.
This sampling needs a random number generator to sample, which is seeded with a known fixed seed to make the output values of this generator and, therefore, the sampled tokens deterministic.
This single setting makes an \gls{LLM} deterministic.
Additionally, the token vocabulary sampling space sampled in every \gls{LLM} step can be trimmed down by setting the number of top tokens to sample from or by only sampling from the top tokens that add up to a certain probability mass.
Both settings were configured such that only the single top token is sampled in every step, which means the token with the highest probability should always be chosen.
The temperature setting of \gls{LLM}s is the input to a \textit{Softmax} function with temperature. This parameter controls whether the probability differences should be softened or enlarged.
In this thesis, the temperature was set to zero, which means that only the highest probability token has a non-zero probability and should always be chosen.
Despite fixing the seed, which should make the model deterministic anyway, trimming the sampling space to only one token and setting the temperature setting to enforce this single token further, only the \textit{LLAMA 2-Chat} models were behaving deterministically.
Both models from \textit{OpenAI} failed to deliver deterministic responses even with the settings above, which should lead to deterministic behavior.
The responses from \textit{OpenAI} models to the same inputs are primarily similar or identical. Still, nothing can be guaranteed. Therefore, no unit test cases can be written for non-deterministic models if they check the full model response text.
The \textit{OpenAI} API sends a \textit{system fingerprint} value with their responses and does not guarantee determinism in general \parencite{openai_chat_api}.
\textit{OpenAI} systems try to sample deterministically if the seed was also fixed in the request \parencite{openai_chat_api}.
If the \textit{system fingerprint} of the response changes compared to a previous request with the same input, it will likely result in a non-deterministic response \parencite{openai_chat_api}.
The problem for the \textit{OpenAI} API user is that there is no way to specify which system you want to have to get deterministic responses. \textit{OpenAI} assigns the used backend systems nondeterministically. Two back-to-back requests will likely have two different \textit{system fingerprint} values \parencite{openai_chat_api}.
The nondeterministic behavior is known to \textit{OpenAI}, and hopefully, they will fix it in a future release.
The \textit{Gemini} model family suffered from similar issues as the \textit{OpenAI} models. It does not even support seeding the internally used random number generator.

\subsection{Model Configuration} \label{model_configuration}
The main changeable configuration parameters of the model configuration enable:
\begin{enumerate}
    \item setting the weight of each requirement type
    \item changing the definitions of requirement types
    \item modification of the internally used prompts
\end{enumerate}
This is the default configuration that is used to operate the proposed model.
Every single setting can be changed to modify the behavior of the proposed model to the desires of the operating human expert recruiter:
\lstinputlisting[language=TypeScript,label=lst:default_model_configuration,caption=Default configuration of the proposed model]{../hrgpt/default_config.json}

\subsection{Scope and Limitations}
As \gls{LLM}s are trained on massive amounts of data compressed into the model's parameters, the resulting model can summarize text and answer questions based on the input text reasonably well in the most general cases.
As most text data on the internet is written in English, the proposed model in its first version was only tested and used with English job descriptions and \acs{CV}s as English is the preferred language of most if not all \gls{LLM}s.
Due to this compression, the model is only guaranteed to output plausible text in some cases.
As there are vast amounts of possible input texts, the model cannot summarize and answer questions on all of them correctly or with the same accuracy, as \gls{LLM}s do not understand the text the same way humans do.
This means that the model will not be able to give a plausible output on every theoretically possible \acs{CV} job matchup and should, therefore, not be used as a single point of truth to pre-filter applicants in the screening process if fairness is a top priority.
However, they will behave quite robustly in most cases due to the vast amounts of training data that are scraped off the internet and used to train these models.
Furthermore, the introduced model will not be fair as the human training data used to build \gls{LLM}s already has some bias within its data. The decision-making process of humans is ambiguous, and past experiences influence humans' decisions. This makes it very hard even for the legal systems to detect discrimination \parencite[113]{discrimination_algorithms}. That means that human decision-making is not fair in all cases. But \textcite[113]{discrimination_algorithms} sees a positive force for equity by incorporating algorithms for decision-making and detecting discrimination if fairness can be reasonably defined. Proving an algorithm's fairness in all possible cases if its behavior depends on human-written data, like in the thesis's case, is virtually impossible. Also, in \textcite[158-160]{discrimination_algorithms}, the authors pointed out that race-aware predictors are more capable of determining college success than race-blind predictors.
That means when the law forbids certain features in algorithmic or human decision-making regarding fairness, the loss of accuracy can be significant, as shown in the example. Other application areas, like healthcare, might be where race-aware algorithms could save lives, but more restrictive legislation would prevent their usage.

\subsection{Multilingual Support}
Multilingual support for the proposed model was introduced by translating all extracted non-English text from job descriptions or \acs{CV}s into English using a machine translation service before supplying it to the underlying \gls{LLM}.
This has the advantage that the \gls{LLM}s can still operate in their preferred language domain.
The detection of whether a text is non-English and needs translation was done by using the \textit{Python} package \textit{Lingua Language Detector} \parencite{lingua_language_detector}, as it is an open-source language detector that offers similar performance to the language detection accuracy of \textit{Google Translate} for example.
For example, the used machine translation service could be either \textit{DeepL Translate} \parencite{deepl_translate} or \textit{Google Translate} \parencite{google_translate}, which both have an API to better integrate with computer programs.
The model implementation only supports translations with \textit{Google Translate}.
If sending data to third parties is not desired, an open-source and offline machine translation library like \textit{Argos Translate} \parencite{argos_translate} could be used and integrated.
That means that all critical building blocks of the model can be replaced with open-source and offline alternatives if operating the model in a more privacy-preserving way is desired.
Furthermore, the English text contents of the \textit{CSV} and \textit{JSON} output files can be optionally translated to a configurable non-English output language using a machine translation service.
This output language can be changed by altering the configuration of the proposed model \ref{model_configuration}.

\subsection{Multiple File Type Support}
The thesis only focused on input documents in the \textit{PDF} format.
However, the tool was also programmed to support \textit{Microsoft Word} and plain text files as input documents.

\chapter{Data} \label{data}

\section{Data Collection}
This section covers how the data was collected.
For the two meetings that were used to get qualitative data, the data collection was done by recording and transcribing the meetings.
To lead the discussion for both meetings in the right direction, a discussion guide was used to formulate the main topics and the most important open questions in the form of a questionnaire.
The human expert recruiters were asked to type the results into an online form to obtain quantitative data.

\subsection{Qualitative Research}
This section describes how the qualitative data was retrieved.
The meetings where the discussion guides below were used were recorded and transcribed to get the qualitative data.

\subsubsection{Kick-Off Meeting Discussion Guide}
To provide more validity to the open, verbal discussion with the human experts of the focus group, the following discussion guide formulates the main topics and the most important open questions in the form of a questionnaire as quickly outlined in \ref{kick_off_meeting}:
\begin{enumerate}
    \item \textbf{Bias and Fairness}
    \begin{itemize}
        \item How do you perceive the potential for bias or definitive bias in \acs{AI}-assisted recruitment technologies?
        \item How important is it that the used \acs{AI} system is designed to ensure fairness and avoid discrimination based on gender, ethnicity, age, or other non-job-related factors?
        \item What are your views on the ethical considerations surrounding using machine learning in human resource processes?
    \end{itemize}
    \item \textbf{Accuracy and Reliability}
    \begin{itemize}
        \item To what extent should these technologies replicate human judgment in the screening process?
        \item To what extent have different \acs{CV} formats or layouts influenced the screening decision? Is an \acs{AI} model that uses the text contents of the \acs{CV} sufficient or not? What important information could be omitted with this approach?
        \item What difficulties do you see for \acs{AI} systems that can effectively match job requirements with a diverse range of qualifications and experiences across different industries?
    \end{itemize}
    \item \textbf{Legal Considerations}
    \begin{itemize}
        \item What legal challenges do you foresee in implementing \acs{AI} in \acs{HR} processes, particularly concerning data security and privacy? How can we maintain transparency in \acs{AI}-assisted recruitment technologies?
        \item Would the perceived transparency be better if the \acs{AI} software runs on the user's servers? Moreover, would you send applicant documents to third-party servers, or would you prefer to run the \gls{LLM} software on your servers?
        \item What key legal safeguards should be in place when using these technologies?
    \end{itemize}
    \item \textbf{Machine Learning as Assistive Technology}
    \begin{itemize}
        \item How do you see machine learning complementing human decision-making in \acs{HR}? What balance should be struck between automated and human decision-making in the screening process?
        \item Are there scenarios where \acs{AI}-assisted technologies should not be used in recruitment?
        \item What are your expectations regarding the efficiency gains from these technologies?
    \end{itemize}
    \item \textbf{Customization and Adaptability}
    \begin{itemize}
        \item How important is customization in \acs{AI}-assisted recruitment technologies for different industries and company cultures?
        \item What aspects of the technology should be customizable by the user? How do we supply feedback to the model?
        \item Should the user be able to tweak the model's configuration of requirement extraction, requirement matching, and weighting of the requirement match scores to change the model output, or is a more high-level form of customizability desired?
    \end{itemize}
    \item \textbf{User Experience}
    \begin{itemize}
        \item What are the key factors that make an \acs{AI}-assisted recruitment tool user-friendly?
        \item How should these technologies integrate with existing \acs{HR} systems? Moreover, what are the dominant file types used for applicant documents?
        \item What are your thoughts on third-party \acs{AI} tools in \acs{HR}? Do you prefer a fully integrated solution, or are multiple tools already used?
    \end{itemize}
    \item \textbf{Candidate Experience}
    \begin{itemize}
        \item What impact do you think \acs{AI} screening will have on the overall candidate experience?
        \item How might these technologies improve response times and feedback generation for applicants?
    \end{itemize}
    \item \textbf{Previous Experiences with \acs{AI}-assisted Technologies in Human Resources}
    \begin{itemize}
        \item What has been your experience with \acs{AI}-assisted technologies in \acs{HR} to date?
        \item Can you share insights on the general reception, advantages, disadvantages, and areas of improvement for these technologies?
        \item How have these technologies been integrated into the \acs{HR} pipeline in your experience, and in what part of the \acs{HR} process?
    \end{itemize}
    \item \textbf{Costs}
    \begin{itemize}
        \item How do you assess the affordability and cost-effectiveness of \acs{AI}-assisted recruitment technologies?
        \item How do you justify the costs of these technologies with their benefits?
    \end{itemize}
\end{enumerate}

\subsubsection{Closure Meeting Discussion Guide}
To provide more validity to the open, verbal discussion with the human experts of the focus group, the following discussion guide formulates the main topics and the most important open questions in the form of a questionnaire as quickly outlined in \ref{closure_meeting}:
\begin{enumerate}
    \item \textbf{Consistency and Agreement}
    \begin{itemize}
        \item How do you perceive the accuracy and the consistency between the model's categorization and ordering of applicants compared to the human recruiters' approach? Can you provide specific examples?
        \item Did you notice any biases or outliers in the model's output? If so, how do these biases or outliers compare to human recruiters' biases or outliers selected by human recruiters?
    \end{itemize}
    \item \textbf{Explainability and Transparency}
    \begin{itemize}
        \item How would you rate the model's ability to explain its decision-making process transparently and understandably?
        \item Can you give an example of a situation where the model's explanation of its decision was particularly clear or unclear?
        \item In your opinion, what changes or tweaks could be made to the model's configuration to improve understanding and usability?
        \item How important do you believe explainability and transparency are in using \acs{AI} for recruitment? Do you think these factors impact user trust and confidence?
    \end{itemize}
\end{enumerate}

\subsection{Quantitative Research}
This section describes how the quantitative data was retrieved.
The experiment results (applicant ranking, applicant promising categorization, and human expert time usage) were typed into the below online form by each human expert recruiter participating in the experiment.
These results are later statistically analyzed.

\subsubsection{Online Form for Experiment Results}
The online form was implemented using \textit{Google Forms} and enabled the recruiters to submit their time tracking, applicant categorization, and ranking results per job description asynchronously. The tool supports a \textit{CSV} export, which was used to further postprocess and analyze the retrieved data.

\section{Data Overview}
This section covers the data collected and gives an overview of the collected data.
The two meetings to get qualitative data were categorized and coded with qualitative content analysis with inductive category formation according to \textit{Mayring} \parencite{mayring}.
The numeric data from the experiment submitted with the online form was aggregated according to section \ref{quantitative_research_design}.

\subsection{Qualitative Research}
This section describes what qualitative data was retrieved.
The transcribed meetings were categorized and coded, resulting in the below data.

\subsubsection{Kick-Off Meeting Discussion Guide} \label{kick_off_meeting_data}
The transcribed meeting was carefully analyzed and brought into inductively built categories. Due to strict meeting time limits, not all questions from the discussion guide for each topic were answered in the same level of detail by all five human experts. Nonetheless, the resulting coding was tried to be as consistent and representative as possible.
\begin{enumerate}
    \item \textbf{Bias and Fairness}
    \begin{itemize}
        \item \textbf{How do you perceive the potential for bias or definitive bias in \acs{AI}-assisted recruitment technologies?}\\
        Four out of the five participating recruiters have said that they came across definite bias in \acs{AI}-assisted recruitment technologies. Only one participant said they did not encounter bias within their internal tests or other tools. Three out of five participants have identified bias issues in their internal toolchain when carrying out tests of \acs{AI}-enabled tools. Two participants said that they cope with these issues by constantly evaluating the decisions of these tools and feeding back better configuration parameters to bring the machine-made decisions into the expected window. That means it is important for \acs{AI}-based technologies to be configurable and learn from past mistakes.
        \item \textbf{How important is it that the used \acs{AI} system is designed to ensure fairness and avoid discrimination based on gender, ethnicity, age, or other non-job-related factors?}\\
        All five participants agreed that a fair \acs{AI} system that is as unbiased as possible is crucial for the success of \acs{AI}-assisted recruitment technologies. Two participants discussed the issue further, and it was concluded that past experiences of humans that form the human bias could also have positive effects, like acting fast under pressure or learning from past experiences. Furthermore, the discussion led to the point of the testability of a tool’s bias. If each human is biased because of past experiences, which entity could validate if a tool is bias-free? Furthermore, a participant mentioned a tool that can be used to post-process human-written text to make it appealing to any group of people. This tool can make job descriptions more appealing to a broader audience, not just men or women.
        \item \textbf{What are your views on the ethical considerations surrounding using machine learning in human resource processes?}
        All five participants agreed that the most significant ethical consideration on \acs{AI}-based tools is that not everybody is treated fairly. That means automated tools use decision criteria not directly related to job requirements and performance and should, therefore, not influence the model decision. Such criteria may be gender, race, or age, for example.
    \end{itemize}
    \item \textbf{Accuracy and Reliability}
    \begin{itemize}
        \item \textbf{To what extent should these technologies replicate human judgment in the screening process?}\\
        All five participants mentioned that they view \acs{AI}-enabled technologies in human resources as assistive technologies.
        These technologies propose candidate rankings and categorizations, but a human recruiter should still decide. One recruiter mentioned that in recent times, the need for automatic tools in screening is getting lower as the job market is getting more and more competitive and fewer applications per advertised job come in.
        \item \textbf{To what extent have different \acs{CV} formats or layouts influenced the screening decision? Is an \acs{AI} model that uses the text contents of the \acs{CV} sufficient or not? What important information could be omitted with this approach?}\\
        All five participants agreed that the \acs{CV} layout has little influence on the final screening decision but mentioned that it may have a higher impact in jobs where creativity is critical. Three out of five participants said that the model misses the applicant's picture by only analyzing text contents, which is still a significant criterion in the Central European human resources culture. One recruiter mentions that this culture has changed in Northern Europe or America, where they use more neutral \acs{CV}s, which do not reveal the applicant's ethnicity, looks, or age. All participants agreed that a \acs{CV} is mandatory to participate as an applicant in the human resources process.
        \item \textbf{What difficulties do you see for \acs{AI} systems that can effectively match job requirements with diverse qualifications and experiences across different industries?}\\
        Only one participant directly answered this question. The other participants did not mention any difficulties they foresaw.
        This recruiter suggested that the model may have problems dealing with implicit information in its input data. For example, implicit job requirements in the job description or implicit abilities in the \acs{CV} that are not explicitly mentioned but are needed for good job requirement coverage and thorough job requirement matching. Furthermore, there may be ambiguity in the natural language that can complicate the matching.
        Human recruiters often resolve ambiguities by requesting more information from candidates via phone or mail.
        Moreover, by using machine learning methods for the matching, it is increasingly essential for applicants to supply their abilities using natural language that contains the keywords expected by the model. A further discussion showed that \acs{AI}-based tooling could also be used to create or enhance \acs{CV}s for an advertised job.
        Hopefully, this is done only by better presenting the truth and not hallucinating non-existent abilities.
    \end{itemize}
    \item \textbf{Legal Considerations}
    \begin{itemize}
        \item \textbf{What legal challenges do you foresee in implementing \acs{AI} in \acs{HR} processes, particularly concerning data security and privacy? How can we maintain transparency in \acs{AI}-assisted recruitment technologies?}\\
        All five participants agreed that conforming to \acs{GDPR} when processing data is challenging. Only one participant gave a definite answer to the transparency question and mentioned that labeling \acs{AI} use and focussing on the unbiased treatment of all applicants is critical to maintaining transparency. Furthermore, this participant mentioned that \acs{AI} tools should focus on fact matching, and humans should randomly check tool decisions. Another participant mentions that the \acs{EU AI Act} may further complicate the usage of \acs{AI} in human resources. One other recruiter mentioned that disproportionate work may be done to protect incoming \acs{CV} data. In contrast, any web crawler can scrap the same data off any professional networking site like \textit{LinkedIn}.
        Another two recruiters mentioned that using \acs{AI} tools should be enhanced by learning from past redacted screening documents and decisions not to reveal the applicant's identity. Implementing this model training in a law-conforming way is also a challenge.
        \item \textbf{Would the perceived transparency be better if the \acs{AI} software runs on the user's servers? Moreover, would you send applicant documents to third-party servers, or would you prefer to run the \gls{LLM} software on your servers?}
        All five participants agreed that the perceived transparency would be better with on-premise software.
        Three participants preferred an on-premise solution with one recruiter open to a \acs{SaaS} solution, while two participants preferred a \acs{SaaS} solution.
        These two participants mentioned that also other mission-critical software in their company, like the \acs{ATS}, is already implemented using \acs{SaaS} products, and they see no point in reinstalling an in-house operations team to run on-premise software.
        Both trust the \acs{SaaS} provider to handle their data securely and see \acs{SaaS} as the industry standard.
        \item \textbf{What key legal safeguards should be in place when using these technologies?}
        Only two participants gave a direct answer to this question. They mentioned that each company has to legally verify that its data processing conforms to the \acs{GDPR} when using \acs{AI}-based tools. Furthermore, conforming to the \acs{EU AI Act} in the future will be necessary.
    \end{itemize}
    \item \textbf{Machine Learning as Assistive Technology}
    \begin{itemize}
        \item \textbf{How do you see machine learning complementing human decision-making in \acs{HR}? What balance should be struck between automated and human decision-making in the screening process?}\\
        All five recruiters agreed that \acs{AI}-based tooling should only be used as assistive technology, and the power to make decisions should stay in the human domain. One recruiter mentioned that the tools may be used to preprocess incoming applications and suggest ranking and categorizing candidates into promising and not promising candidates. Another recruiter mentioned an even broader range where \acs{AI}-based tooling can be applied, including the following tasks: transcription, analysis, reporting, and job ad design. The same recruiter proposed that candidate engagement can be boosted by offering good but rejected candidates other suitable currently open job positions determined via \acs{AI}-based applicant-job-matching. Furthermore, the matching technology could be used to find suitable candidates to open positions in internal databases or offered databases constructed from scraped data from professional networking sites like \textit{LinkedIn}.
        A sample provider of such scraped data would be \textit{coresignal}. This matching technology also makes unsolicited applications to recruitment companies more viable, as suitable jobs can be offered to the applicant without the applicant's need to select suitable employment.
        \item \textbf{Are there scenarios where \acs{AI}-assisted technologies should not be used in recruitment?}\\
        Four recruiters gave a definite answer to this question. One recruiter mentioned that applicants for low-skilled jobs may be more challenging to match for \acs{AI}-based tooling as there are very few skills to be used for matching, and some \acs{CV}s are still submitted as hand-written documents. Another recruiter mentioned that if the requirement matching requires domain knowledge underrepresented in the training data of the used \gls{LLM} like the domain of laws, it may be better to carry out the matching by humans to get valid results. Of course, this deficiency may vanish with newer generations of \gls{LLM}s that may or may not incorporate knowledge graphs to source information. A different participant suggests that the model may have difficulties matching job requirements if the personality traits as part of the soft skills should be highly weighted. The last participant proposes a similar scenario and says that if soft skills or empathy should have the most priority, these features are hard to assess by only analyzing text. Therefore, a valid assessment of these skills can only be done by human interaction with the applicant. The same recruiter says that \acs{AI}-based models will be more applicable if hard skills have higher priority or weight, suggesting the technology's use to match technology job applicants for jobs like software engineers or electrical engineers.
        \item \textbf{What are your expectations regarding the efficiency gains from these technologies?}
        All five recruiters agreed they expect efficiency gains within their internal processes by incorporating \acs{AI}-based tooling as assistive technologies. A discussion made clear that advertised gains must be thoroughly tested and verified in the processing pipeline in a repeatable way to be trusted by each of the five human recruiters. Most companies miss this point of internal testing \acs{AI}-based tooling to verify marketing claims.
    \end{itemize}
    \item \textbf{Customization and Adaptability}
    \begin{itemize}
        \item \textbf{How important is customization in \acs{AI}-assisted recruitment technologies for different industries and company cultures?}
        Four of five recruiters agreed that customization of \acs{AI}-assisted recruitment technologies is important regardless of industry or company culture. Only one participant said that customization is unimportant when using machine learning tools in the human resources pipeline.
        \item \textbf{What aspects of the technology should be customizable by the user? How to supply feedback to the model?}
        The suggested configuration parameters defined in \ref{model_configuration} were found to be suitable by all of the five candidates. However, two applicants requested even more possibilities to tune the model output. One of these two recruiters wished to consider the company culture or political affiliation as an additional parameter to the model or any other information that is only present implicitly. With ever-improving \gls{LLM}s, this should be less of a necessity in the future. The other recruiter wanted to add an explicit fading factor to the model that can give the model a hint on how to value experiences regarding certain job requirements that are relevant to the job but are already several years old. The fading valuation of past experiences is handled implicitly by the model, which is an area for improvement.
        \item \textbf{Should the user be able to tweak the model's configuration of requirement extraction, requirement matching, and weighting of the requirement match scores to change the model output, or is a more high-level form of customizability desired?}
        Three out of five recruiters said the proposed configuration parameters are sufficiently abstract. The other two participants requested a more high-level way of configuring the model. One possibility is to supply different validated model configurations that are tailored and explicitly validated for a specific job group and are activatable by specifying the name of that validated configuration. The idea is to provide multiple presets of the model configuration, not just a single default configuration.
    \end{itemize}
    \item \textbf{User Experience}
    \begin{itemize}
        \item \textbf{What are the key factors that make an \acs{AI}-assisted recruitment tool user-friendly?}
        All five recruiters agreed that the user interface must be easy to use, self-explanatory, and intuitive and must present the applicant ranking and categorization in an understandable and visually pleasing way.
        \item \textbf{How should these technologies integrate with existing \acs{HR} systems? Moreover, what are the dominant file types used for applicant documents?}
        Two participants did not answer the integration question. Two other participants preferred an \acs{AI} tool integration with the existing \acs{ATS} by leveraging on-premise or \acs{SaaS} products. Those two recruiters mentioned that the deployment type depends on company guidelines and if the current company software stack is built more around on-premise software or if more \acs{SaaS} products are used. That means if an on-premise database should not be exposed to the public internet or via a VPN server, on-premise products are favorable. Suppose all software components are already used as \acs{SaaS} products. In that case, it makes sense to use further \acs{AI} tools as \acs{SaaS} products as those companies might not need or have a skilled operations team available to manage the hardware infrastructure. The two participants wanted to use the \acs{AI}-enabled tools in \acs{HR} to assist in screening, ranking, and applicant sourcing from internal and external data sources.
        The last participant favored an on-premise \acs{AI} tool to better interface with the existing on-premise infrastructure as outlined before. This applicant only wants to use \acs{AI} tools to source candidates from their internal candidate database as tasks like screening can be quickly carried out by humans for their current amount of incoming \acs{CV}s.
        One recruiter additionally made the critical remark that \acs{AI} tools or third-party tools in general that are operating on data provided by the \acs{ATS} should only act as data processors and not as data warehouses. That means the tools should only temporarily store the data while processing it and not permanently store it.
        This dramatically simplifies data protection and privacy handling to comply with \acs{GDPR} as there is just a single point of truth, not multiple encapsulated systems saving various copies of the same underlying data.
        All five participants agreed that the dominant file types used for applicant documents are the \textit{PDF} and the \textit{Microsoft Word} format.
        \item \textbf{What are your thoughts on third-party \acs{AI} tools in \acs{HR}? Do you prefer a fully integrated solution, or are multiple tools already used?}
        All five recruiters said they prefer a fully integrated solution tightly coupled to the internally used \acs{ATS}.
        One recruiter additionally mentioned that a fully integrated solution is preferred to simplify the usage of the whole software stack for the recruiters and not rely on multiple data import and export functionalities from various third-party encapsulated systems.
    \end{itemize}
    \item \textbf{Candidate Experience} \label{candidate_experience}
    \begin{itemize}
        \item \textbf{What impact do you think \acs{AI} screening will have on the overall candidate experience?}
        All five participants said that they expect a faster overall screening process if \acs{AI} tools are used as assistive technologies in the screening task, as the tool can already check the coverage of mandatory and optional job requirements for each applicant and save the result in a human-readable way. Three out of five recruiters also remarked that recruiters must decide which candidates proceed in the process and which are rejected but can use the output of \acs{AI} tools. Those three participants elaborated further that a rejection letter should not be sent by \acs{AI} tools but should be formulated by a human recruiter to protect the candidate relationship, which is very important for recruitment companies. One other recruiter mentioned that using \acs{AI} tools may have the advantage of reducing the effect of human bias during the screening phase. The input applicant documents to the \acs{AI} tool could be redacted such that no features susceptible to bias are present in the input data. This may include age and gender, for example. Another possibility would be that the \acs{AI} tool ignores such susceptible features overall. The last remaining recruiter remarked that the \acs{AI} tool used during screening should compute the job requirement coverage and list needed follow-up questions to the candidate to clarify unclear or missing information in the \acs{CV}. This may help give candidates with unclear mandatory or optional requirement coverages in their applicant documents a second chance to clarify their abilities instead of sorting them out.
        \item \textbf{How might these technologies improve response times and feedback generation for applicants?}
        All five participants said that they expect a positive impact on the overall candidate experience by improved response times as some of the recruiter's work is already done by the \acs{AI}-enabled tools, and the recruiter can build on the work already done by those tools like job requirement coverage checking per applicant.
    \end{itemize}
    \item \textbf{Previous Experiences with \acs{AI}-assisted Technologies in Human Resources}
    \begin{itemize}
        \item \textbf{What has been your experience with \acs{AI}-assisted technologies in \acs{HR} to date?}
        Three out of five participants had no prior experience with \acs{AI}-assisted technologies in human resources. The other two participants reported that their companies have already tested several \acs{AI} tools within their internal processes that cover almost any aspect of the \acs{HR} pipeline and are readily available. They reportedly tested general-purpose tools in the form of \gls{LLM}s (like \textit{ChatGPT}, for example) and also more specialized and more expensive tools that specifically target needs in the \acs{HR} pipeline. Three out of five participants additionally mentioned that they use \acs{AI} tools like \textit{ChatGPT} for private use and office work not directly related to \acs{HR}.
        \item \textbf{Can you share insights on the general reception, advantages, disadvantages, and areas of improvement for these technologies?}
        Only two recruiters with past \acs{AI} experience could answer this question, and those two participants reported that the general reception was positive. The most essential advantages were seen in process efficiency gains through the time savings that could be achieved. A communicated downside is that the saved time is not guaranteed to be used to improve candidate engagement or process throughput. No participant explicitly mentioned areas for improvements for the used tools.
        \item \textbf{How have these technologies been integrated into the \acs{HR} pipeline in your experience, and in what part of the \acs{HR} process?}
        Only two recruiters who had past \acs{AI} experience could answer this question, and those two participants reported that the used tools were tightly integrated into their existing internal \acs{ATS}. One recruiter reported a \acs{SaaS} deployment of the \acs{ATS}, and the other recruiter reported an on-premise deployment of the \acs{ATS}. These technologies have primarily been used as assistive technology in the applicant screening and candidate sourcing task, as reported by the two participants.
    \end{itemize}
    \item \textbf{Costs}
    \begin{itemize}
        \item \textbf{How do you assess the affordability and cost-effectiveness of \acs{AI}-assisted recruitment technologies?}
        Only two recruiters with past \acs{AI} experience could answer this question, and those two participants reported that it is of utmost importance that the advertised positive effects of \acs{AI} tool usage are tested in-house in a repeatable and valid test setting. That means the test setting must define which metrics should be evaluated using which method. The operating human's situation or environment should be as similar as possible for each test run to gain valid results. Based on such valid metrics, affordability and cost-effectiveness can be assessed by interpreting the results.
        \item \textbf{How do you justify the costs of these technologies with their benefits?}
        Only two recruiters who had past \acs{AI} experience could answer this question, and those two participants reported that justification of such costs is best done by presenting an interpretation of the sourced valid test results of the testing procedure described in the previous point.
    \end{itemize}
    \item \textbf{Open Discussion}
    This enumeration covers points at any time within the interview that were not directly attributable to the above main topics.
    \begin{itemize}
        \item \textbf{Completeness of Job Requirement Types}\\
        All five participating human expert recruiters agreed that the $12$ chosen job requirement types are sufficient for \acs{AI}-enabled screening and matching.
        \item \textbf{More Fine-Grained Weighting}\\
        One recruiter expressed the desire for a more fine-grained weighting of the job requirements in the proposed model.
        Not only should the job requirement types be configurable, but subtypes like the weighting of hardware development skills compared to software development skills within the defined job requirement type \textit{Hard Skills}.
        To implement such a feature, a knowledge graph or some ontology would be necessary so that the model knows which subtypes belong to which parent job requirement type. A complete ontology is also required so that the user can define an appropriate weighting for each job requirement subtype.
        \item \textbf{Information Sourcing Apart From Input Documents}\\
        One participant suggested that the proposed model should be able to source information from other sources besides the input documents.
        For example, the model could query the internet on implicit job requirements not explicitly listed in the job description.
        \item \textbf{Lack of Domain Knowledge}\\
        One recruiter pointed out that in fields that are underrepresented in the training data of the \gls{LLM}, the model might be unable to make accurate decisions due to lacking domain knowledge. The participant has experienced this issue in the domain of law. This limitation may vanish with newer generations of \gls{LLM}s that may or may not incorporate knowledge graphs to source information.
        \item \textbf{Screening Task for State-Owned Enterprises}\\
        One recruiter reported that when screening applicants for state-owned enterprises, rejected candidates can turn to the equal treatment authority to challenge the decision. Then, the recruitment company must give valid reasons for rejecting this candidate. This is a critical point to consider when using \acs{AI}-based tools in the recruitment process of state-owned enterprises, as relying too much on the decision of an \acs{AI} tool might not be a valid enough reason.
    \end{itemize}
\end{enumerate}

\subsubsection{Closure Meeting Discussion Guide} \label{closure_meeting_data}
The transcribed meeting was carefully analyzed and brought into inductively built categories. Due to strict meeting time limits, not all questions from the discussion guide for each topic were answered in the same level of detail by all five human experts. Nonetheless, the resulting coding was tried to be as consistent and representative as possible.
\begin{enumerate}
    \item \textbf{Consistency and Agreement}
    \begin{itemize}
        \item \textbf{How do you perceive the overall accuracy and the consistency between the model's categorization and ordering of applicants compared to the human recruiters' approach? Can you provide specific examples?}
        These questions were tough to answer in the way they were asked after presenting the results to all the participants as there was no consistency between the model's outputs and the human recruiters' outputs possible as even within the human recruiter's outputs, there was very little consistency and very little positive correlation between the individual recruiter's results. That is why the discussion was directed in a way that helps us understand where the drastic differences in human categorization and ranking results come from. Three out of five human recruiters found the categorization and ranking task very hard to carry out as there was no briefing meeting on the expected weightings to use for the various present job requirement types. Furthermore, they mentioned that it was difficult to deal with job descriptions with no company name attached to them, and it was also difficult to handle \acs{CV}s with lesser-known companies in Austria that may not have an office in Austria. Those three recruiters said that they also missed the interaction with the candidates to retrieve missing information by phone or mail, and they also pointed out that an applicant ranking is typically not done at this initial stage of applicant screening. Moreover, these three recruiters said that one other issue was that the required domain knowledge to find suitable candidates for a \textit{Green Hydrogen Piping Engineer} role was eventually not there within the recruiters. One other recruiter mentioned that by looking at the model's results, the differences might originate from the different job requirement type weightings of all recruiters and the model used. This recruiter also pointed out that a human recruiter may handle implicit knockout criteria better than the model and gave a fluent German language proficiency job requirement as an example for store managers working in Austria. Furthermore, the same recruiter elaborated further that the model may be better to score transferable abilities like related programming languages better than a human because it has implicitly learned the underlying ontology and also mentioned the desire to implement the seniority of a position as a knockout criterion for the model as it is also is a knockout criterion for most human recruiters. The last human recruiter also repeated that the low correlations between the human results might originate from different internally used weightings for the various job requirement types as the isolated test situation has not included a briefing meeting. A recruiter may apply a different weighting for each job and maybe even for each applicant based on the applicant's \acs{CV} and the recruiter's internal bias and past experiences. The same recruiter mentioned that the environment where the skill was used is critical to score a skill correctly, as programming at \textit{Google} may differ from coding at a technology startup. This recruiter also noted that the previously mentioned fading factor for scoring past abilities and experiences is significant. Furthermore, the low correlation of the human recruiter's results may also originate from the subjective scoring of the candidates as the screening documents were sometimes quite lengthy and involved creating a very complex task to solve. Two out of five recruiters mentioned that the task was more difficult because the documents were written in non-native English. Three recruiters admitted that the tool might provide good support to rank and categorize applicants with little bias as the job requirement type weighting stays constant for every applicant, yielding fairer results.
        \item \textbf{Did you notice any biases or outliers in the model's output? If so, how do these biases or outliers compare to human recruiters' biases or outliers selected by human recruiters?}
        None of the five participating recruiters mentioned a detected model bias or outliers in the model's results. However, a recruiter mentioned that a human might be able to deal with implicit information in a \acs{CV} better by using past experiences (the human recruiter's bias) or requesting additional information by phone or mail.
    \end{itemize}
    \item \textbf{Explainability and Transparency}
    \begin{itemize}
        \item \textbf{How would you rate the model's ability to explain its decision-making process transparently and understandably?}
        All five recruiters stated that the model's decision-making process was transparent and understandable due to the sensible and detailed explanations for the individual job requirement scores. However, all participants also mentioned that the model results should be visually presented in a more appealing way to make the results even more understandable for less experienced users and to make the model more user-friendly. This is understandable as most decision details are only output in a \textit{JSON} file.
        \item \textbf{Can you give an example of a situation where the model's explanation of its decision was particularly clear or unclear?}
        Four out of five recruiters have not given specific examples where the model's explanation was particularly clear or unclear. The remaining recruiter mentioned that the model's answers were generally apparent and understandable. The same recruiter mentioned that a perfect score was given for two job requirements of type \textit{Location} and \textit{Working Hours}, even though it was only a partial match in the recruiter's opinion. In the first case, the \acs{CV} only mentioned Austria as the candidate's location, and the job was located in Vienna, but the model gave a perfect score. In the second case, the job was a full-time position, but the positions in the candidate's \acs{CV} have not listed the past worked working hours. Still, the model deduced that they were most likely full-time positions, explained that, and noted that, giving a perfect score. That was intentionally designed by design as the used requirement type definitions in the default model config \ref{model_configuration} for these two job requirement types were always intended to yield a perfect match if the applicant explicitly gives no specific preference. This decision was made because most applicants are fine with the advertised job location and working hours. Otherwise, they would not have applied. Generally, it is a good sign that one of the recruiters detected no big job requirement scoring issue.
        \item \textbf{In your opinion, what changes or tweaks could be made to the model's configuration to improve understanding and usability?}
        All recruiters mentioned that the model's output with the individual job requirement scores, including the explanations, should not only be saved as a \textit{JSON} file but also as a table to compare the scores of all applicants for each job quickly. One of those recruiters also mentioned that the model's explanations were too elaborate and should be shortened to contain only the most essential information, probably using bullet points. The same recruiter mentioned that the resulting \textit{CSV} file containing only the total score per applicant where applicants are easily comparable is too high level. The complete model output \textit{JSON} file per applicant contains all individual job requirement scores. It is difficult to compare candidates because the separation of files is too low level and too much information to be scanned by the recruiter. Therefore, maybe the total score per job requirement type should additionally be added to the model's \textit{CSV} output file to please the desire to compare all job applicants better using a tabular view. One other recruiter mentioned that the explanations should be more concise and concrete regarding the given scores, and the weightings of the job requirement types should also be present in the output file. Furthermore, the same recruiter mentioned that the tool should generate follow-up questions as defined in \ref{candidate_experience} that should guide the operating recruiter to the next steps regarding processing the candidate's application.
        \item \textbf{How important do you believe explainability and transparency are in using \acs{AI} for recruitment? Do you think these factors impact user trust and confidence?}
        All five participants mentioned that it is essential that the model's decisions are transparent and understandable. Furthermore, all five recruiters stated that these features are paramount in building user trust and confidence. One recruiter additionally added that especially in times of drastic innovation like the introduction of \acs{AI} in almost all applicable areas, features like explainability and transparency are vital to building up user trust and confidence in new technologies in the beginning until they can be trusted and used with gradually lowered levels of alertness in the future. Moreover, consistent positive experiences with the tool and reliable evidence also help build user trust faster.
    \end{itemize}
    \item \textbf{Open Discussion}
    This enumeration covers points at any time within the interview that were not directly attributable to the above main topics.
    \begin{itemize}
        \item \textbf{Model Applicability for Low-Skilled Jobs}\\
        One recruiter mentioned that categorizing and ranking low-skilled jobs may be challenging for the model due to the low-quality applicant documents in this domain.
        \item \textbf{Variable Job Requirement Type Weightings}\\
        One recruiter mentioned that making the weightings of the model variable per job description or job role type may be a good way to improve the model's accuracy or tune it further in the desired direction. In the current setting, it was difficult to identify a clear optimization target, so this optimization technique could not be applied.
        \item \textbf{Concerns on Model Ranking Accuracy}\\
        One recruiter mentioned that the model should only focus on categorizing applicants into promising and non-promising groups, as their internal tests showed that the ranking before partially structured job interviews could differ greatly from the ranking after those interviews. Furthermore, as one recruiter pointed out, an essential criterion for ranking is interpersonal chemistry between the applicant and the interviewers from the applied company. Also, another recruiter mentioned that for an exact ordering of the candidates, the presented \acs{CV}s were not enough provided information. A further recruiter mentioned that they have some job offerings that receive around $250$ applicants, and a proper categorization tool should filter out the most promising $15$ to $20$ candidates, which would be an enormous process efficiency improvement. The remaining candidates may be cautiously ranked by the tool as assistive work to the recruiter, but this ranking may suffer from the discussed deficiencies. One other recruiter mentioned the possibility of building a categorization tool that only focuses on the clearest knockout criteria that can easily be inferred from the presented \acs{CV}s to make the tool better testable for these criteria. Verifying the results is far easier than obtaining results that account for all job requirements.
        \item \textbf{More Narration on Sample Screening Documents Desired}\\
        One recruiter mentioned that he wished to have more narration surrounding the screening documents, like a description of the company that advertised the job and descriptions regarding the companies of the applicants' individual \acs{CV}s. Even though these companies were actual, they were lesser known in Austria, and this information may be essential to human recruiters. One other recruiter mentioned that this kind of narrative information was not necessary for categorizing applicants by using only the most critical knockout criteria. Also, the addressed ambiguity of the recruiters was part of the categorization and ranking task of the applicants.
        \item \textbf{Unclear Ground Truth}\\
        To compute error metrics for the human and model results, there needs to be a clear ground truth to calculate the error. As the results from the human recruiters had such a low correlation, it is simply not possible to derive a clear ground truth from those human results. The low amount of samples further enforced this. Two recruiters mentioned that this problem of lacking a clear ground truth in several \acs{HR} process activities also makes it very hard to test \acs{AI} tools in the \acs{HR} domain. The tricky question is with what repeatable procedure and given information can a correct ranking or categorization be retrieved and what properties must an accurate ranking or categorization fulfill. This can be a topic for further research.
        \item \textbf{Hasty Work of Recruiters}\\
        A participant admitted that the categorization and ranking task was hastily done by this recruiter in around six minutes per job description, including screening $8$ candidates. Furthermore, this recruiter mentioned that to produce a better result. It would have been necessary to spend around $20$ to $25$ minutes per job description due to the high complexity of the task originating from the foreign language, the lengthy \acs{CV}s, and some uncommon job positions. Furthermore, it was added that this might also be a source of divergence for the human results, and given more time, the results would have been closer together.
        \item \textbf{Model Feedback Handling}\\
        One participant pointed out that it is essential that the model can learn from past mistakes, whether this is via a dense feedback signal where individual scores of requirements are adjusted or from a sparse feedback signal where only the applicant categorization is changed. This recruiter believes the proposed model should be fine-grained to meet internal recruiting standards or guidelines. This recruiter further clarifies that seasoned and skilled recruiters should calibrate the model but admits that for this configuration work, a different skillset is necessary compared to regular work in the \acs{HR} sector. This participant also reinforced that transparency of such assistive technologies is a critical property that must be fulfilled.
        \item \textbf{Sourcing from Candidates}\\
        One participant also mentioned that many recruiting companies have an internal database with past applicants that could be filtered more effectively with the proposed model. This recruiter mentions that by filtering the candidates with already available course filters, the entire candidate pool can be trimmed down to a few $100$s of applicants. Furthermore, the same participant elaborated that using the proposed model to further fine filter this prefiltered pool, the candidates could be trimmed down to a few $10$s of applicants or even fewer such that the human recruiters can further process them. A significant time saving is involved here as the model can process the applicants in a fraction of the time a human recruiter would need to process the same number of applicants. Another recruiter mentioned that the fine filter based on the proposed model can be configured freely because the applicants' attached total score can arbitrarily set the threshold to match the expected filter strength.
        \item \textbf{Implicit Job Requirements}\\
        One recruiter suggested that the model should have a dedicated pipeline step to augment the found job requirements with implicit job requirements not explicitly given in the job description. This could be done by querying the Internet for the job title and the company name and analyzing the job description for implicit requirements. This recruiter mentioned that this step is crucial as the model may not find all implicit requirements by analyzing the job description alone.
    \end{itemize}
\end{enumerate}

\subsection{Quantitative Research}
This section describes what quantitative data was retrieved.
The experiment results (applicant ranking, applicant promising categorization, and human expert time usage) were extracted from the online form submissions.
The results are aggregated, and the resulting data is presented below.

\subsubsection{Online Form for Experiment Results}
As \textit{Google Forms} was used to retrieve the responses from the human recruiters, the data was directly available as a downloadable \textit{CSV} file when all reactions came in. The categorization and ranking results of the human recruiters will be presented in the analysis chapter. Still, the tracked time of the participating human recruiters can be found in the following table:
\csv{taken_time}{Tracked Taken Time in minutes by Human Recruiters}{1.0}

\chapter{Analysis} \label{analysis}

\section{Analysis of a Sample Model Output} \label{analysis_sample_output}
A sample output of the model was generated by running the proposed model on the provided sample job description for the position \textit{Digital Design Engineer} and the applicant \acs{CV}s of candidate $1$ called \textit{Bao Neilan} and candidate $8$ called \textit{Emanuelle Fought}. This was done to briefly discuss the generated output files of the model and their contents and to understand how the model made its decision. The model creates the already mentioned \textit{CSV} file that briefly summarizes the model's decision, which was further enhanced by the human recruiters' feedback to include the mean scores for each present job requirement type to compare the candidates in a tabular view better visually. This table is the \textit{CSV} output for the described screening document set:
\csv{sample_job_match_result}{Sample Job Match Result Overview}{1.0}
This view makes it very easy for human recruiters to compare individual candidates for a single job description in various ways. As the candidates are transparently sorted in descending order by the promising flag first and then by the total score as described in \ref{output_data_postprocessing}, the recruiter can also start working from the top of the list and work their way down, and this immediately aligns with the priority that each candidate should get according to the model. The total score is computed according to the weighting of the job requirement types, which are set in the configuration of the model \ref{model_configuration}. If the recruiter wants to dive deeper into the mean score for a specific job requirement type or the explanation for the promising decision, the mentioned \textit{JSON} file per job applicant can be consulted. This information is only present there as textual explanations are not very suited to be displayed in a compact \textit{CSV} file that should provide a concise overview. The following presented outputs are excerpts from the candidate \textit{JSON} file. For example, the explanation for the promising result of candidate $1$ is given by the model as follows:
\json{candidate_1_promising_result}{Promising Result Explanation for \textit{Bao Neilan}}
The promising result of candidate $8$ is given by the model with this explanation:
\json{candidate_8_promising_result}{Promising Result Explanation for \textit{Emanuelle Fought}}
By reviewing the job descriptions' requirements and the candidates' abilities as presented in their \acs{CV}s, the model's decision seems to be perfectly valid.
Furthermore, the candidates can be compared by analyzing the model output for the job requirement type \textit{Hard Skills}.
The model extracted the following job requirement for this category from the job description and scored the requirement like this for candidate $1$:
\json{candidate_1_hard_skills_result}{Requirement Matches of Type \textit{Hard Skills} for \textit{Bao Neilan}}
The same extracted requirement was also scored for candidate $8$:
\json{candidate_8_hard_skills_result}{Requirement Matches of Type \textit{Hard Skills} for \textit{Emanuelle Fought}}
The model seems to understand the provided information in the job description quite well and creates an extracted requirement that contains a concise specification and whether this requirement is \textit{mandatory} or \textit{optional}. Furthermore, the requirement is adequately matched to the applicant's \acs{CV} by providing a score accompanied by a textual explanation of that score. To also supply an example of an \textit{optional} requirement, the matched requirements of candidate $1$ for the job requirement type \textit{Languages} are given in the following listing:
\json{candidate_1_languages_result}{Requirement Matches of Type \textit{Languages} for \textit{Bao Neilan}}
The model correctly separates the two language requirements for the job description and assigns the correct requirement type. The scoring of the requirements also seems to be appropriate when analyzing the applicant documents. That overview should have given the reader a good overview of what output files and output information the human recruiter can expect from the proposed model. The complete model output in \textit{JSON} format for both applicants can be found in the appendix under \ref{lst:match_result_candidate_1} and \ref{lst:match_result_candidate_8}.

\section{Quantitative Result Analysis}
The following sections analyze the accuracy of the model for the applicant ranking task and the applicant categorization task that divides the applicants into promising and non-promising candidates. Furthermore, the time savings and the costs associated with the model usage are presented.

\subsection{Categorization Accuracy}
The results of the categorization task were analyzed using the Hamming distance as defined in \ref{quantitative_research_design}, but there was no estimated ground truth computed as the mean human categorization. That decision was made as the mean Hamming distance from each recruiter's results to their results, the other recruiters' and the model's results were around $3$, and the Hamming distance did not significantly increase that value to the model's results as we can see later. That means three applicants will be categorized differently when comparing two human recruiters' categorizations. As this result was unexpected and the high variance and uncorrelatedness would yield a quite random mean value, it was chosen not to compute the estimated ground truth that way. Without estimated ground truth, no error signal could also be calculated. The error signal would have been very biased either way, as when comparing a value against the estimated ground truth with a sample size of $5$, the compared value contributes $20\%$ to the mean value. Of course, this probably leads to a smaller error value. Therefore, it was chosen to compare all the resulting values from each human recruiter and the model using a distance matrix by job description and a mean distance matrix across all job descriptions. That way, it can be seen if one or more result-producing entities have a significantly higher distance from the other entities and are, therefore, less similar. That would mean that if the model results were not similar to the human results, they would have the highest mean distance from the other entities. These are the resulting distance matrices:
\csv{export_specialist_hamming_distance_distance_matrix}{Hamming Distance Matrix for the \textit{Export Specialist}}{1}
\csv{embedded_software_engineer_hamming_distance_distance_matrix}{Hamming Distance Matrix for the \textit{Embedded Software Engineer}}{1}
\csv{green_hydrogen_piping_engineer_hamming_distance_distance_matrix}{Hamming Distance Matrix for the \textit{Green Hydrogen Piping Engineer}}{1}
\csv{validation_and_qualification_engineer_hamming_distance_distance_matrix}{Hamming Distance Matrix for the \textit{Validation and Qualification Engineer}}{1}
\csv{store_manager_hamming_distance_distance_matrix}{Hamming Distance Matrix for the \textit{Store Manager}}{1}
\csv{digital_design_engineer_hamming_distance_distance_matrix}{Hamming Distance Matrix for the \textit{Digital Design Engineer}}{1}
\csv{mean_hamming_distance_distance_matrix}{Mean Hamming Distance}{0.3}
Job descriptions with a higher mean Hamming distance across human recruiters and the model provided a more complex categorization task. For example, the more common job description \textit{Export Specialist}, where less domain knowledge is needed to match requirements, had a mean Hamming distance of $2.28$. In comparison, the less common job description \textit{Green Hydrogen Piping Engineer}, where more domain knowledge is needed to match requirements, had a mean Hamming distance of $3.17$. This was already expected in the meetings by the human recruiters. As can be seen in table \ref{tab:mean_hamming_distance_distance_matrix}, if the labels of the result-producing entities would not be here, one would assume that the second row is from the proposed model as it has the highest mean distance with $3.806$ to all the other results. The proposed model's results were similar to the human results as it had the second lowest mean Hamming distance with $2.917$ to all the other results. This is a great result and shows that the model is likely well suited to categorize applicants into a promising and a non-promising group. Of course, the results of the proposed model have to be replicated on a grander scale with a higher sample size to provide statistical support to this hypothesis. This is also necessary as the mean Hamming distances between all the results are still relatively high. In the mean, the proposed model classified around $4.17$ candidates as non-promising, and the human recruiters classified around $3.73$ candidates as non-promising out of the $8$ candidates supplied for each job description. That means even the number of filtered applicants was similar between the proposed model and the human recruiters. Maintaining a small Hamming distance between the individual results is also necessary.

\subsection{Ranking Accuracy}
The results of the ranking task were analyzed using Kendall's Tau as defined in \ref{quantitative_research_design}, but there was no estimated ground truth computed as the mean human ranking. That decision was made as the mean Kendall's Tau correlation coefficient from each recruiter's results to their results, the other recruiters' results, and the model's results were around $0.2$, and that value was not significantly lowered by Kendall's Tau correlation coefficient to the model's results as we can see later. When comparing two human recruiter's rankings, the correlation is relatively low in the mean as results closer to $0$ are more and more uncorrelated. As this result was unexpected and the high variance and uncorrelatedness would yield a quite random mean value, it was chosen not to compute the estimated ground truth that way. Without estimated ground truth, no error signal could also be calculated. The error signal would have been very biased either way, as when comparing a value against the estimated ground truth with a sample size of $5$, the compared value contributes $20\%$ to the mean value. Of course, this probably leads to a smaller error value. Therefore, it was chosen to compare all the resulting values from each human recruiter and the model using a correlation matrix by job description and a mean correlation matrix across all job descriptions. That way, it can be seen if one or more result-producing entities have a significantly lower correlation to the other entities and are, therefore, less similar. That would mean that if the model results were not similar to the human results, they would have the lowest mean correlation with the other entities. These are the resulting correlation matrices:
\csv{export_specialist_kendall_tau_correlation_matrix}{Kendall's Tau Correlation Matrix for the \textit{Export Specialist}}{1}
\csv{embedded_software_engineer_kendall_tau_correlation_matrix}{Kendall's Tau Correlation Matrix for the \textit{Embedded Software Engineer}}{1}
\csv{green_hydrogen_piping_engineer_kendall_tau_correlation_matrix}{Kendall's Tau Correlation Matrix for the \textit{Green Hydrogen Piping Engineer}}{1}
\csv{validation_and_qualification_engineer_kendall_tau_correlation_matrix}{Kendall's Tau Correlation Matrix for the \textit{Validation and Qualification Engineer}}{1}
\csv{store_manager_kendall_tau_correlation_matrix}{Kendall's Tau Correlation Matrix for the \textit{Store Manager}}{1}
\csv{digital_design_engineer_kendall_tau_correlation_matrix}{Kendall's Tau Correlation Matrix for the \textit{Digital Design Engineer}}{1}
\csv{mean_kendall_tau_correlation_matrix}{Mean Kendall's Tau Correlation}{0.3}
Job descriptions with a lower mean Kendall's Tau correlation coefficient across human recruiters and the model provided a more complex ranking task. For example, the more common job description \textit{Export Specialist}, where less domain knowledge is needed to match requirements, had a mean Kendall's Tau correlation coefficient of $0.26$. In comparison, the less common job description \textit{Green Hydrogen Piping Engineer}, where more domain knowledge is needed to match requirements, had a mean Kendall's Tau correlation coefficient of $0.11$. This was already expected in the meetings by the human recruiters. As can be seen in table \ref{tab:mean_kendall_tau_correlation_matrix}, if the labels of the result-producing entities would not be here, one would assume that the fifth row is from the proposed model as it has the lowest mean correlation coefficient with $0.185$ to all the other results. The proposed model's results were similar to the human results as it had the second highest mean Kendall's Tau correlation coefficient with $0.248$ to all the other results. This excellent result shows that the model is likely well-suited to rank applicants to prioritize work according to this proposed ranking. Of course, the results of the proposed model have to be replicated on a grander scale with a higher sample size to provide statistical support to this hypothesis. This is also necessary as the mean Kendall's Tau correlation coefficient between all the results is still relatively low.

\subsection{Time Savings associated with the Model Usage}
The tracked times of the human recruiters have already been presented in \ref{tab:taken_time}. The following table presents the tracked execution time of the proposed model:
\csv{taken_time_model}{Tracked Taken Time in minutes by Model}{0.5}
The mean time for the categorization and ranking task for a single job with $8$ applicants was around $21.60$ minutes by human recruiters and $1.04$ minutes by the proposed model. That means the proposed model uses around $95\%$ less time to rank and categorize the applicants than the human recruiters. A faster \gls{LLM} like the \textit{GPT-3.5 Turbo} model can bring this savings percentage even closer to $100\%$. The open question that must be answered in future research is how to compare the quality of the human recruiters' and the proposed model's results in terms of quality and accuracy to understand the tradeoffs of the saved time by \acs{AI} assistance. Unfortunately, the limited sample size and low correlation of the human recruiters’ data do not allow a satisfactory answer.

\subsection{Costs associated with the Model Usage}
The costs of operating the proposed model are determined by the hardware needed to run the \textit{Python} program and the costs associated with the third-party \gls{LLM} usage via an API.
As the costs of the \gls{LLM} usage are far greater than the costs of the hardware usage, the costs of the \gls{LLM} usage will be solely analyzed in more detail to present the involved costs of the proposed model usage. The cost of the used \gls{LLM} \textit{GPT-4 Turbo} is determined by the input tokens supplied to the model and the output tokens generated by the model. The amount of input tokens is determined by the sizes of the input documents and the configured prompts that include these input documents. Those prompts can be changed in the model's configuration \ref{model_configuration}. The amount of output tokens is determined by the input tokens as those are formulating a question or prompt to the model and the parameters and model structure of the used \gls{LLM}. That means a third-party \gls{LLM} provider might want to give lengthy answers to bill more output tokens to their customers. Of course, such a problem can be weakened by prompt engineering, which means asking the model to be concise as part of the text converted to the input tokens. The cost was not analyzed on a per-job basis. Still, instead, the proposed model was triggered to compute all rankings and categorizations for all six jobs with eight applicants each. Then, the summed-up costs were divided to approximate the actual cost per applicant. That means that, in total, around $960000$ input tokens have been supplied to the model, and around $110000$ output tokens have been generated by the model to fulfill the specified workload. At the time of writing, the provider \textit{OpenAI} billed $10\$$ for one million input tokens and $30\$$ for one million output tokens for the \textit{GPT-4 Turbo} model, which was used for this thesis' results \parencite{openai_pricing}. That does not seem much, but sending large amounts of texts repeatably to the model quickly adds up. The total cost of operation for the specified workload was around $13\$$. That means that the average cost for each of the $48$ applicants was around $0.27\$$. As the job requirements only need to be extracted once for all applicants for a job, the cost per applicant decreases if more applicants are present for a job.
Still, the main junk of \gls{LLM} costs can be attributed to the requirement matching per applicant. That cost could be reduced by using the \textit{GPT-3.5 Turbo} model instead of the \textit{GPT-4 Turbo} model with the tradeoff of its inferior general reasoning capability as reported by several benchmarks. \textit{OpenAI} offers \textit{GPT-3.5 Turbo} at the price of $0.5\$$ for one million input tokens and $1.5\$$ for one million output tokens. That would approximately yield a cost of $0.013\$$ for each applicant, assuming this model generates a similar amount of output tokens. Another advantage is the much greater execution speed of the \textit{GPT-3.5 Turbo} model, which produces the model results significantly faster. Future research must be carried out to assess how much quality is sacrificed using the \textit{GPT-3.5 Turbo} model. That means there is a tradeoff of probably quality, cost, and execution time in choosing either model.
In the future, the current flagship models will presumably also be offered at much lower prices by \textit{OpenAI}, as the same happened to the \textit{GPT-3.5 Turbo} model.

\section{Kick-Off Meeting Result Analysis}
In this section, a careful analysis per topic on the interview data collected in the kick-off meeting \ref{kick_off_meeting_data} is done. The data will be interpreted and concisely summarized. If a more detailed view of the data is desired, please consult \ref{kick_off_meeting_data}. The topics belonging to the open discussion will be analyzed in \ref{open_discussion_result_analysis}.

\subsection{Bias and Fairness}
In the kick-off meeting, most recruiters acknowledged encountering bias in \acs{AI}-assisted recruitment technologies, with four out of five noting definite biases. They emphasized the necessity of continuous evaluation and feedback mechanisms to refine \acs{AI} decision-making processes. Strict and generally applicable guidelines must be set to test the \acs{AI} tool output against a predefined verification document. All participants unanimously recognized the importance of designing \acs{AI} systems that ensure fairness and avoid discrimination, highlighting the challenge of creating unbiased tools given inherent human biases. Ethical considerations were also universally agreed upon, with the primary concern being the fair treatment of all candidates, ensuring that decision-making criteria are strictly job-related and do not include factors like gender, race, or age. This can be ensured by supplying masked data to the \acs{AI} systems that do not contain information susceptible to bias. This underscores the critical need for configurable, learning \acs{AI} systems that can adapt and improve over time to minimize biases.

\subsection{Accuracy and Reliability}
In the kick-off meeting, all five participants viewed \acs{AI} technologies in \acs{HR} as supportive tools that suggest candidate rankings or categorizations, with final decisions still resting with human recruiters. They concurred that \acs{CV} layout minimally impacts screening decisions, except in creative roles, and noted a cultural preference in Central Europe for \acs{CV}s that include applicant photos, contrasting with more neutral \acs{CV}s in Northern Europe and America. Concerning \acs{AI}'s ability to match job requirements with diverse qualifications, only one recruiter highlighted potential difficulties, such as handling implicit job requirements and ambiguities in natural language, typically resolved by human recruiters through direct communication. There was also a mention of \acs{AI} potentially being used to optimize \acs{CV} presentations, with a caution against fabricating qualifications. Conversely, the quality of the proposed model's matching result depends on the applicant documents' truthfulness, quality, and machine-readability. Handwritten \acs{CV}s are currently not supported, and \acs{CV}s with lots of missing data might also not be matched correctly. Furthermore, in some very specialized fields like processor design or laws, reasonable domain knowledge is necessary to match candidates' abilities to the job description requirements accurately. The internal matching of the proposed model might not work well in all cases, as some specialized areas might be underrepresented in the training data.

\subsection{Legal Considerations}
In the kick-off meeting, legal challenges associated with implementing \acs{AI} in \acs{HR} processes were primarily centered around \acs{GDPR} compliance and maintaining transparency in \acs{AI}-assisted recruitment. Participants highlighted the importance of labeling \acs{AI} usage, obtaining the necessary confirmations, and ensuring unbiased treatment of applicants to enhance transparency. The discussion also discussed the potential complications the upcoming \acs{EU AI Act} introduced. Regarding data handling, there was a consensus on the benefits of on-premise software for perceived transparency. However, opinions were divided between preferring on-premise solutions and \acs{SaaS}, with some citing existing reliance on \acs{SaaS} for other critical operations.
Furthermore, \acs{SaaS} solutions may also have the advantage of abstracting away the operation side of the software, which can also prevent exposing the internal company data to massive cybersecurity threats, even more so if the operation team is not highly skilled. It will not often be the case that recruiting-focused companies have such a dedicated operation team. Fundamental legal safeguards suggested included strict adherence to \acs{GDPR} and preparation for the \acs{EU AI Act}, emphasizing the need for legal verification of \acs{AI} tools' data processing activities. It might also be a good idea only to process, not store data in in-house or third-party \acs{AI} tools and only feed the \acs{AI} tools with redacted or masked data to minimize the impact in case of data breaches of temporarily stored information. The redaction and masking also prevent third-party providers from collecting and connecting valuable information from multiple customers.

\subsection{Machine Learning as Assistive Technology} \label{interpretation_ml_as_assistive_technology}
In the kick-off meeting, all five recruiters concurred that machine learning should be an assistive tool in \acs{HR}, enhancing but not replacing human decision-making. They suggested its application in preprocessing applications, suggesting candidate rankings, and aiding in tasks like transcription and job ad design. \acs{AI} could also improve candidate engagement by suggesting alternative positions for promising but rejected applicants and identifying potential candidates from internal and external databases, such as the \textit{LinkedIn} database provided by \textit{coresignal}. For the candidate sourcing use case, the used \acs{AI} tool must operate incredibly fast and cheaply to process thousands of applicants for a reasonable price tag. At the current price tag of flagship \gls{LLM}s, a couple of years of research is still needed until smaller models with fewer parameters achieve the expected accuracy to execute the matching task with an \gls{LLM} architecture at a price tag suited for massive parallelism. The recruiters noted limitations for roles requiring high empathy or soft skills, which are best tested through direct human interaction, and low-skilled positions where \acs{AI} might struggle due to insufficient provided information, data quality, and machine-readability caused by hand-written applicant documents. Recruiters expected efficiency gains and emphasized the necessity of valid, repeatable, and internal testing to affirm the efficiency claims of \acs{AI} tools. This highlights a gap in current practices where such technologies are often not rigorously tested within the company's processes before being adopted.

\subsection{Customization and Adaptability}
In the kick-off meeting, the importance of customization in \acs{AI}-assisted recruitment technologies was emphasized, with four out of five recruiters advocating for its necessity across various industries and company cultures. The discussion highlighted the need for more customization options for the technology, with suggestions for additional features like incorporating company culture or political affiliations and adjusting the model's handling of outdated experiences by introducing an explicit fading factor. While all recruiters agreed on the suitability of the current configuration parameters, there was a desire for more user-friendly customization options. That can be solved by including high-level configuration presets tailored to specific job groups to simplify the process and enhance the model's adaptability to different recruitment scenarios. Those presets could be given as a starting point to recruitment companies, who could then tune their experiences separately for each targeted job group.

\subsection{User Experience}
In the kick-off meeting, all five recruiters emphasized the importance of a user-friendly interface for \acs{AI}-assisted recruitment tools, highlighting the need for ease of use, intuitiveness, and clear visual presentation of applicant rankings. That point was improved by altering the \textit{CSV} output of the proposed model. Integration preferences with existing \acs{HR} systems varied, with some recruiters favoring on-premise \acs{AI} tools to align with existing on-premise infrastructure. At the same time, others preferred \acs{SaaS} products as some other critical software is based on \acs{SaaS}. The deployment type depends on the company's existing software environment and operational capabilities. The consensus was that \acs{AI} tools should integrate seamlessly with the current \acs{ATS} and function primarily as data processors, not data warehouses, to simplify compliance with \acs{GDPR} by avoiding permanent data storage. The preferred file types for applicant documents were identified as \textit{PDF} and \textit{Microsoft Word}, both supported by the proposed model. Overall, there was a strong preference for a fully integrated \acs{AI} solution that enhances the functionality of the \acs{ATS} without complicating the data management landscape and software interaction flow. To fully integrate a third-party solution with an already deployed \acs{ATS}, the degree of modularity of the \acs{ATS} is crucial. The \acs{ATS} must either support features like plugins with a defined interface, an \textit{API} to the \acs{ATS} to transfer data or the possibility to link custom webhooks to specific events in the software, for example.

\subsection{Candidate Experience}
In the kick-off meeting, all five participants agreed that \acs{AI} screening tools would expedite the candidate screening process by automating the evaluation of job requirement coverage, thus enhancing the overall candidate experience with quicker response times and probably fairer screening document evaluation. However, three recruiters emphasized the importance of human involvement in final decision-making and personalized communication, particularly in rejection scenarios, to maintain candidate relationships. Additionally, one recruiter highlighted the potential of \acs{AI} to reduce human bias by redacting or ignoring sensitive information like age and gender in application documents. Another recruiter suggested that \acs{AI} tools should assess requirement coverage and generate follow-up questions for candidates, thereby offering a chance to clarify any ambiguities and fill in missing information in their applications, potentially giving them a second chance in the screening process. This proposed new feature is a great way to mimic even a more significant portion of the human screening process by the proposed model to boost screening efficiency. 
Moreover, the proposed model could also automatically initiate communication with candidates regarding necessary follow-up questions in the future. Probably in the future, it might also be common practice to automatically send carefully constructed and individualized rejection letters generated by \acs{AI} to applicants. However, no company would like to admit this practice.

\subsection{Previous Experiences with \acs{AI}-assisted Technologies in Human Resources}
The kick-off meeting revealed that three out of five participants had no prior experience with \acs{AI}-assisted technologies in \acs{HR}. At the same time, the remaining two had utilized various \acs{AI} tools, including both general-purpose models like \textit{ChatGPT} and specialized tools, across nearly all \acs{HR} processes. These experienced users reported positive feedback, highlighting significant efficiency gains and time savings. However, it was noted that this saved time was not always redirected toward enhancing candidate engagement or process throughput. The integration of \acs{AI} technologies occurred mainly in applicant screening and candidate sourcing, with these tools being incorporated into the company's existing \acs{ATS}, either through \acs{SaaS} or on-premise deployments. The participants identified no specific areas for improvement. As \acs{AI}-assisted technologies are still in the early stages of adoption in the \acs{HR} sector, the lack of identified areas for improvement may be due to the limited exposure of the participants to these tools. 
Moreover, time will tell what additional workloads \acs{AI} will carry out instead of humans, given another three to five years of continuous improvements in research. It seems like \acs{AI} will sooner or later be able to replace all the human workforce interacting with just computers and doing no manual labor, especially in non-creative environments. Advanced robots will tackle manual labor automation, but this innovation needs more time. The positive feedback from experienced users, even in this early stage, suggests that \acs{AI} technologies have the potential to significantly enhance and disrupt \acs{HR} processes in the future.

\subsection{Costs}
In the kick-off meeting, only two recruiters with prior \acs{AI} experience discussed the costs associated with \acs{AI}-assisted recruitment technologies. They emphasized the necessity of conducting in-house, repeatable, and valid tests to evaluate the advertised benefits of \acs{AI} tools. These tests should have predefined metrics and consistent conditions to ensure validity. The affordability and cost-effectiveness of these technologies can then be assessed by analyzing the outcomes of these tests. Furthermore, the justification for the costs of \acs{AI} technologies is best supported by presenting data from these valid tests, linking the benefits directly to the expenses incurred. For example, a metric that could be analyzed is the reduced working time for a defined task. As this time can be converted to costs, it can be directly compared to the costs of the used \acs{AI} tool. Of course, amortization may significantly impact the used \acs{AI} tool cost for comparison. If the \acs{AI} tool is billed by usage, then amortization may have little effect, but if there are specific license plans, then amortization may come into effect guided by the adoption rate of the \acs{AI} tool.

\section{Closure Meeting Result Analysis}
In this section, a careful analysis per topic on the interview data collected in the closure meeting \ref{closure_meeting_data} is done. The data will be interpreted and concisely summarized. If a more detailed view of the data is desired, please consult \ref{closure_meeting_data}. The topics belonging to the open discussion will be analyzed in \ref{open_discussion_result_analysis}.

\subsection{Consistency and Agreement}
During the closure meeting, there was a significant discrepancy between the model's and human recruiters' categorization and ranking of applicants, primarily due to inconsistencies and low correlation of the categorization and ranking results among the recruiters themselves. Three out of five recruiters highlighted difficulties in categorizing and ranking without predefined criteria usually set up in briefing meetings and struggled with job descriptions lacking specific company names or \acs{CV}s featuring lesser-known companies. They also miss direct interactions with candidates, which are crucial for gathering additional information, and typically do not rank applicants at the initial screening stage. The isolated task environment was necessary for reproducible results and the same environment for every recruiter. The lack of domain knowledge for specific roles like the \textit{Green Hydrogen Piping Engineer} was a challenge. One recruiter noted that differences might stem from varying job requirement weightings used by individuals and the model, suggesting that the model could better assess transferable skills or abilities due to its underlying learning of well-covered fields like programming in its training data.
The same recruiter proposed incorporating seniority as a knockout criterion in the model, mirroring human practices. Another recruiter emphasized the importance of the context in which skills are used, such as programming at a significant company versus a startup, as the company culture may be vastly different, and highlighted the significance of a fading factor for scoring past abilities. The discussion also touched on the potential of the proposed \acs{AI} tool to support less biased applicant ranking and categorization, as it maintains a consistent job requirement type weighting across applicants, contrasting the suspected varying and subjective weighting of the human recruiters. No biases or outliers were reported in the model's output. However, one recruiter mentioned that humans might better handle implicit or missing \acs{CV} information through personal experience or additional inquiries. Some recruiters said the task complexity was higher due to the English screening documents. English is a language that is non-native to human recruiters. This setting was chosen as most \gls{LLM} training data is in the English language, so this should be preferable for the proposed model. The model implementation later worked around that by translating the model input text to English and the model output text to the configured output language.
Another point that may have influenced the human ranking and categorization result is that, in varying degrees, most candidates were considered suitable for the job description. That means most candidates were never wholly unsuitable for the applied job by working in a different domain or lacking several mandatory requirements, for example. This led to the fact that very few candidates per job were as bad to clearly and easily filter them out, and the rest were hard to rank due to this circumstance. In reality, such applications where mandatory requirements are missing might occur as well or more often than in the sample screening documents, and the model must also be tested better against that scenario in the future. Still, the results for such cases in \ref{analysis_sample_output} look promising.

\subsection{Explainability and Transparency}
In the closure meeting, all five recruiters affirmed the transparency and understandability of the \acs{AI} model's decision-making process, attributing this clarity to detailed explanations for job requirement scores. However, they suggested enhancing visual presentation and simplifying explanations to aid less experienced users. The tabular result presentation of the proposed model was implemented after the recruiters gave their feedback and made the applicants easier to compare by each job requirement type. While most recruiters did not provide specific instances of clarity or confusion in the model's explanations, one noted discrepancies in scores for job requirements like location and working hours, which were deemed perfect matches by the model despite very ambiguous provided information in the \acs{CV}s. This is a configuration choice of the model, as most applicants are fine with the location or working hours when applying for a job. To improve usability and time savings related to model usage, recruiters recommended making explanations more concise. They unanimously agreed on the importance of explainability and transparency in building user trust and confidence in \acs{AI}-driven recruitment, emphasizing that these features are essential to foster user trust through consistent, positive experiences, especially during initial phases of technology adoption. It can be concluded that the way the \acs{AI} model presents its results was generally accepted by all the recruiters. To further improve the usability of the model, a user interface must be built, and several additional feedback rounds and implementation iterations must be carried out with the target group.

\section{Open Discussion Result Analysis} \label{open_discussion_result_analysis}
In this section, a careful analysis per topic on the interview data collected in the kick-off meeting \ref{kick_off_meeting_data} and closure meeting \ref{closure_meeting_data} is done that belonged to the open discussion. The data will be interpreted and concisely summarized. If a more detailed view of the data is desired, please consult either \ref{kick_off_meeting_data} or \ref{closure_meeting_data}.

\subsection{Completeness of Job Requirement Types}
The consensus among the five expert recruiters involved in the kick-off meeting is that the twelve selected job requirement types are adequately comprehensive for \acs{AI}-enabled screening and matching processes. This unanimity suggests a strong validation of the chosen criteria, indicating their potential effectiveness in enhancing recruitment efficiency through \acs{AI} technology. Multiple online and offline sources were consulted to find the source \textcite{job_requirement_types}, which had the biggest inspiration for the used enumeration. Some changes were applied to the proposed categories as the \textit{Skills} requirement type was split up into \textit{Soft Skills} and \textit{Hard Skills} to differentiate between the better valid scoring of \textit{Hard Skills} by \acs{AI} tools in contrast to the less valid scoring of \textit{Soft Skills}.

\subsection{More Fine-Grained Weighting}
During the kick-off meeting, a recruiter suggested enhancing the proposed model by introducing a more detailed, fine-grained weighting system for job requirements. The recruiter emphasized the need for configurable weightings at the level of main job requirement types and subtypes, such as differentiating between hardware and software development skills within the \textit{Hard Skills} category. A knowledge graph or an ontology was proposed to facilitate this. It would categorize subtypes under their respective main types and allow users to assign specific weightings to each job requirement subtype, ensuring a tailored and precise evaluation framework. This would surely make the proposed model more configurable, but it also raises the bar on the required knowledge and skill set of the recruiters responsible for configuring the model. These recruiters must now create an ontology of selected job requirement types and assign weighting to all defined subtypes if a more fine-grained weighting is desired. Future tests must be conducted to prove the expected accuracy gains by this additional way of configuring the model.

\subsection{Information Sourcing Apart From Input Documents} \label{interpretation_sourcing_from_internet}
During the kick-off meeting, it was proposed that the model should extend its capability beyond analyzing provided input documents by incorporating external information sources. Specifically, the suggestion was made to enable the model to access the internet to gather additional details, such as implicit job requirements not directly mentioned in job descriptions. This enhancement aims to enrich the model's understanding and effectiveness in interpreting job-related data. This addition adds more context to the text input the model currently receives. This additional input could include information about the applied company, the applied domain or field, the applied job position, or the applicant itself. That could lead to better incorporating the company culture or information from the applicant's social media or social networking account sites like \textit{LinkedIn} or \textit{GitHub} in the final decision.

\subsection{Lack of Domain Knowledge}
In the kick-off meeting, a recruiter highlighted a significant limitation of the \gls{LLM} concerning its decision-making accuracy in underrepresented fields, exemplified by the domain of law. This issue stems from the model's lack of domain-specific knowledge, which could be mitigated in future iterations of \gls{LLM}s that might integrate knowledge graphs to enhance information sourcing and the model's context. Another possibility to reduce this shortcoming is to use \gls{LLM}s trained with more varied training data or \gls{LLM}s that are fine-tuned on a specific domain. As the training data of \gls{LLM}s increases in size and variety with each generation, the question will always be where to get this high-quality training data, as the amount and quality of training data determines the trained model's performance. The quality of training data and innovations in the model architecture of \gls{LLM}s will be the next driving forces for the next generations of \gls{LLM}s as every major provider already uses all worldwide and publicly available text as training data.

\subsection{Screening Task for State-Owned Enterprises}
In the recruitment process for state-owned enterprises, it is crucial to handle rejections with care, as candidates can appeal to equal treatment authorities if they believe the decision was unjust. This necessitates that recruitment companies prepare to substantiate their decisions with concrete reasons. The use of \acs{AI} tools in this context poses a significant challenge as reliance solely on \acs{AI} for decision-making may not suffice as a valid reason for rejection, highlighting the need for a balanced approach that integrates \acs{AI} insights with human judgment to ensure fairness and compliance with regulatory standards. That particular example shows that there are still application areas where \acs{AI} may never fully replace human decision-making due to possible consequences imposed by the replacement.
This might be the case as long as human decision-making is considered superior to \acs{AI} decision-making in common sense.

\subsection{Model Applicability for Low-Skilled Jobs}
The interview data highlights a concern from a recruiter regarding the model's effectiveness in categorizing and ranking low-skilled job applications, primarily due to the poor quality of the sometimes hand-written applicant documents typically found in this sector. This suggests potential limitations in the model's applicability and accuracy when dealing with low-skilled job applications, as optical character recognition must be employed to preprocess the scanned hand-written documents further, for example. Furthermore, if not many skills are required to carry out a job, there is also little matching work for the model, making it harder to rank and categorize the applicants as there are few distinctive features. In this domain, values like punctuality, reliability, and general positive attitude may provide a better basis to determine future job performance, and those cannot be easily inferred by the applicant's \acs{CV}.

\subsection{Variable Job Requirement Type Weightings} \label{interpretation_variable_job_requirement_type_weightings}
In the closure meeting, a recruiter suggested that customizing the job requirement weightings of the model configuration according to specific job descriptions or roles previously mentioned as presets could enhance the overall model's accuracy. Due to the lack of a notion of a correct candidate ranking or candidate categorization, a clear error signal required to optimize configuration parameters could not be derived. This potentially beneficial adjustment was not implemented in the thesis, and the proposed model always used the default configuration. This approach could allow for more tailored and effective model tuning to meet diverse requirements. A potential ranking or categorization that could be used as ground truth to compute the error signal may be derived as the average of many human recruiters' rankings or categorizations.

\subsection{Concerns on Model Ranking Accuracy}
In the closure meeting, recruiters expressed concerns about the accuracy of model rankings for job applicants. They suggested that the model should primarily categorize applicants into promising and non-promising groups rather than rank them, as rankings can significantly change after incorporating information from partially structured job interviews. The interpersonal dynamics between the applicant and the interviewers also play a crucial role in the ranking process, which the model currently does not capture. Additionally, the information provided by \acs{CV}s alone was deemed insufficient for precise candidate ordering. Recruiters highlighted the utility of a tool that could efficiently narrow down large applicant pools (e.g., from $250$ to $20$ of the most suitable candidates), suggesting that beyond this initial categorization, any further ranking should be treated with caution due to inherent and potential inaccuracies. A proposal was also to focus the tool on clear knockout criteria easily identifiable from \acs{CV}s to enhance the tool's testability and reliability. To implement that suggestion, the prompts must be changed to extract only knockout criteria from job descriptions, and the matching pipeline can be trimmed down to just a boolean decision maker. A downside of that approach is that some points advertised as knockout criteria in job descriptions, like several years of mandatory job experience, are often not taken as seriously by recruiters if other candidates' abilities make up for it. Nevertheless, an \acs{AI} tool programmed to filter out candidates based solely on knockout criteria would filter out all candidates who lack job experience. Due to the inherent ambiguity of the natural language, even a tool that just checks knockout criteria might also have its quirks and downsides.

\subsection{More Narration on Sample Screening Documents Desired}
During the closure meeting, recruiters expressed differing opinions on additional narrative information in sample screening documents. One recruiter highlighted the importance of including descriptions of both the advertising company, which was omitted and the real companies mentioned in applicants' \acs{CV}s, particularly when these companies are lesser-known within Austria, suggesting that such context could significantly aid human recruiters. Conversely, another recruiter argued that narrative details were superfluous for categorizing applicants based on essential knockout criteria, indicating that the inherent ambiguity in recruiter perceptions was integral to the applicant evaluation process. It was chosen not to supply that kind of information as ambiguity should be part of the categorization and ranking task, and the company identity of the job advertisements was also chosen to be omitted so as not to bias the recruiters. Nevertheless, it was surprising to notice that such details seem to impact the final decision as company culture and the context of work experiences are crucial information bits for human recruiters.

\subsection{Unclear Ground Truth}
This topic highlights the significant challenge in evaluating human and \acs{AI} performance in \acs{HR} processes due to the absence of a definitive ground truth. This issue was underscored by the low correlation between human recruiters' results and the limited data samples, making it difficult to establish a reliable standard for measuring error metrics as discussed in \ref{interpretation_variable_job_requirement_type_weightings}. As expressed by two recruiters, the lack of a precise ground truth complicates the testing of \acs{AI} tools in \acs{HR} activities. The critical unresolved question is identifying a repeatable procedure that can accurately generate a correct ranking or categorization and defining the criteria such rankings or categorizations must meet. This dilemma presents a potential area for future research to explore effective methodologies and criteria for establishing ground truths in \acs{HR} processes. However, this is no easy task and may be utterly unsolvable as inherent missing information or ambiguity makes this problem extremely complex.

\subsection{Hasty Work of Recruiters}
In the closure meeting, a recruiter acknowledged that this recruiter completed categorizing and ranking candidates too quickly, taking only about six minutes per job description to screen eight candidates. The recruiter suggested that a more appropriate duration would be at least $20$ to $25$ minutes per job description, attributing the need for additional time to the complexity of the task, which was exacerbated by factors such as foreign language requirements, lengthy \acs{CV}s, and unusual job positions. This rushed process by this recruiter likely contributed to inconsistencies in the results, and with more time, outcomes could have been probably more uniform. The average time spent per job description and $8$ candidates for ranking and categorization was around $22$ minutes, as seen in \ref{tab:taken_time}. This suggests that most participants have taken their time to produce valid results for further analysis. The result from the single recruiter who has not spent as much time was kept in the data set as the results from the other four recruiters were also very weakly correlated or uncorrelated, and the addition has not mitigated any previously existing correlation.

\subsection{Model Feedback Handling}
In the closure meeting, a participant emphasized the necessity for the recruitment model to adapt and learn from previous errors through dense or sparse feedback mechanisms, adjusting individual scores or applicant categorizations, respectively. This can be done by fine-tuning the underlying model with provided humanly scored or categorized examples or augmenting the model context, also called the model input, with matching or categorization instructions offered by humans. This is possible with the current configuration capabilities of the model \ref{model_configuration}. A downside of the fine-tuning approach is that a large amount of humanly annotated samples is necessary to fine-tune the model reasonably. The same participant advocated for the model's configurability to align with specific internal recruitment standards and suggested that experienced recruiters should handle the calibration. However, this task requires a skill set distinct from typical \acs{HR} roles. To minimize the needed skill set to configure the model, most of the proposed model's configuration can be changed by altering the prompt or definition texts, which requires no excellent technical skills. Maintaining transparency in such assistive technologies was also highlighted as a critical requirement.

\subsection{Sourcing from Candidates}
The interview data reveals that recruiting companies could significantly enhance their candidate sourcing efficiency by utilizing an advanced filtering model on their internal databases of past applicants. One participant highlighted that initial coarse filtering could reduce the candidate pool to a few hundred, and subsequent fine filtering with the proposed model could narrow it further to tens of applicants. A requirement to carry out this kind of fine filtering with the proposed model is a reasonable model computation time and model computation cost, as also discussed in \ref{interpretation_ml_as_assistive_technology}. This refined process streamlines the selection and drastically reduces the time required for human recruiters to process the same number of candidates. Additionally, the model's flexibility allows for customizable filter strength through adjustable thresholds based on the total scores of promising candidates, as noted by another recruiter. This adaptability ensures that the filtering process can effectively be tailored to meet specific recruitment needs. With ever-growing available in-house and external candidate databases, this feature will become increasingly important, and work must be done to implement the proposed model with a cheaper and faster \gls{LLM} architecture on the inside. A switch of the underlying \gls{LLM} architecture can quickly be done with the current model implementation as it already supports multiple providers through an interface-based modular concept. Future iterations of the \textit{LLAMA} model family by \textit{Meta} with a reasonable accuracy and parameter size are apparent candidates for fast processing. Even on-device processing may be possible with smaller \gls{LLM} variants.

\subsection{Implicit Job Requirements}
The interview data highlights a recruiter's suggestion for enhancing job requirement models by incorporating a dedicated pipeline step to identify implicit job requirements not explicitly stated in job descriptions. This step involves using internet searches based on job titles and company names and analyzing the job description. This procedure was already discussed in \ref{interpretation_sourcing_from_internet}. The recruiter emphasizes the importance of this addition, noting that relying solely on explicit details from job descriptions and applicants' \acs{CV}s may lead to incomplete requirement identification, potentially affecting the accuracy and effectiveness of the hiring process. This insight underscores the need for a more nuanced approach in automated job matching systems to capture the full spectrum of job requirements.
Furthermore, the problem can not only be tackled by providing the model with more context. Standard methods like better \gls{LLM} base models and fine-tuning can also address this problem. A simple but partial solution would be to add a dedicated, prompt request in the current architecture that queries the underlying \gls{LLM} to augment the currently found requirements with currently not-mentioned requirements implicitly induced by the job description.

\chapter{Discussion and Conclusion} \label{discussion_and_conclusion}

\section{Interpretation}
Most of the results have already been interpreted in the previous chapter. This section quickly summarizes the use cases of the proposed model as suggested by the human recruiters. The human recruiters would only categorize applicants with an assistive \acs{AI} tool to double-check the results by a skilled human recruiter. The recruiters received the transparency of the model well and said transparency is also a mandatory requirement for most recruiters when using \acs{AI} tools. The human recruiters would use the proposed model for incoming applications and source applicants from already available databases as a sort of an \acs{AI} filter mechanism. Of course, the model needs to operate faster and cheaper for this use case, as many more candidates are processed that way.
Furthermore, it was mentioned that \acs{GDPR} compliance needs to be ensured when deploying \acs{AI} models. The discussion on the ground truth for the ranking and categorization task error signal computation raised whether such a ground truth can be analytically found or described or if the domain is too noisy and ambiguous to be dealt with mathematically or analytically. The interactive work with the recruiters was constructive and sparked many ideas for improvement through reciprocal communication. 

\section{Challenges and Ethical Considerations}
As the proposed model used \gls{LLM}s from third-party providers, they already do their best to introduce as slight bias as possible to the models. However, as discussed in both meetings, bias issues must be continually monitored and mitigated to successfully integrate \acs{AI} solutions in \acs{HR} processes. It is also essential to use \acs{AI} tools that are configurable, make transparent decisions and can learn from past mistakes by tweaking their parameters or configurations. The introduction of assistive \acs{AI} technologies will also be quite tricky as most humans in \acs{HR} will fear losing their jobs if \acs{AI} continues to develop at such a rapid pace.

\section{Future Work} \label{future_work}
The fruitful meetings brought up many ideas to improve the currently used architecture:
\begin{itemize}
    \item \textbf{Multimodal Input}\\
    As the current state of the model has no support for multimodal input, it could be an area for improvement in the future. Features like images, audio, video, and code as particular forms of text and files with the example of \textit{PDF} files could be used as multimodal inputs.
    \item \textbf{Follow-Up Points}\\
    The recruiters also gave the practical recommendation that the model should spit out follow-up points that should be discussed with the applicant in direct communication to clarify missing or ambiguous information. Later, the model could initiate this communication on its own.
    \item \textbf{Configuration Presets}\\
    Configuration presets should be created for each major job group with suggested predefined job requirement type weightings, for example. This should help recruiters with the correct model configuration.
    \item \textbf{Fine-Grained Weighting}\\
    Furthermore, it was proposed that job requirement type weightings be finer-grained by introducing subtypes for each type. This would allow for a more precise model configuration, but each type needs a predefined or user-defined ontology to define the relations.
    \item \textbf{Implicit Job Requirements}\\
    It was proposed to add a special pipeline step to expand the implicit job requirements to explicit ones, as human recruiters also perform this sort of work when matching applicants. For example, language requirements can be given implicitly.
    \item \textbf{Improved Domain Knowledge}\\
    To enhance the domain knowledge of the used underlying \gls{LLM}, it could be either coupled with a domain-specific knowledge graph or any other form of improving the input tokens with more information or by fine-tuning the underlying \gls{LLM} itself.
    \item \textbf{Seniority}\\
    It was proposed to implement seniority as knockout criteria for the model as a senior developer will most likely not be considered a junior developer position.
    \item \textbf{Experience Attenuations}\\
    It was proposed that a fading factor for experiences should be implemented, such that older experiences are considered to have a minor impact when matching them with job requirements. Another possibility could be to add a context factor to the requirement matching as a programmer at \textit{Google} might have acquired more valuable skills than a programmer at a small, low-tech company.
    \item \textbf{Online Information Sourcing}\\
    It was proposed to augment the input tokens to the \gls{LLM} with additional information about the applied company, the applied domain or field, the applied job position, or the applicant itself. This could be done by querying the internet for additional information.
\end{itemize}

\section{Summary}
The model demonstrated strong indications of similarity to human experts in matching candidates to job descriptions, with distance and correlation scores suggesting that the model's results are indistinguishable from the human recruiter results. The similarity of the categorization task was determined via the Hamming distance, and the similarity of the ranking task was determined using Kendall's Tau correlation coefficient. The downside of this result is that the overall Kendall's Tau correlation coefficient between the human recruiter and the other results was low at about $0.2$, and the respective Hamming distance with a distance of about $3$ was relatively high for the same case. That means that to better statistically support the claims made, the sample size needs to be vastly increased. Time savings due to model usage were around $95\%$, and the cost to match a single applicant was around $0.27\$$, with the time savings percentage expected to go up and the cost significantly down. The proposed model currently uses the \textit{GPT-4 Turbo} model from \textit{OpenAI} to match the applicants. By switching this model with the \textit{GPT-3.5 Turbo} model from \textit{OpenAI}, the cost per applicant can be brought down to $0.013\$$ by simultaneously increasing the time-saving percentage. This presumable leads to less accurate matchings, but the degree of which may be explored in follow-up work. The human expert recruiters suggested only using the categorization aspect of the model as assistive tooling. This decision was made as the \acs{CV} does not offer enough information to rank applicants with enough validity to be helpful in their opinion. Several improvements to the proposed model have been discussed as listed under \ref{future_work}. Therefore, future work should explore these proposed model improvements and maybe include original ideas on further improving this model. Furthermore, increasing the sample size to better statistically support the made claims would also be desirable.

\section{Contributions}
This thesis provides an openly available model with good baseline performance for the candidate categorization and ranking task. The model is offered at \url{https://github.com/Oidlichtnwoada/hrGPT}, and changes or improvements may be created on \textit{GitHub}. Hopefully, some follow-up implementation project will bring this architecture to the next level. 

\backmatter

% Use an optional list of algorithms.
% \listofalgorithms
% \addcontentsline{toc}{chapter}{List of Algorithms}

% Add a bibliography.
% comment out when finished
\nocite{*}
\printbibliography

% Add an index.
\printindex

% Add a glossary.
\printglossaries


\chapter{Appendix}
\setcounter{page}{1}
\setcounter{chapter}{0}

\section{Code Listings}
\lstinputlisting[language=Python,label=lst:code_usage_example,caption=Functions of the programmed \gls{LLM} interface]{../hrgpt/utils/chat_utils.py}

\section{Sample Model Match Results}
\json{match_result_candidate_1}{Match Result for \textit{Bao Neilan}}
\json{match_result_candidate_8}{Match Result for \textit{Emanuelle Fought}}

\end{document}
